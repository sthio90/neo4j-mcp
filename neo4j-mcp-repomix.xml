This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  commands/
    prime.md
  settings.local.json
ai_docs/
  pocket-pick-v1.md
  repomix-output.xml
demo/
  check_data.py
  index.html
  mcp-client.js
  README.md
  run_http_server.py
  serve_demo.py
  styles.css
  test_demo.py
  test_stdio_client.py
  validate_demo.py
examples/
  test_connection.py
specs/
  fix-for-natural-query.md
  mcp-server-testing-plan.md
  neo4j-mcp-v1.md
src/
  mcp_server_neo4j_ehr/
    modules/
      functionality/
        get_clinical_notes.py
        get_schema.py
        list_diagnoses.py
        list_lab_events.py
        list_medications.py
        list_procedures.py
        natural_query.py
        patient.py
      constants.py
      data_types.py
      db_connection.py
    tests/
      functionality/
        test_get_clinical_notes.py
        test_get_schema.py
        test_list_diagnoses.py
        test_list_lab_events.py
        test_list_medications.py
        test_list_procedures.py
        test_natural_query.py
        test_patient.py
      conftest.py
      README.md
    __main__.py
    server.py
tests/
  README.md
  test_server.py
.env.example
.gitignore
AGENTIC_SEARCH_ARCHITECTURE.md
CHANGELOG.md
CONTRIBUTING.md
debug_natural_query.py
mcp_app.md
MCP_CLIENT_GUIDE.md
mcp_inspector_test.md
pyproject.toml
pytest.ini
README.md
requirements.txt
setup.sh
TOOL_REFACTORING.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(ls:*)",
      "Bash(mkdir:*)",
      "Bash(touch:*)",
      "Bash(python:*)",
      "Bash(mcp-server-neo4j-ehr:*)",
      "Bash(uv pip install:*)",
      "Bash(uv run pytest:*)",
      "Bash(export PATH=\"$HOME/.local/bin:$PATH\")",
      "Bash(uv run:*)",
      "Bash(chmod:*)",
      "Bash(find:*)",
      "Bash(eza:*)",
      "WebFetch(domain:github.com)",
      "WebFetch(domain:pypi.org)",
      "Bash(curl:*)",
      "Bash(mv:*)"
    ],
    "deny": []
  }
}
</file>

<file path=".claude/commands/prime.md">
# Context Prime
> Follow the instructions to understand the context of the project.

## Run the following command

eza . --tree --git-ignore

## Read the following files
> Read the files below and nothing else.

README.md
pyproject.toml
src/server.py
src/mcp_server_pocket_pick/modules/data_types.py
</file>

<file path="ai_docs/repomix-output.xml">
This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
mcp-neo4j-cloud-aura-api/
  src/
    mcp_neo4j_aura_manager/
      __init__.py
      server.py
  tests/
    integration/
      conftest.py
      test_aura_IT.py
      test_http_transport_IT.py
    unit/
      test_aura_manager.py
      test_utils.py
  .dockerignore
  CHANGELOG.md
  Dockerfile
  Makefile
  pyproject.toml
  README.md
  test.sh
mcp-neo4j-cypher/
  src/
    mcp_neo4j_cypher/
      __init__.py
      server.py
  tests/
    integration/
      conftest.py
      test_http_transport_IT.py
      test_server_tools_IT.py
      test_sse_transport_IT.py
      test_stdio_transport_IT.py
  .dockerignore
  .flake8
  .python-version
  CHANGELOG.md
  docker-compose.yml
  Dockerfile
  inspector.sh
  Makefile
  manifest.json
  pyproject.toml
  pyrightconfig.json
  README.md
  test.sh
mcp-neo4j-data-modeling/
  src/
    mcp_neo4j_data_modeling/
      __init__.py
      data_model.py
      server.py
      static.py
  tests/
    integration/
      conftest.py
      test_http_transport_IT.py
      test_sse_transport_IT.py
      test_stdio_transport_IT.py
    unit/
      conftest.py
      test_data_model.py
  .dockerignore
  .flake8
  .python-version
  CHANGELOG.md
  Dockerfile
  Makefile
  pyproject.toml
  pyrightconfig.json
  README.md
mcp-neo4j-memory/
  src/
    mcp_neo4j_memory/
      __init__.py
      neo4j_memory.py
      server.py
  tests/
    integration/
      conftest.py
      test_http_transport_IT.py
      test_neo4j_memory_IT.py
      test_sse_transport_IT.py
      test_stdio_transport_IT.py
  .dockerignore
  CHANGELOG.md
  Dockerfile
  Makefile
  pyproject.toml
  README.md
  test.sh
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="mcp-neo4j-cloud-aura-api/src/mcp_neo4j_aura_manager/__init__.py">
from . import server
import asyncio
import argparse
import os
import logging
import sys 


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def main():
    """Main entry point for the application."""
    parser = argparse.ArgumentParser(description="Neo4j Aura Database Instance Manager")
    parser.add_argument("--client-id", help="Neo4j Aura API Client ID", 
                        default=os.environ.get("NEO4J_AURA_CLIENT_ID"))
    parser.add_argument("--client-secret", help="Neo4j Aura API Client Secret", 
                        default=os.environ.get("NEO4J_AURA_CLIENT_SECRET"))
    parser.add_argument("--transport", default=None, help="Transport type")
    parser.add_argument("--server-host", default=None, help="Server host")
    parser.add_argument("--server-port", default=None, help="Server port")
    parser.add_argument("--server-path", default=None, help="Server path")
    
    args = parser.parse_args()
    
    if not args.client_id or not args.client_secret:
        logger.error("Client ID and Client Secret are required. Provide them as arguments or environment variables.")
        sys.exit(1)
    
    try:
        asyncio.run(server.main(
            args.client_id, 
            args.client_secret,
            args.transport or os.getenv("NEO4J_TRANSPORT", "stdio"),
            args.server_host or os.getenv("NEO4J_MCP_SERVER_HOST", "127.0.0.1"),
            args.server_port or os.getenv("NEO4J_MCP_SERVER_PORT", 8000),
            args.server_path or os.getenv("NEO4J_MCP_SERVER_PATH", "/mcp/"),
        ))
    except KeyboardInterrupt:
        logger.info("Server stopped by user")
    except Exception as e:
        logger.error(f"Error starting server: {str(e)}")
        sys.exit(1)

# Optionally expose other important items at package level
__all__ = ["main", "server"]
</file>

<file path="mcp-neo4j-cloud-aura-api/src/mcp_neo4j_aura_manager/server.py">
import json
import logging
import time
from typing import Any, Dict, List, Optional, Union, Literal

import requests
from fastmcp.server import FastMCP
from pydantic import Field

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def _validate_region(cloud_provider: str, region: str) -> None:
    """
    Validate the region exists for the given cloud provider.

    Args:
        cloud_provider: The cloud provider to validate the region for
        region: The region to validate

    Returns:
        None
    
    Raises:
        ValueError: If the region is not valid for the given cloud provider
    """

    if cloud_provider == "gcp" and region.count("-") != 1:
        raise ValueError(f"Invalid region for GCP: {region}. Must follow the format 'region-zonenumber'. Refer to https://neo4j.com/docs/aura/managing-instances/regions/ for valid regions.")
    elif cloud_provider == "aws" and region.count("-") != 2:
        raise ValueError(f"Invalid region for AWS: {region}. Must follow the format 'region-zone-number'. Refer to https://neo4j.com/docs/aura/managing-instances/regions/ for valid regions.")
    elif cloud_provider == "azure" and region.count("-") != 0:
        raise ValueError(f"Invalid region for Azure: {region}. Must follow the format 'regionzone'. Refer to https://neo4j.com/docs/aura/managing-instances/regions/ for valid regions.")

    
class AuraAPIClient:
    """Client for interacting with Neo4j Aura API."""
    
    BASE_URL = "https://api.neo4j.io/v1"
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        self.token = None
        self.token_expiry = 0
    
    def _get_auth_token(self) -> str:
        """Get authentication token for Aura API."""
        auth_url = "https://api.neo4j.io/oauth/token"
        
        # Create base64 encoded credentials
        import base64
        credentials = f"{self.client_id}:{self.client_secret}"
        encoded_credentials = base64.b64encode(credentials.encode()).decode()
        
        headers = {
            "Authorization": f"Basic {encoded_credentials}",
            "Content-Type": "application/x-www-form-urlencoded"
        }
        
        payload = {
            "grant_type": "client_credentials"
        }
        
        try:
            response = requests.post(auth_url, headers=headers, data=payload)
            response.raise_for_status()
            token_data = response.json()
            if not isinstance(token_data, dict) or \
               not token_data.get("access_token") or \
               not token_data.get("expires_in") or \
               not token_data.get("token_type") or \
               token_data.get("token_type").lower() != "bearer":
                raise Exception("Invalid token response format")
            self.token = token_data["access_token"]
            return self.token
        except requests.RequestException as e:
            logger.error(f"Authentication error: {str(e)}")
            raise Exception(f"Failed to authenticate with Neo4j Aura API: {str(e)}")
    
    def _get_headers(self) -> Dict[str, str]:
        """Get headers for API requests including authentication."""
        current_time = time.time()
        if not self.token or current_time >= self.token_expiry:
            self.token = self._get_auth_token()
            
        return {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
    
    def _handle_response(self, response: requests.Response) -> Dict[str, Any]:
        """Handle API response and errors."""
        try:
            response.raise_for_status()
            data = response.json()
            if "data" in data:
                return data["data"]
            else:
                return data
        except requests.HTTPError as e:
            error_msg = f"HTTP error: {e}"
            try:
                error_data = response.json()
                if "message" in error_data:
                    error_msg = f"{error_msg} - {error_data['message']}"
            except:
                pass
            logger.error(error_msg)
            raise Exception(error_msg)
        except requests.RequestException as e:
            logger.error(f"Request error: {str(e)}")
            raise Exception(f"API request failed: {str(e)}")
        except json.JSONDecodeError:
            logger.error("Failed to parse API response")
            raise Exception("Failed to parse API response")
    
    def list_instances(self) -> List[Dict[str, Any]]:
        """List all database instances."""
        url = f"{self.BASE_URL}/instances"
        response = requests.get(url, headers=self._get_headers())
        return self._handle_response(response)
    
    def get_instance_details(self, instance_ids: Union[str, List[str]]) -> Union[Dict[str, Any], List[Dict[str, Any]]]:
        """Get details for one or more instances by ID.
        
        Args:
            instance_ids: Either a single instance ID string or a list of instance ID strings
            
        Returns:
            A single instance details dict or a list of instance details dicts
        """
        if isinstance(instance_ids, str):
            # Handle single instance ID
            url = f"{self.BASE_URL}/instances/{instance_ids}"
            response = requests.get(url, headers=self._get_headers())
            return self._handle_response(response)
        else:
            # Handle list of instance IDs
            results = []
            for instance_id in instance_ids:
                url = f"{self.BASE_URL}/instances/{instance_id}"
                response = requests.get(url, headers=self._get_headers())
                try:
                    data = self._handle_response(response)
                    results.append(data)
                except Exception as e:
                    results.append({"error": str(e), "instance_id": instance_id})
            return results
    
    def get_instance_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """Find an instance by name."""
        instances = self.list_instances()
        for instance in instances:
            if name.lower() in instance.get("name", "").lower():
                # Get full instance details using the instance ID
                return self.get_instance_details(instance.get("id"))
        return None
    
    def create_instance(self, tenant_id: str, name: str, memory: int = 1, region: str = "europe-west1", 
                        version: str = "5", type: str = "free-db", 
                        vector_optimized: bool = False,
                        cloud_provider: str = "gcp", graph_analytics_plugin: bool = False,
                        source_instance_id: str = None) -> Dict[str, Any]:
        """Create a new database instance."""
        if tenant_id is None:
            raise ValueError("tenant_id is required")
        
        # Always set version to "5"
        version = "5"
        
        # Validate based on instance type
        if type == "free-db":
            if memory != 1:
                raise ValueError("free-db instances can only have 1GB memory")
            
            if not cloud_provider == "gcp":
                raise ValueError("free-db instances can only be created in GCP regions")
            
            if vector_optimized:
                raise ValueError("free-db instances cannot be vector optimized")
        
        # Validate for professional/enterprise/business-critical types
        elif type in ["professional-db", "enterprise-db", "business-critical"]:
            if cloud_provider and cloud_provider not in ["gcp", "aws", "azure"]:
                raise ValueError("cloud_provider must be one of: gcp, aws, azure")
            
            if vector_optimized and memory < 4:
                raise ValueError("vector optimized instances must have at least 4GB memory")
            
            # If cloning, source_instance_id is required
            if source_instance_id is not None:
                if not isinstance(source_instance_id, str):
                    raise ValueError("source_instance for clone from instance must be defined")
        else:
            raise ValueError(f"Invalid type {type}")
        
        _validate_region(cloud_provider, region)
        
        if graph_analytics_plugin and type not in ["professional-db", "enterprise-db", "business-critical"]:
            raise ValueError("graph analytics plugin is only available for professional, enterprise, and business-critical instances")

        if vector_optimized and type not in ["professional-db", "enterprise-db", "business-critical"]:
            raise ValueError("vector optimized instances are only available for professional, enterprise, and business-critical instances")


        payload = {
            "tenant_id": tenant_id,
            "name": name,
            "memory": f"{memory}GB",
            "region": region,
            "version": version,
            "type": type,
            "vector_optimized": vector_optimized,
            "cloud_provider": cloud_provider,
            "graph_analytics_plugin": graph_analytics_plugin
        }
        
        # Add source_instance_id if provided (for cloning)
        if source_instance_id is not None:
            payload["source_instance_id"] = source_instance_id
        
        url = f"{self.BASE_URL}/instances"
        response = requests.post(url, headers=self._get_headers(), json=payload)
        return self._handle_response(response)
    
    def update_instance(self, instance_id: str, name: Optional[str] = None, 
                        memory: Optional[int] = None, 
                        vector_optimized: Optional[bool] = None, 
                        storage: Optional[int] = None) -> Dict[str, Any]:
        """Update an existing instance."""
        payload = {}
        if name is not None:
            payload["name"] = name
        if memory is not None:
            payload["memory"] = f"{memory}GB"
            payload["storage"] = f"{2*memory}GB"
        if storage is not None:
            payload["storage"] = f"{storage}GB"
        if vector_optimized is not None:
            payload["vector_optimized"] = str(vector_optimized).lower()
        
        # Validate vector optimization requirements only if both memory and vector_optimized are being updated
        if (memory is not None and vector_optimized is not None and 
            vector_optimized and memory < 4):
            raise ValueError("vector optimized instances must have at least 4GB memory")
        
        url = f"{self.BASE_URL}/instances/{instance_id}"
        response = requests.patch(url, headers=self._get_headers(), json=payload)
        return self._handle_response(response)
    
    def pause_instance(self, instance_id: str) -> Dict[str, Any]:
        """Pause a database instance."""
        url = f"{self.BASE_URL}/instances/{instance_id}/pause"
        response = requests.post(url, headers=self._get_headers())
        return self._handle_response(response)
    
    def resume_instance(self, instance_id: str) -> Dict[str, Any]:
        """Resume a paused database instance."""
        url = f"{self.BASE_URL}/instances/{instance_id}/resume"
        response = requests.post(url, headers=self._get_headers())
        return self._handle_response(response)
    
    def list_tenants(self) -> List[Dict[str, Any]]:
        """List all tenants/projects."""
        url = f"{self.BASE_URL}/tenants"
        response = requests.get(url, headers=self._get_headers())
        return self._handle_response(response)
    
    def get_tenant_details(self, tenant_id: str) -> Dict[str, Any]:
        """Get details for a specific tenant/project."""
        url = f"{self.BASE_URL}/tenants/{tenant_id}"
        response = requests.get(url, headers=self._get_headers())
        return self._handle_response(response)

    def delete_instance(self, instance_id: str) -> Dict[str, Any]:
        """Delete a database instance.
        
        Args:
            instance_id: ID of the instance to delete
            
        Returns:
            Response dict with status information
        """
        url = f"{self.BASE_URL}/instances/{instance_id}"
        response = requests.delete(url, headers=self._get_headers())
        return self._handle_response(response)


class AuraManager:
    """MCP server for Neo4j Aura instance management."""
    
    def __init__(self, client_id: str, client_secret: str):
        self.client = AuraAPIClient(client_id, client_secret)
    
    async def list_instances(self, **kwargs) -> Dict[str, Any]:
        """List all Aura database instances."""
        try:
            instances = self.client.list_instances()
            return {
                "instances": instances,
                "count": len(instances)
            }
        except Exception as e:
            return {"error": str(e)}
    
    async def get_instance_details(self, instance_ids: List[str], **kwargs) -> Dict[str, Any]:
        """Get details for one or more instances by ID."""
        try:
            results = self.client.get_instance_details(instance_ids)
            return {
                "instances": results,
                "count": len(results)
            }
        except Exception as e:
            return {"error": str(e)}
    
    async def get_instance_by_name(self, name: str, **kwargs) -> Dict[str, Any]:
        """Find an instance by name."""
        try:
            instance = self.client.get_instance_by_name(name)
            if instance:
                return instance
            return {"error": f"Instance with name '{name}' not found"}
        except Exception as e:
            return {"error": str(e)}
    
    async def create_instance(self, tenant_id: str, name: str, memory: int = 1, region: str = "us-central1", 
                             version: str = "5", type: str = "free-db", 
                             vector_optimized: bool = False,
                             cloud_provider: str = "gcp", graph_analytics_plugin: bool = False,
                             source_instance_id: str = None, **kwargs) -> Dict[str, Any]:
        """Create a new database instance."""
        try:
            return self.client.create_instance(
                tenant_id=tenant_id,
                name=name,
                memory=memory,
                region=region,
                version=version,
                type=type,
                vector_optimized=vector_optimized,
                cloud_provider=cloud_provider,
                graph_analytics_plugin=graph_analytics_plugin,
                source_instance_id=source_instance_id
            )
        except Exception as e:
            return {"error": str(e)}
    
    async def update_instance_name(self, instance_id: str, name: str, **kwargs) -> Dict[str, Any]:
        """Update an instance's name."""
        try:
            return self.client.update_instance(instance_id=instance_id, name=name)
        except Exception as e:
            return {"error": str(e)}
    
    async def update_instance_memory(self, instance_id: str, memory: int, **kwargs) -> Dict[str, Any]:
        """Update an instance's memory allocation."""
        try:
            return self.client.update_instance(instance_id=instance_id, memory=memory)
        except Exception as e:
            return {"error": str(e)}
    
    async def update_instance_vector_optimization(self, instance_id: str, 
                                                vector_optimized: bool, **kwargs) -> Dict[str, Any]:
        """Update an instance's vector optimization setting."""
        try:
            return self.client.update_instance(
                instance_id=instance_id, 
                vector_optimized=vector_optimized
            )
        except Exception as e:
            return {"error": str(e)}
    
    async def pause_instance(self, instance_id: str, **kwargs) -> Dict[str, Any]:
        """Pause a database instance."""
        try:
            return self.client.pause_instance(instance_id)
        except Exception as e:
            return {"error": str(e)}
    
    async def resume_instance(self, instance_id: str, **kwargs) -> Dict[str, Any]:
        """Resume a paused database instance."""
        try:
            return self.client.resume_instance(instance_id)
        except Exception as e:
            return {"error": str(e)}
    
    async def list_tenants(self, **kwargs) -> Dict[str, Any]:
        """List all tenants/projects."""
        try:
            tenants = self.client.list_tenants()
            return {
                "tenants": tenants,
                "count": len(tenants)
            }
        except Exception as e:
            return {"error": str(e)}
    
    async def get_tenant_details(self, tenant_id: str, **kwargs) -> Dict[str, Any]:
        """Get details for a specific tenant/project."""
        try:
            return self.client.get_tenant_details(tenant_id)
        except Exception as e:
            return {"error": str(e)}
    
    async def delete_instance(self, instance_id: str, **kwargs) -> Dict[str, Any]:
        """Delete one database instance."""
        try:
            return self.client.delete_instance(instance_id)
        except Exception as e:
            return {"error": str(e)}


def create_mcp_server(aura_manager: AuraManager) -> FastMCP:
    """Create an MCP server instance for Aura management."""
    
    mcp: FastMCP = FastMCP("mcp-neo4j-aura-manager", dependencies=["requests", "pydantic"], stateless_http=True)

    @mcp.tool()
    async def list_instances() -> dict:
        """List all Neo4j Aura database instances."""
        result = await aura_manager.list_instances()
        return result

    @mcp.tool()
    async def get_instance_details(instance_ids: List[str]) -> dict:
        """Get details for one or more Neo4j Aura instances by ID."""
        result = await aura_manager.get_instance_details(instance_ids)
        return result

    @mcp.tool()
    async def get_instance_by_name(name: str) -> dict:
        """Find a Neo4j Aura instance by name and returns the details including the id."""
        result = await aura_manager.get_instance_by_name(name)
        return result

    @mcp.tool()
    async def create_instance(
        tenant_id: str = Field(..., description="ID of the tenant/project where the instance will be created"),
        name: str = Field(..., description="Name for the new instance"),
        memory: int = Field(1, description="Memory allocation in GB"),
        region: str = Field("us-central1", description="Region for the instance (e.g., 'us-central1')"),
        type: str = Field("free-db", description="Instance type (free-db, professional-db, enterprise-db, or business-critical)"),
        vector_optimized: bool = Field(False, description="Whether the instance is optimized for vector operations"),
        cloud_provider: str = Field("gcp", description="Cloud provider (gcp, aws, azure)"),
        graph_analytics_plugin: bool = Field(False, description="Whether to enable the graph analytics plugin"),
        source_instance_id: Optional[str] = Field(None, description="ID of the source instance to clone from")
    ) -> dict:
        """Create a new Neo4j Aura database instance."""
        result = await aura_manager.create_instance(
            tenant_id=tenant_id,
            name=name,
            memory=memory,
            region=region,
            type=type,
            vector_optimized=vector_optimized,
            cloud_provider=cloud_provider,
            graph_analytics_plugin=graph_analytics_plugin,
            source_instance_id=source_instance_id
        )
        return result

    @mcp.tool()
    async def update_instance_name(instance_id: str, name: str) -> dict:
        """Update the name of a Neo4j Aura instance."""
        result = await aura_manager.update_instance_name(instance_id, name)
        return result

    @mcp.tool()
    async def update_instance_memory(instance_id: str, memory: int) -> dict:
        """Update the memory allocation of a Neo4j Aura instance."""
        result = await aura_manager.update_instance_memory(instance_id, memory)
        return result

    @mcp.tool()
    async def update_instance_vector_optimization(instance_id: str, vector_optimized: bool) -> dict:
        """Update the vector optimization setting of a Neo4j Aura instance."""
        result = await aura_manager.update_instance_vector_optimization(instance_id, vector_optimized)
        return result

    @mcp.tool()
    async def pause_instance(instance_id: str) -> dict:
        """Pause a Neo4j Aura database instance."""
        result = await aura_manager.pause_instance(instance_id)
        return result

    @mcp.tool()
    async def resume_instance(instance_id: str) -> dict:
        """Resume a paused Neo4j Aura database instance."""
        result = await aura_manager.resume_instance(instance_id)
        return result

    @mcp.tool()
    async def list_tenants() -> dict:
        """List all Neo4j Aura tenants/projects."""
        result = await aura_manager.list_tenants()
        return result

    @mcp.tool()
    async def get_tenant_details(tenant_id: str) -> dict:
        """Get details for a specific Neo4j Aura tenant/project."""
        result = await aura_manager.get_tenant_details(tenant_id)
        return result

    @mcp.tool()
    async def delete_instance(instance_id: str) -> dict:
        """Delete a Neo4j Aura database instance."""
        result = await aura_manager.delete_instance(instance_id)
        return result

    return mcp


async def main(
    client_id: str, 
    client_secret: str,
    transport: Literal["stdio", "sse", "http"] = "stdio",
    host: str = "127.0.0.1",
    port: int = 8000,
    path: str = "/mcp/",
) -> None:
    """Start the MCP server."""
    logger.info("Starting MCP Neo4j Aura Manager Server")
    
    aura_manager = AuraManager(client_id, client_secret)
    
    # Create MCP server
    mcp = create_mcp_server(aura_manager)

    # Run the server with the specified transport
    match transport:
        case "http":
            await mcp.run_http_async(host=host, port=port, path=path)
        case "stdio":
            await mcp.run_stdio_async()
        case "sse":
            await mcp.run_sse_async(host=host, port=port, path=path)
        case _:
            raise ValueError(f"Unsupported transport: {transport}")


if __name__ == "__main__":
    main()
</file>

<file path="mcp-neo4j-cloud-aura-api/tests/integration/conftest.py">
import os
import pytest
from typing import Dict, Any

# Skip all tests if credentials are not available
pytestmark = pytest.mark.skipif(
    not os.environ.get("NEO4J_AURA_CLIENT_ID") or not os.environ.get("NEO4J_AURA_CLIENT_SECRET"),
    reason="NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required for integration tests"
)


@pytest.fixture(scope="session")
def aura_credentials() -> Dict[str, str]:
    """Get Aura API credentials from environment variables."""
    client_id = os.environ.get("NEO4J_AURA_CLIENT_ID")
    client_secret = os.environ.get("NEO4J_AURA_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        pytest.skip("NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required")
    
    return {
        "client_id": client_id,
        "client_secret": client_secret
    }


@pytest.fixture(scope="session")
def test_tenant_id(aura_credentials) -> str:
    """Get a test tenant ID for integration tests."""
    from mcp_neo4j_aura_manager.server import AuraAPIClient
    
    client = AuraAPIClient(aura_credentials["client_id"], aura_credentials["client_secret"])
    tenants = client.list_tenants()
    
    if len(tenants) == 0:
        pytest.skip("No tenants available for testing")
    
    # Look for a test tenant or use the first one
    for tenant in tenants:
        if "test" in tenant.get("name", "").lower():
            return tenant["id"]
    
    # Return the first tenant if no test tenant found
    return tenants[0]["id"]


@pytest.fixture(scope="session")
def test_instance_id(aura_credentials) -> str:
    """Get a test instance ID for integration tests."""
    from mcp_neo4j_aura_manager.server import AuraAPIClient
    
    client = AuraAPIClient(aura_credentials["client_id"], aura_credentials["client_secret"])
    instances = client.list_instances()
    
    if len(instances) == 0:
        pytest.skip("No instances available for testing")
    
    # Look for a test instance or use the first one
    for instance in instances:
        if "test" in instance.get("name", "").lower():
            return instance["id"]
    
    # Return the first instance if no test instance found
    return instances[0]["id"]
</file>

<file path="mcp-neo4j-cloud-aura-api/tests/integration/test_aura_IT.py">
import os
import pytest
import logging
from mcp_neo4j_aura_manager.server import AuraAPIClient
import uuid
import time

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Skip all tests if credentials are not available
pytestmark = pytest.mark.skipif(
    not os.environ.get("NEO4J_AURA_CLIENT_ID") or not os.environ.get("NEO4J_AURA_CLIENT_SECRET"),
    reason="NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required for integration tests"
)

def wait_for_instance_status(aura_client, instance_id, status="running"):
    max_wait_time = 500  # Maximum wait time in seconds
    wait_interval = 10  # Check every 10 seconds
    start_time = time.time()
    
    time.sleep(wait_interval)

    instance_details = None
    while time.time() - start_time < max_wait_time:
        instance_details = aura_client.get_instance_details([instance_id])[0]
        assert instance_details["id"] == instance_id
        
        if instance_details["status"] == status:
            print(f"Instance {instance_id} is now in {status} state")
            return instance_details
            
        time.sleep(wait_interval)
    
    return instance_details

@pytest.fixture
def aura_client():
    """Create a real Aura API client using environment variables."""
    client_id = os.environ.get("NEO4J_AURA_CLIENT_ID")
    client_secret = os.environ.get("NEO4J_AURA_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        pytest.skip("NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required")
    
    return AuraAPIClient(client_id, client_secret)

def test_authentication(aura_client):
    """Test that authentication works with the provided credentials."""
    token = aura_client._get_auth_token()
    assert token is not None
    assert isinstance(token, str)
    assert len(token) > 0

def test_list_instances(aura_client):
    """Test listing instances from the real API."""
    instances = aura_client.list_instances()
    assert isinstance(instances, list)
    # Even if there are no instances, this should return an empty list, not fail

def test_list_tenants(aura_client):
    """Test listing tenants/projects from the real API."""
    tenants = aura_client.list_tenants()
    assert isinstance(tenants, list)
    # There should be at least one tenant if the account is valid
    assert len(tenants) > 0

def get_test_tenant(tenants):
    """Find a tenant with 'Test Tenant' in the name."""
    for tenant in tenants:
        if "Test Tenant" in tenant.get("name", ""):
            return tenant["id"]
    pytest.skip("No tenant found with 'Test Tenant' in the name")

@pytest.mark.parametrize("test_type", ["read_only", "create_instance"])
def test_integration_flow(aura_client, test_type):
    """
    Test a complete flow of operations.
    
    This test has two modes:
    - read_only: Only performs read operations
    - create_instance: Creates a test instance, updates it, then deletes it
      (WARNING: This will incur costs if run against a paid account)
    """
    # First, list all tenants
    tenants = aura_client.list_tenants()
    assert len(tenants) > 0
    tenant_id = get_test_tenant(tenants)
    
    # Get details for the first tenant
    tenant_details = aura_client.get_tenant_details(tenant_id)
    assert tenant_details["id"] == tenant_id
    assert "instance_configurations" in tenant_details
    
    # List all instances
    instances = aura_client.list_instances()
    # Verify instance details if any exist
    if instances:
        for instance in instances:
            assert "id" in instance
            assert "name" in instance
            assert "cloud_provider" in instance
            assert "created_at" in instance
            instance_details = aura_client.get_instance_details([instance["id"]])[0]
            print(instance_details)
            assert "id" in instance_details
            assert "name" in instance_details
            assert "cloud_provider" in instance_details
            assert "created_at" in instance_details
            assert "region" in instance_details
            assert "status" in instance_details
            assert "memory" in instance_details
            assert "type" in instance_details
            assert isinstance(instance_details["vector_optimized"], bool)
            assert isinstance(instance_details["graph_analytics_plugin"], bool)
    
    # If we're only doing read operations, we're done
    if test_type == "read_only":
        return
    
    # WARNING: The following will create a real instance and incur costs
    # Only run this if explicitly enabled and you understand the implications
    if test_type == "create_instance" and os.environ.get("ENABLE_INSTANCE_CREATION") == "true":
        # Create a test instance
        test_instance_name = f"Pro Test Instance {uuid.uuid4().hex[:8]}"
        
        try:
            # Create a small instance for testing
            instance = aura_client.create_instance(
                tenant_id=tenant_id,
                name=test_instance_name,
                memory=1,  # Minimum size
                region="us-central1",  # Use a common region
                version="5",  # Use a current version
                type="professional-db",
                vector_optimized=False
            )
            
            instance_id = instance["id"]
            assert instance["name"] == test_instance_name
            
            # Update the instance name
            print("Updating instance name")
            updated_name = f"{test_instance_name}-U"
            updated = aura_client.update_instance(instance_id=instance_id, name=updated_name)
            assert updated["name"] == updated_name
            
            print("Getting instance details")
            instance_details = aura_client.get_instance_details([instance_id])[0]
            assert instance_details["name"] == updated_name
            
            instance_details = wait_for_instance_status(aura_client, instance_id,"running")
            assert instance_details["status"] == "running"

            # Pause the instance
            print("Pausing instance")
            paused = aura_client.pause_instance(instance_id)
            assert paused["status"] in ["paused", "pausing"]
            
            print("Waiting for instance to be paused")
            instance_details = wait_for_instance_status(aura_client, instance_id,"paused")
            assert instance_details["status"] == "paused"

            print("Resuming instance")
            resumed = aura_client.resume_instance(instance_id)
            assert resumed["status"] in ["resuming", "running"]

            print("Waiting for instance to be running")
            instance_details = wait_for_instance_status(aura_client, instance_id,"running")
            assert instance_details["status"] == "running"

            print("Updating instance memory")
            updated = aura_client.update_instance(instance_id=instance_id, memory=2)
            instance_details = wait_for_instance_status(aura_client, instance_id,"running")
            assert instance_details["status"] == "running"
            assert instance_details["memory"] == "2GB"

        except Exception as e:
            logger.error(f"Error during instance creation test: {str(e)}")
            raise 
        finally:
            delete_result = aura_client.delete_instance(instance_id)
            instance_details = aura_client.get_instance_details([instance_id])[0]
            assert "status" in instance_details
            print(f"Deleted test instance {instance_id}: {delete_result} {instance_details}")

def test_get_instance_details_multiple(aura_client):
    """Test getting details for multiple instances from the real API."""
    # First, list instances to get some IDs
    instances = aura_client.list_instances()
    
    # Skip if there aren't at least 2 instances
    if len(instances) < 2:
        pytest.skip("Need at least 2 instances for this test")
    
    instance_ids = [instances[0]["id"], instances[1]["id"]]
    details = aura_client.get_instance_details(instance_ids)
    
    assert isinstance(details, list)
    assert len(details) == 2
    for i, detail in enumerate(details):
        assert detail["id"] == instance_ids[i]


@pytest.mark.parametrize("test_type", ["create_instance"])
def test_create_and_delete_instance_integration(aura_client, test_type):
    """Test creating and then deleting an instance with the real API."""
    # Skip if not running the create_instance test
    if test_type != "create_instance":
        pytest.skip("Skipping instance creation test")
    
    # First, list tenants to get a tenant ID
    tenants = aura_client.list_tenants()
    assert len(tenants) > 0
    tenant_id = get_test_tenant(tenants)
    
    # Create a test instance
    instance_name = f"Test Instance {uuid.uuid4().hex[:8]}"
    instance = aura_client.create_instance(
        tenant_id=tenant_id,
        name=instance_name,
        memory=1,
        cloud_provider="gcp",
        region="europe-west1",
        type="free-db",
    )
    
    assert "id" in instance
    instance_id = instance["id"]

    try:
        assert "name" in instance
        assert instance["name"] == instance_name

        instance_details = aura_client.get_instance_details([instance_id])[0]

        assert "id" in instance_details
        assert "name" in instance_details
        assert "cloud_provider" in instance_details
        assert "created_at" in instance_details
        assert "region" in instance_details
        assert "status" in instance_details
        assert "memory" in instance_details
        assert "type" in instance_details
        assert isinstance(instance_details["vector_optimized"], bool)
        assert isinstance(instance_details["graph_analytics_plugin"], bool)

        instance_details = wait_for_instance_status(aura_client, instance_id, "running")        
        # Verify the instance reached Running state
        assert instance_details is not None
        assert instance_details["status"] == "running", "Instance did not reach Running state"
        
    finally:
        # Clean up - delete the instance
        delete_result = aura_client.delete_instance(instance_id)
        instance_details = aura_client.get_instance_details([instance_id])[0]
        assert "status" in instance_details
        print(f"Deleted test instance {instance_id}: {delete_result} {instance_details}")


def test_create_instance_vector_optimized_and_memory_less_than_4_should_raise_error(aura_client):
    with pytest.raises(ValueError):
        aura_client.create_instance(memory=3, vector_optimized=True, tenant_id="test-tenant-1", name="Test Instance")

def test_update_instance_vector_optimized_and_memory_less_than_4_should_raise_error(aura_client):
    with pytest.raises(ValueError):
        aura_client.update_instance(instance_id="test-instance", memory=3, vector_optimized=True)
</file>

<file path="mcp-neo4j-cloud-aura-api/tests/integration/test_http_transport_IT.py">
import asyncio
import json
import logging
import os
import pytest
import requests
import time
from typing import AsyncGenerator, Dict, Any
import aiohttp

logger = logging.getLogger(__name__)

async def parse_sse_response(response: aiohttp.ClientResponse) -> dict:
    """Parse Server-Sent Events response from FastMCP 2.0."""
    content = await response.text()
    lines = content.strip().split('\n')
    
    # Find the data line that contains the JSON
    for line in lines:
        if line.startswith('data: '):
            json_str = line[6:]  # Remove 'data: ' prefix
            return json.loads(json_str)
    
    raise ValueError("No data line found in SSE response")
    
# Skip all tests if credentials are not available
pytestmark = pytest.mark.skipif(
    not os.environ.get("NEO4J_AURA_CLIENT_ID") or not os.environ.get("NEO4J_AURA_CLIENT_SECRET"),
    reason="NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required for integration tests"
)


@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture(scope="session")
async def aura_manager_server() -> AsyncGenerator[Dict[str, Any], None]:
    """Start the Aura Manager MCP server with HTTP transport."""
    
    # Get real credentials from environment
    client_id = os.environ.get("NEO4J_AURA_CLIENT_ID")
    client_secret = os.environ.get("NEO4J_AURA_CLIENT_SECRET")
    
    if not client_id or not client_secret:
        pytest.skip("NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required")
    
    # Import the server module
    import sys
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../../src"))
    
    from mcp_neo4j_aura_manager.server import main
    
    # Start the server in a separate process
    server_process = None
    server_url = "http://127.0.0.1:8001/mcp/"
    
    try:
        # Start the server
        import subprocess
        import threading
        
        def run_server():
            asyncio.run(main(
                client_id=client_id,
                client_secret=client_secret,
                transport="http",
                host="127.0.0.1",
                port=8001,
                path="/mcp/"
            ))
        
        server_thread = threading.Thread(target=run_server, daemon=True)
        server_thread.start()
        
        # Wait for server to start
        time.sleep(3)
        
        # Test server is running
        try:
            response = requests.get(server_url.replace("/mcp/", "/health"), timeout=5)
            if response.status_code == 200:
                logger.info("Aura Manager server started successfully")
            else:
                logger.warning(f"Server health check returned {response.status_code}")
        except requests.exceptions.RequestException as e:
            logger.warning(f"Could not connect to server: {e}")
        
        yield {
            "url": server_url,
            "client_id": client_id,
            "client_secret": client_secret
        }
        
    finally:
        if server_process:
            server_process.terminate()
            server_process.wait()


class TestAuraManagerHTTPTransport:
    """Test Aura Manager MCP server over HTTP transport."""
    
    @pytest.mark.asyncio
    async def test_server_startup(self, aura_manager_server):
        """Test that the server starts up correctly."""
        url = aura_manager_server["url"]
        
        # Verify server configuration
        assert url == "http://127.0.0.1:8001/mcp/"
        assert aura_manager_server["client_id"] is not None
        assert aura_manager_server["client_secret"] is not None
    
    @pytest.mark.asyncio
    async def test_transport_configuration(self, aura_manager_server):
        """Test that the server is configured for HTTP transport."""
        # This test verifies the server was started with HTTP transport
        # The fixture ensures this by calling main() with transport="http"
        assert True  # If we get here, the server started with HTTP transport
    
    @pytest.mark.asyncio
    async def test_server_connectivity(self, aura_manager_server):
        """Test basic server connectivity."""
        url = aura_manager_server["url"]
        
        try:
            response = requests.get(url, timeout=5)
            # The server should be running and responding
            assert response.status_code in [200, 404, 405]  # Accept various responses
        except requests.exceptions.RequestException as e:
            # Server might not be fully ready, which is okay for this test
            logger.warning(f"Server connectivity test failed: {e}")
            pass

    @pytest.mark.asyncio
    async def test_invalid_node_data(self, aura_manager_server):
        """Test handling of invalid node data."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "validate_node",
                        "arguments": {
                            "node": {
                                "invalid_field": "invalid_value"
                            }
                        }
                    }
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json"
                }
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Should return an error or handle gracefully
                assert "result" in result

    @pytest.mark.asyncio
    async def test_invalid_data_model(self, aura_manager_server):
        """Test handling of invalid data model."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "validate_data_model",
                        "arguments": {
                            "data_model": {
                                "invalid_field": "invalid_value"
                            }
                        }
                    }
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json"
                }
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Should return an error or handle gracefully
                assert "result" in result


class TestAuraManagerRealAPI:
    """Test Aura Manager with real API calls (requires credentials)."""
    
    @pytest.fixture
    def aura_client(self):
        """Create a real Aura API client using environment variables."""
        client_id = os.environ.get("NEO4J_AURA_CLIENT_ID")
        client_secret = os.environ.get("NEO4J_AURA_CLIENT_SECRET")
        
        if not client_id or not client_secret:
            pytest.skip("NEO4J_AURA_CLIENT_ID and NEO4J_AURA_CLIENT_SECRET environment variables are required")
        
        from mcp_neo4j_aura_manager.server import AuraAPIClient
        return AuraAPIClient(client_id, client_secret)
    
    def test_authentication(self, aura_client):
        """Test that authentication works with the provided credentials."""
        token = aura_client._get_auth_token()
        assert token is not None
        assert isinstance(token, str)
        assert len(token) > 0
    
    def test_list_instances(self, aura_client):
        """Test listing instances from the real API."""
        instances = aura_client.list_instances()
        assert isinstance(instances, list)
        # Even if there are no instances, this should return an empty list, not fail
    
    def test_list_tenants(self, aura_client):
        """Test listing tenants/projects from the real API."""
        tenants = aura_client.list_tenants()
        assert isinstance(tenants, list)
        # There should be at least one tenant if the account is valid
        assert len(tenants) > 0
    
    def test_get_instance_details(self, aura_client):
        """Test getting instance details from the real API."""
        # First, list instances to get some IDs
        instances = aura_client.list_instances()
        
        # Skip if there are no instances
        if len(instances) == 0:
            pytest.skip("No instances available for testing")
        
        instance_id = instances[0]["id"]
        details = aura_client.get_instance_details([instance_id])
        
        assert isinstance(details, list)
        assert len(details) == 1
        assert details[0]["id"] == instance_id


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
</file>

<file path="mcp-neo4j-cloud-aura-api/tests/unit/test_aura_manager.py">
import os
import pytest
from unittest.mock import patch, MagicMock

from mcp_neo4j_aura_manager.server import AuraAPIClient, AuraManager

# Mock responses for testing
MOCK_INSTANCES = {
    "data": [
        {
            "id": "instance-1",
            "name": "Test Instance 1",
            "memory": 4,
            "status": "running",
            "region": "us-east-1",
            "version": "5.15",
            "type": "enterprise",
            "vector_optimized": False
        },
        {
            "id": "instance-2",
            "name": "Test Instance 2",
            "memory": 8,
            "status": "paused",
            "region": "eu-west-1",
            "version": "5.15",
            "type": "enterprise",
            "vector_optimized": True
        }
    ]
}

MOCK_TENANTS = {
    "data": [
        {
            "id": "tenant-1",
            "name": "Test Tenant 1",
            "type": "free"
        },
        {
            "id": "tenant-2",
            "name": "Test Tenant 2",
            "type": "professional"
        }
    ]
}

MOCK_TENANT_DETAILS = {
    "data": {
        "id": "tenant-1",
        "name": "Test Tenant 1",
        "instance_configurations": [
            {
                "cloud_provider": "gcp",
                "memory": "8GB",
                "region": "europe-west1",
                "region_name": "Belgium (europe-west1)",
                "storage": "16GB",
                "type": "professional-ds",
                "version": "5"
            }
        ]
    }
}


class MockResponse:
    def __init__(self, json_data, status_code=200):
        self.json_data = json_data
        self.status_code = status_code
        
    def json(self):
        return self.json_data
        
    def raise_for_status(self):
        if self.status_code >= 400:
            raise Exception(f"HTTP Error: {self.status_code}")


@pytest.fixture
def mock_client():
    with patch('requests.get') as mock_get, \
         patch('requests.post') as mock_post, \
         patch('requests.patch') as mock_patch:
                
        # Set up different responses based on URL
        def get_side_effect(url, headers=None, **kwargs):
            if "/instances" in url and not url.split("/instances")[1]:
                return MockResponse(MOCK_INSTANCES)
            elif "/instances/instance-1" in url:
                return MockResponse({"data":MOCK_INSTANCES["data"][0]})
            elif "/instances/instance-2" in url:
                return MockResponse({"data":MOCK_INSTANCES["data"][1]})
            elif "/tenants" in url and not url.split("/tenants")[1]:
                return MockResponse(MOCK_TENANTS)
            elif "/tenants/tenant-1" in url:
                return MockResponse(MOCK_TENANT_DETAILS)
            else:
                return MockResponse({"error": "Not found"}, 404)
        
        mock_get.side_effect = get_side_effect
        
        # Set up different responses based on URL for POST requests
        def post_side_effect(url, headers=None, **kwargs):
            if "/oauth/token" in url:
                return MockResponse({
                    "access_token": "fake-token",
                    "token_type": "bearer", 
                    "expires_in": 3600,
                })
            elif "/instances" in url and not url.split("/instances")[1]:
                # Creating new instance
                return MockResponse({"data": MOCK_INSTANCES["data"][0]})
            elif "/pause" in url:
                return MockResponse({"data": {"status": "paused"}})
            elif "/resume" in url:
                return MockResponse({"data": {"status": "running"}})
            else:
                return MockResponse({"error": "Not found"}, 404)
                
        mock_post.side_effect = post_side_effect
        mock_patch.return_value = MockResponse({"status": "updated"})
        
        client = AuraAPIClient("fake-id", "fake-secret")
        yield client


@pytest.mark.asyncio
async def test_list_instances(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    result = await manager.list_instances()
    assert "instances" in result
    assert len(result["instances"]) == 2
    assert result["count"] == 2


@pytest.mark.asyncio
async def test_get_instance_details(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    mock_client.get_instance_details = MagicMock(return_value=[
        MOCK_INSTANCES["data"][0]
    ])
    manager.client = mock_client
    
    result = await manager.get_instance_details(["instance-1"])
    assert result["count"] == 1

    assert result["instances"][0]["id"] == "instance-1"
    assert result["instances"][0]["name"] == "Test Instance 1"


@pytest.mark.asyncio
async def test_get_instance_details_multiple(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the get_instance_details method to return a list
    mock_client.get_instance_details = MagicMock(return_value=[
        MOCK_INSTANCES["data"][0],
        MOCK_INSTANCES["data"][1]
    ])
    
    result = await manager.get_instance_details(["instance-1", "instance-2"])
    assert "instances" in result
    assert result["count"] == 2
    assert result["instances"][0]["id"] == "instance-1"
    assert result["instances"][1]["id"] == "instance-2"


@pytest.mark.asyncio
async def test_get_instance_by_name(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the get_instance_by_name method
    mock_client.get_instance_by_name = MagicMock(return_value=MOCK_INSTANCES["data"][0])
    
    result = await manager.get_instance_by_name("Test Instance 1")
    assert result["id"] == "instance-1"
    assert result["name"] == "Test Instance 1"

@pytest.mark.asyncio
async def test_get_instance_by_name_substring(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the get_instance_by_name method
    mock_client.get_instance_by_name = MagicMock(return_value=MOCK_INSTANCES["data"][0])
    
    result = await manager.get_instance_by_name("Instance 1")
    assert result["id"] == "instance-1"
    assert result["name"] == "Test Instance 1"

@pytest.mark.asyncio
async def test_get_instance_by_name_lower(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the get_instance_by_name method
    mock_client.get_instance_by_name = MagicMock(return_value=MOCK_INSTANCES["data"][0])
    
    result = await manager.get_instance_by_name("test instance")
    assert result["id"] == "instance-1"
    assert result["name"] == "Test Instance 1"


@pytest.mark.asyncio
async def test_list_tenants(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    result = await manager.list_tenants()
    assert "tenants" in result
    assert len(result["tenants"]) == 2
    assert result["count"] == 2


@pytest.mark.asyncio
async def test_error_handling(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock an error
    mock_client.get_instance_details = MagicMock(side_effect=Exception("Test error"))
    
    result = await manager.get_instance_details(["non-existent"])
    assert "error" in result
    assert "Test error" in result["error"]


@pytest.mark.asyncio
async def test_get_tenant_details(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    result = await manager.get_tenant_details("tenant-1")
    print(result)
    assert result["id"] == "tenant-1"
    assert "instance_configurations" in result
    assert len(result["instance_configurations"]) > 0


@pytest.mark.asyncio
async def test_pause_instance(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the pause_instance method
    mock_client.pause_instance = MagicMock(return_value={"status": "paused"})
    
    result = await manager.pause_instance("instance-1")
    assert result["status"] == "paused"

@pytest.mark.asyncio
async def test_update_instance_name(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the update_instance method
    mock_client.update_instance = MagicMock(return_value={"name": "New Name", "id": "instance-1"})
    
    result = await manager.update_instance_name("instance-1", "New Name")
    assert result["name"] == "New Name"
    assert result["id"] == "instance-1"

@pytest.mark.asyncio
async def test_create_instance(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the create_instance method
    mock_client.create_instance = MagicMock(return_value={
        "id": "new-instance-1",
        "name": "New Test Instance",
        "status": "creating"
    })
    
    result = await manager.create_instance(
        tenant_id="tenant-1",
        name="New Test Instance",
        memory=1,
        region="us-central1",
        type="free-db"
    )
    
    assert result["id"] == "new-instance-1"
    assert result["name"] == "New Test Instance"
    assert result["status"] == "creating"
    
    # Verify the mock was called with the correct parameters
    mock_client.create_instance.assert_called_once_with(
        tenant_id="tenant-1",
        name="New Test Instance",
        memory=1,
        region="us-central1",
        version="5",
        type="free-db",
        vector_optimized=False,
        cloud_provider="gcp",
        graph_analytics_plugin=False,
        source_instance_id=None
    )


@pytest.mark.asyncio
async def test_delete_instance(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the delete_instance method
    mock_client.delete_instance = MagicMock(return_value={"status": "deleted", "id": "instance-1"})
    
    result = await manager.delete_instance(instance_id="instance-1")
    assert result["id"] == "instance-1"
    
    # Verify the mock was called with the correct parameters
    mock_client.delete_instance.assert_called_once_with("instance-1")


@pytest.mark.asyncio
async def test_update_instance_name(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the update_instance method
    mock_client.update_instance = MagicMock(return_value={"name": "New Name", "id": "instance-1"})
    
    result = await manager.update_instance_name("instance-1", "New Name")
    assert result["name"] == "New Name"
    assert result["id"] == "instance-1"
    
    # Verify the mock was called with the correct parameters
    mock_client.update_instance.assert_called_once_with(instance_id="instance-1", name="New Name")


@pytest.mark.asyncio
async def test_pause_instance(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the pause_instance method
    mock_client.pause_instance = MagicMock(return_value={"status": "paused"})
    
    result = await manager.pause_instance("instance-1")
    assert result["status"] == "paused"
    
    # Verify the mock was called with the correct parameters
    mock_client.pause_instance.assert_called_once_with("instance-1")


@pytest.mark.asyncio
async def test_resume_instance(mock_client):
    manager = AuraManager("fake-id", "fake-secret")
    manager.client = mock_client
    
    # Mock the resume_instance method
    mock_client.resume_instance = MagicMock(return_value={"status": "running"})
    
    result = await manager.resume_instance("instance-1")
    assert result["status"] == "running"
    
    # Verify the mock was called with the correct parameters
    mock_client.resume_instance.assert_called_once_with("instance-1")
</file>

<file path="mcp-neo4j-cloud-aura-api/tests/unit/test_utils.py">
from mcp_neo4j_aura_manager.server import _validate_region
import pytest

def test_validate_region_aws_valid():
    # Test GCP regions
    assert _validate_region("aws", "us-east-1") is None
    assert _validate_region("aws", "eu-west-1") is None
    assert _validate_region("aws", "eu-east-1") is None

def test_validate_region_aws_invalid():
    # Test GCP regions
    with pytest.raises(ValueError):
        _validate_region("aws", "us-east1")
    with pytest.raises(ValueError):
        _validate_region("aws", "euwest")
    with pytest.raises(ValueError):
        _validate_region("aws", "eu-west-1-1-1")

def test_validate_region_gcp_valid():
    # Test GCP regions
    assert _validate_region("gcp", "us-central1") is None
    assert _validate_region("gcp", "europe-west1") is None
    assert _validate_region("gcp", "us-central2") is None

def test_validate_region_gcp_invalid():
    # Test GCP regions
    with pytest.raises(ValueError):
        _validate_region("gcp", "us-east-1")
    with pytest.raises(ValueError):
        _validate_region("gcp", "eu-west-1-1")
    with pytest.raises(ValueError):
        _validate_region("gcp", "euwest")

def test_validate_region_azure_valid():
    # Test Azure regions
    assert _validate_region("azure", "eastus") is None
    assert _validate_region("azure", "northeurope") is None

def test_validate_region_azure_invalid():
    # Test Azure regions
    with pytest.raises(ValueError):
        _validate_region("azure", "us-east-1")
    with pytest.raises(ValueError):
        _validate_region("azure", "eu-west1")
</file>

<file path="mcp-neo4j-cloud-aura-api/.dockerignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Git
.git
.gitignore

# Docker
Dockerfile
.dockerignore

# Documentation
docs/
*.md
!README.md
!pyproject.toml

# Tests
tests/
test/
testing/
</file>

<file path="mcp-neo4j-cloud-aura-api/CHANGELOG.md">
## Next

### Fixed

### Changed

### Added

## v0.3.0

### Changed
* Migrate to FastMCP v2.x

### Added
* Add HTTP transport option

## v0.2.2
...
</file>

<file path="mcp-neo4j-cloud-aura-api/Dockerfile">
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install build dependencies
RUN pip install --no-cache-dir hatchling

# Copy dependency files first
COPY pyproject.toml /app/

# Install runtime dependencies
RUN pip install --no-cache-dir fastmcp>=2.0.0 requests>=2.31.0

# Copy the source code
COPY src/ /app/src/
COPY README.md /app/

# Install the package
RUN pip install --no-cache-dir -e .

# Environment variables for Neo4j Aura API credentials
ENV NEO4J_AURA_CLIENT_ID=""
ENV NEO4J_AURA_CLIENT_SECRET=""
ENV NEO4J_TRANSPORT="http"
ENV NEO4J_MCP_SERVER_HOST="127.0.0.1"
ENV NEO4J_MCP_SERVER_PORT=8000
ENV NEO4J_MCP_SERVER_PATH="/mcp/"

# Command to run the server using the package entry point
CMD ["sh", "-c", "mcp-neo4j-aura-manager"]
</file>

<file path="mcp-neo4j-cloud-aura-api/Makefile">
install-dev:
	uv sync

test-unit:
	uv run pytest tests/unit/ -v

test-integration:
	uv run pytest tests/integration/ -v

test-http:
	uv run pytest tests/integration/test_http_transport.py -v

test-all:
	uv run pytest tests/ -v

all: install-dev test-all
</file>

<file path="mcp-neo4j-cloud-aura-api/pyproject.toml">
[project]
name = "mcp-neo4j-aura-manager"
version = "0.3.0"
description = "MCP Neo4j Aura Database Instance Manager"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastmcp>=2.0.0",
    "requests>=2.31.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
    "pyright>=1.1.389",
    "pytest>=8.3.5",
    "pytest-asyncio>=0.25.3",
    "aiohttp>=3.8.0",
]

[project.scripts]
mcp-neo4j-aura-manager = "mcp_neo4j_aura_manager:main"

[tool.pytest.ini_options]
pythonpath = [
  "src"
]
</file>

<file path="mcp-neo4j-cloud-aura-api/README.md">
# 🚀💖☁️ Neo4j Aura Database Manager MCP Server

## 🌟 Overview

A Model Context Protocol (MCP) server implementation that provides tools for managing Neo4j Aura database instances through the Neo4j Aura API.

This server allows you to create, monitor, and manage Neo4j Aura instances directly through Claude, making it easy to provision and maintain your graph database infrastructure.

## 🔑 Authentication

Authentication with the Neo4j Aura API requires:
- Client ID
- Client Secret

You can obtain these credentials from the Neo4j Aura console, see the [documentation of the Aura API](https://neo4j.com/docs/aura/classic/platform/api/overview/)

Here is the [API Specification](https://neo4j.com/docs/aura/platform/api/specification/)

## 📦 Components

### 🔧 Tools

The server offers these core tools:

#### 🛠️ Instance Management
- `list_instances`
  - List all Neo4j Aura database instances
  - No input required
  - Returns: List of all instances with their details

- `get_instance_details`
  - Get details for a specific instance or multiple instances by ID
  - Input:
    - `instance_ids` (string or array): ID of the instance to retrieve, or array of instance IDs
  - Returns: Detailed information about the instance(s)

- `get_instance_by_name`
  - Find an instance by name
  - Input:
    - `name` (string): Name of the instance to find
  - Returns: Instance details if found

- `create_instance`
  - Create a new Neo4j Aura database instance
  - Input:
    - `tenant_id` (string): ID of the tenant/project where the instance will be created
    - `name` (string): Name for the new instance
    - `memory` (integer): Memory allocation in GB
    - `region` (string): Region for the instance (e.g., 'us-east-1')
    - `version` (string): Neo4j version (e.g., '5.15')
    - `type` (string, optional): Instance type (enterprise or professional)
    - `vector_optimized` (boolean, optional): Whether the instance is optimized for vector operations
  - Returns: Created instance details

- `update_instance_name`
  - Update the name of an instance
  - Input:
    - `instance_id` (string): ID of the instance to update
    - `name` (string): New name for the instance
  - Returns: Updated instance details

- `update_instance_memory`
  - Update the memory allocation of an instance
  - Input:
    - `instance_id` (string): ID of the instance to update
    - `memory` (integer): New memory allocation in GB
  - Returns: Updated instance details

- `update_instance_vector_optimization`
  - Update the vector optimization setting of an instance
  - Input:
    - `instance_id` (string): ID of the instance to update
    - `vector_optimized` (boolean): Whether the instance should be optimized for vector operations
  - Returns: Updated instance details

- `pause_instance`
  - Pause a database instance
  - Input:
    - `instance_id` (string): ID of the instance to pause
  - Returns: Instance status information

- `resume_instance`
  - Resume a paused database instance
  - Input:
    - `instance_id` (string): ID of the instance to resume
  - Returns: Instance status information

- `delete_instance`
  - Delete a database instance
  - Input:
    - `tenant_id` (string): ID of the tenant/project where the instance exists
    - `instance_id` (string): ID of the instance to delete
  - Returns: Deletion status information

#### 🏢 Tenant/Project Management
- `list_tenants`
  - List all Neo4j Aura tenants/projects
  - No input required
  - Returns: List of all tenants with their details

- `get_tenant_details`
  - Get details for a specific tenant/project
  - Input:
    - `tenant_id` (string): ID of the tenant/project to retrieve
  - Returns: Detailed information about the tenant/project


## 🔧 Usage with Claude Desktop

### 💾 Installation

```bash
pip install mcp-neo4j-aura-manager
```

### ⚙️ Configuration

Add the server to your `claude_desktop_config.json`:

```json
"mcpServers": {
  "neo4j-aura": {
    "command": "uvx",
    "args": [
      "mcp-neo4j-aura-manager@0.3.0",
      "--client-id",
      "<your-client-id>",
      "--client-secret",
      "<your-client-secret>"
      ]
  }
}
```

Alternatively, you can set environment variables:

```json
"mcpServers": {
  "neo4j-aura": {
    "command": "uvx",
    "args": [ "mcp-neo4j-aura-manager@0.3.0" ],
    "env": {
      "NEO4J_AURA_CLIENT_ID": "<your-client-id>",
      "NEO4J_AURA_CLIENT_SECRET": "<your-client-secret>"
    }
  }
}
```

### 🐳 Using with Docker

```json
"mcpServers": {
  "neo4j-aura": {
    "command": "docker",
    "args": [
      "run",
      "--rm",
      "-e", "NEO4J_AURA_CLIENT_ID=${NEO4J_AURA_CLIENT_ID}",
      "-e", "NEO4J_AURA_CLIENT_SECRET=${NEO4J_AURA_CLIENT_SECRET}",
      "mcp-neo4j-aura-manager:0.3.0"
    ]
  }
}
```

### 🌐 HTTP Transport Mode

The server supports HTTP transport for web-based deployments and microservices:

```bash
# Basic HTTP mode (defaults: host=127.0.0.1, port=8000, path=/mcp/)
mcp-neo4j-aura-manager --transport http

# Custom HTTP configuration
mcp-neo4j-aura-manager --transport http --host 0.0.0.0 --port 8080 --path /api/mcp/
```

Environment variables for HTTP configuration:

```bash
export NEO4J_TRANSPORT=http
export NEO4J_MCP_SERVER_HOST=0.0.0.0
export NEO4J_MCP_SERVER_PORT=8080
export NEO4J_MCP_SERVER_PATH=/api/mcp/
mcp-neo4j-aura-manager
```

### 🔄 Transport Modes

The server supports three transport modes:

- **STDIO** (default): Standard input/output for local tools and Claude Desktop
- **SSE**: Server-Sent Events for web-based deployments  
- **HTTP**: Streamable HTTP for modern web deployments and microservices

## 📝 Usage Examples

### 🔍 Give overview over my tenants

![](docs/images/mcp-aura-tenant-overview.png)

### 🔎 Find an instance by name

![](docs/images/mcp-aura-find-by-name.png)

### 📋 List instances and find paused instance
![](docs/images/mcp-aura-find-paused.png)

### ▶️ Resume paused instances
![](docs/images/mcp-aura-list-resume.png)

### ➕ Create a new instance

![](docs/images/mcp-aura-create-instance.png)

## 🚀 Development

### 📦 Prerequisites

1. Install `uv` (Universal Virtualenv):
```bash
# Using pip
pip install uv

# Using Homebrew on macOS
brew install uv

# Using cargo (Rust package manager)
cargo install uv
```

2. Clone the repository and set up development environment:
```bash
# Clone the repository
git clone https://github.com/yourusername/mcp-neo4j-aura-manager.git
cd mcp-neo4j-aura-manager

# Create and activate virtual environment using uv
uv venv
source .venv/bin/activate  # On Unix/macOS
.venv\Scripts\activate     # On Windows

# Install dependencies including dev dependencies
uv pip install -e ".[dev]"
```

### 🐳 Docker

Build and run the Docker container:

```bash
# Build the image
docker build -t mcp-neo4j-aura-manager:<version> .

# Run the container
docker run -e NEO4J_AURA_CLIENT_ID="your-client-id" \
          -e NEO4J_AURA_CLIENT_SECRET="your-client-secret" \
          mcp-neo4j-aura-manager:<version>
```

## 📄 License

This MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.
</file>

<file path="mcp-neo4j-cloud-aura-api/test.sh">
if [ -f .env ]; then
    uv run --env-file .env pytest tests
else
    uv run pytest tests
fi
</file>

<file path="mcp-neo4j-cypher/src/mcp_neo4j_cypher/__init__.py">
import argparse
import asyncio
import os

from . import server


def main():
    """Main entry point for the package."""
    parser = argparse.ArgumentParser(description="Neo4j Cypher MCP Server")
    parser.add_argument("--db-url", default=None, help="Neo4j connection URL")
    parser.add_argument("--username", default=None, help="Neo4j username")
    parser.add_argument("--password", default=None, help="Neo4j password")
    parser.add_argument("--database", default=None, help="Neo4j database name")
    parser.add_argument("--transport", default=None, help="Transport type (stdio, sse, http)")
    parser.add_argument("--namespace", default=None, help="Tool namespace")
    parser.add_argument("--server-path", default=None, help="HTTP path (default: /mcp/)")
    parser.add_argument("--server-host", default=None, help="Server host")
    parser.add_argument("--server-port", default=None, help="Server port")

    args = parser.parse_args()
    asyncio.run(
        server.main(
            args.db_url or os.getenv("NEO4J_URL") or os.getenv("NEO4J_URI", "bolt://localhost:7687"),
            args.username or os.getenv("NEO4J_USERNAME", "neo4j"),
            args.password or os.getenv("NEO4J_PASSWORD", "password"),
            args.database or os.getenv("NEO4J_DATABASE", "neo4j"),
            args.transport or os.getenv("NEO4J_TRANSPORT", "stdio"),
            args.namespace or os.getenv("NEO4J_NAMESPACE", ""),
            args.server_host or os.getenv("NEO4J_MCP_SERVER_HOST", "127.0.0.1"),
            args.server_port or int(os.getenv("NEO4J_MCP_SERVER_PORT", "8000")),
            args.server_path or os.getenv("NEO4J_MCP_SERVER_PATH", "/mcp/"),
        )
    )


__all__ = ["main", "server"]
</file>

<file path="mcp-neo4j-cypher/src/mcp_neo4j_cypher/server.py">
import json
import logging
import re
from typing import Any, Literal, Optional

from fastmcp.exceptions import ToolError
from fastmcp.tools.tool import ToolResult, TextContent
from fastmcp.server import FastMCP
from mcp.types import ToolAnnotations
from neo4j import (
    AsyncDriver,
    AsyncGraphDatabase,
    AsyncResult,
    AsyncTransaction,
)
from neo4j.exceptions import ClientError, Neo4jError
from pydantic import Field

logger = logging.getLogger("mcp_neo4j_cypher")

def _format_namespace(namespace: str) -> str:
    if namespace:
        if namespace.endswith("-"):
            return namespace
        else:
            return namespace + "-"
    else:
        return ""

async def _read(tx: AsyncTransaction, query: str, params: dict[str, Any]) -> str:
    raw_results = await tx.run(query, params)
    eager_results = await raw_results.to_eager_result()

    return json.dumps([r.data() for r in eager_results.records], default=str)


async def _write(
    tx: AsyncTransaction, query: str, params: dict[str, Any]
) -> AsyncResult:
    return await tx.run(query, params)


def _is_write_query(query: str) -> bool:
    """Check if the query is a write query."""
    return (
        re.search(r"\b(MERGE|CREATE|SET|DELETE|REMOVE|ADD)\b", query, re.IGNORECASE)
        is not None
    )


def create_mcp_server(neo4j_driver: AsyncDriver, database: str = "neo4j", namespace: str = "") -> FastMCP:
    mcp: FastMCP = FastMCP("mcp-neo4j-cypher", dependencies=["neo4j", "pydantic"], stateless_http=True)

    namespace_prefix = _format_namespace(namespace)

    @mcp.tool(name=namespace_prefix+"get_neo4j_schema", 
              annotations=ToolAnnotations(title="Get Neo4j Schema", 
                                          readOnlyHint=True,
                                          destructiveHint=False,
                                          idempotentHint=True,
                                          openWorldHint=True
                                          )
            )
    async def get_neo4j_schema() -> list[ToolResult]:
        """
        List all nodes, their attributes and their relationships to other nodes in the neo4j database.
        This requires that the APOC plugin is installed and enabled.
        """

        get_schema_query = """
        CALL apoc.meta.schema();
        """

        def clean_schema(schema: dict) -> dict:
            cleaned = {}

            for key, entry in schema.items():

                new_entry = {
                    "type": entry["type"]
                }
                if "count" in entry:
                    new_entry["count"] = entry["count"]

                labels = entry.get("labels", [])
                if labels:
                    new_entry["labels"] = labels

                props = entry.get("properties", {})
                clean_props = {}
                for pname, pinfo in props.items():
                    cp = {}
                    if "indexed" in pinfo:
                        cp["indexed"] = pinfo["indexed"]
                    if "type" in pinfo:
                        cp["type"] = pinfo["type"]
                    if cp:
                        clean_props[pname] = cp
                if clean_props:
                    new_entry["properties"] = clean_props

                if entry.get("relationships"):
                    rels_out = {}
                    for rel_name, rel in entry["relationships"].items():
                        cr = {}
                        if "direction" in rel:
                            cr["direction"] = rel["direction"]
                        # nested labels
                        rlabels = rel.get("labels", [])
                        if rlabels:
                            cr["labels"] = rlabels
                        # nested properties
                        rprops = rel.get("properties", {})
                        clean_rprops = {}
                        for rpname, rpinfo in rprops.items():
                            crp = {}
                            if "indexed" in rpinfo:
                                crp["indexed"] = rpinfo["indexed"]
                            if "type" in rpinfo:
                                crp["type"] = rpinfo["type"]
                            if crp:
                                clean_rprops[rpname] = crp
                        if clean_rprops:
                            cr["properties"] = clean_rprops

                        if cr:
                            rels_out[rel_name] = cr

                    if rels_out:
                        new_entry["relationships"] = rels_out

                cleaned[key] = new_entry

            return cleaned


        try:
            async with neo4j_driver.session(database=database) as session:
                results_json_str = await session.execute_read(
                    _read, get_schema_query, dict()
                )

                logger.debug(f"Read query returned {len(results_json_str)} rows")

                schema = json.loads(results_json_str)[0].get('value')
                schema_clean = clean_schema(schema)
                schema_clean_str = json.dumps(schema_clean)

                return ToolResult(content=[TextContent(type="text", text=schema_clean_str)])
        
        except ClientError as e:
            if "Neo.ClientError.Procedure.ProcedureNotFound" in str(e):
                raise ToolError("Neo4j Client Error: This instance of Neo4j does not have the APOC plugin installed. Please install and enable the APOC plugin to use the `get_neo4j_schema` tool.")
            else:
                raise ToolError(f"Neo4j Client Error: {e}")
        
        except Neo4jError as e:
            raise ToolError(f"Neo4j Error: {e}")
    
        except Exception as e:
            logger.error(f"Error retrieving Neo4j database schema: {e}")
            raise ToolError(f"Unexpected Error: {e}")

    @mcp.tool(name=namespace_prefix+"read_neo4j_cypher", 
              annotations=ToolAnnotations(title="Read Neo4j Cypher", 
                                          readOnlyHint=True,
                                          destructiveHint=False,
                                          idempotentHint=True,
                                          openWorldHint=True
                                          ))
    async def read_neo4j_cypher(
        query: str = Field(..., description="The Cypher query to execute."),
        params: dict[str, Any] = Field(
            dict(), description="The parameters to pass to the Cypher query."
        ),
    ) -> list[ToolResult]:
        """Execute a read Cypher query on the neo4j database."""

        if _is_write_query(query):
            raise ValueError("Only MATCH queries are allowed for read-query")

        try:
            async with neo4j_driver.session(database=database) as session:
                results_json_str = await session.execute_read(_read, query, params)

                logger.debug(f"Read query returned {len(results_json_str)} rows")

                return ToolResult(content=[TextContent(type="text", text=results_json_str)])
                    
        except Neo4jError as e:
            logger.error(f"Neo4j Error executing read query: {e}\n{query}\n{params}")
            raise ToolError(f"Neo4j Error: {e}\n{query}\n{params}")
    
        except Exception as e:
            logger.error(f"Error executing read query: {e}\n{query}\n{params}")
            raise ToolError(f"Error: {e}\n{query}\n{params}")

    @mcp.tool(name=namespace_prefix+"write_neo4j_cypher", 
              annotations=ToolAnnotations(title="Write Neo4j Cypher", 
                                          readOnlyHint=False,
                                          destructiveHint=True,
                                          idempotentHint=False,
                                          openWorldHint=True
                                          ))
    async def write_neo4j_cypher(
        query: str = Field(..., description="The Cypher query to execute."),
        params: dict[str, Any] = Field(
            dict(), description="The parameters to pass to the Cypher query."
        ),
    ) -> list[ToolResult]:
        """Execute a write Cypher query on the neo4j database."""

        if not _is_write_query(query):
            raise ValueError("Only write queries are allowed for write-query")

        try:
            async with neo4j_driver.session(database=database) as session:
                raw_results = await session.execute_write(_write, query, params)
                counters_json_str = json.dumps(
                    raw_results._summary.counters.__dict__, default=str
                )

            logger.debug(f"Write query affected {counters_json_str}")

            return ToolResult(content=[TextContent(type="text", text=counters_json_str)])

        except Neo4jError as e:
            logger.error(f"Neo4j Error executing write query: {e}\n{query}\n{params}")
            raise ToolError(f"Neo4j Error: {e}\n{query}\n{params}")
    
        except Exception as e:
            logger.error(f"Error executing write query: {e}\n{query}\n{params}")
            raise ToolError(f"Error: {e}\n{query}\n{params}")

    return mcp


async def main(
    db_url: str,
    username: str,
    password: str,
    database: str,
    transport: Literal["stdio", "sse", "http"] = "stdio",
    namespace: str = "",
    host: str = "127.0.0.1",
    port: int = 8000,
    path: str = "/mcp/",
) -> None:
    logger.info("Starting MCP neo4j Server")

    neo4j_driver = AsyncGraphDatabase.driver(
        db_url,
        auth=(
            username,
            password,
        ),
    )

    mcp = create_mcp_server(neo4j_driver, database, namespace)

    # Run the server with the specified transport
    match transport:
        case "http":
            logger.info(f"Running Neo4j Cypher MCP Server with HTTP transport on {host}:{port}...")
            await mcp.run_http_async(host=host, port=port, path=path)
        case "stdio":
            logger.info("Running Neo4j Cypher MCP Server with stdio transport...")
            await mcp.run_stdio_async()
        case "sse":
            logger.info(f"Running Neo4j Cypher MCP Server with SSE transport on {host}:{port}...")
            await mcp.run_sse_async(host=host, port=port, path=path)
        case _:
            logger.error(f"Invalid transport: {transport} | Must be either 'stdio', 'sse', or 'http'")
            raise ValueError(f"Invalid transport: {transport} | Must be either 'stdio', 'sse', or 'http'")


if __name__ == "__main__":
    main()
</file>

<file path="mcp-neo4j-cypher/tests/integration/conftest.py">
import os
import asyncio
import subprocess
from typing import Any

import pytest
import pytest_asyncio
from neo4j import AsyncGraphDatabase
from testcontainers.neo4j import Neo4jContainer


from mcp_neo4j_cypher.server import create_mcp_server

neo4j = (
    Neo4jContainer("neo4j:latest")
    .with_env("NEO4J_apoc_export_file_enabled", "true")
    .with_env("NEO4J_apoc_import_file_enabled", "true")
    .with_env("NEO4J_apoc_import_file_use__neo4j__config", "true")
    .with_env("NEO4J_PLUGINS", '["apoc"]')
)


@pytest.fixture(scope="module", autouse=True)
def setup(request):
    neo4j.start()

    def remove_container():
        neo4j.get_driver().close()
        neo4j.stop()

    request.addfinalizer(remove_container)
    os.environ["NEO4J_URI"] = neo4j.get_connection_url()
    os.environ["NEO4J_HOST"] = neo4j.get_container_host_ip()
    os.environ["NEO4J_PORT"] = neo4j.get_exposed_port(7687)

    yield neo4j


@pytest_asyncio.fixture(scope="function")
async def async_neo4j_driver(setup: Neo4jContainer):
    driver = AsyncGraphDatabase.driver(
        setup.get_connection_url(), auth=(setup.username, setup.password)
    )
    try:
        yield driver
    finally:
        await driver.close()


@pytest_asyncio.fixture(scope="function")
async def mcp_server(async_neo4j_driver):
    mcp = create_mcp_server(async_neo4j_driver, "neo4j")

    return mcp


@pytest.fixture(scope="function")
def init_data(setup: Neo4jContainer, clear_data: Any):
    with setup.get_driver().session(database="neo4j") as session:
        session.run("CREATE (a:Person {name: 'Alice', age: 30})")
        session.run("CREATE (b:Person {name: 'Bob', age: 25})")
        session.run("CREATE (c:Person {name: 'Charlie', age: 35})")
        session.run(
            "MATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'}) CREATE (a)-[:FRIEND]->(b)"
        )
        session.run(
            "MATCH (b:Person {name: 'Bob'}), (c:Person {name: 'Charlie'}) CREATE (b)-[:FRIEND]->(c)"
        )


@pytest.fixture(scope="function")
def clear_data(setup: Neo4jContainer):
    with setup.get_driver().session(database="neo4j") as session:
        session.run("MATCH (n) DETACH DELETE n")



@pytest_asyncio.fixture
async def sse_server(setup: Neo4jContainer):
    """Start the MCP server in SSE mode."""

    
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-cypher", 
        "--transport", "sse", 
        "--server-host", "127.0.0.1", 
        "--server-port", "8002",
        "--db-url", setup.get_connection_url(),
        "--username", setup.username,
        "--password", setup.password,
        "--database", "neo4j",
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    await asyncio.sleep(3)
    
    if process.returncode is not None:
        stdout, stderr = await process.communicate()
        raise RuntimeError(f"Server failed to start. stdout: {stdout.decode()}, stderr: {stderr.decode()}")
    
    yield process
    
    try:
        process.terminate()
        await asyncio.wait_for(process.wait(), timeout=5.0)
    except asyncio.TimeoutError:
        process.kill()
        await process.wait()

@pytest_asyncio.fixture
async def http_server(setup: Neo4jContainer):
    """Start the MCP server in HTTP mode."""
    
    # Start server process in HTTP mode using the installed binary
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-cypher", 
        "--transport", "http", 
        "--server-host", "127.0.0.1", 
        "--server-port", "8001",
        "--db-url", setup.get_connection_url(),
        "--username", setup.username,
        "--password", setup.password,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    # Wait for server to start
    await asyncio.sleep(3)
    
    # Check if process is still running
    if process.returncode is not None:
        stdout, stderr = await process.communicate()
        raise RuntimeError(f"Server failed to start. stdout: {stdout.decode()}, stderr: {stderr.decode()}")
    
    yield process
    
    # Cleanup
    try:
        process.terminate()
        await asyncio.wait_for(process.wait(), timeout=5.0)
    except asyncio.TimeoutError:
        process.kill()
        await process.wait()
</file>

<file path="mcp-neo4j-cypher/tests/integration/test_http_transport_IT.py">
import asyncio
import json
import os
import pytest
import aiohttp
import subprocess
import uuid




async def parse_sse_response(response: aiohttp.ClientResponse) -> dict:
    """Parse Server-Sent Events response from FastMCP 2.0."""
    content = await response.text()
    lines = content.strip().split('\n')
    
    # Find the data line that contains the JSON
    for line in lines:
        if line.startswith('data: '):
            json_str = line[6:]  # Remove 'data: ' prefix
            return json.loads(json_str)
    
    raise ValueError("No data line found in SSE response")


@pytest.mark.asyncio
async def test_http_tools_list(http_server):
    """Test that tools/list endpoint works over HTTP."""
    session_id = str(uuid.uuid4())
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/list"
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
        ) as response:
            print(f"Response status: {response.status}")
            print(f"Response headers: {dict(response.headers)}")
            response_text = await response.text()
            print(f"Response text: {response_text}")
            
            assert response.status == 200
            result = await parse_sse_response(response)
            assert "result" in result
            assert "tools" in result["result"]
            tools = result["result"]["tools"]
            assert len(tools) > 0
            tool_names = [tool["name"] for tool in tools]
            assert "get_neo4j_schema" in tool_names
            assert "read_neo4j_cypher" in tool_names
            assert "write_neo4j_cypher" in tool_names

@pytest.mark.asyncio
async def test_http_get_schema(http_server):
    """Test that get_neo4j_schema works over HTTP."""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {
                    "name": "get_neo4j_schema",
                    "arguments": {}
                }
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            assert "result" in result
            assert "content" in result["result"]
            assert len(result["result"]["content"]) > 0

@pytest.mark.asyncio
async def test_http_write_query(http_server):
    """Test that write_neo4j_cypher works over HTTP."""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {
                    "name": "write_neo4j_cypher",
                    "arguments": {
                        "query": "CREATE (n:Test {name: 'http_test'})"
                    }
                }
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            assert "result" in result
            assert "content" in result["result"]

@pytest.mark.asyncio
async def test_http_read_query(http_server):
    """Test that read_neo4j_cypher works over HTTP."""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {
                    "name": "read_neo4j_cypher",
                    "arguments": {
                        "query": "MATCH (n:Test) RETURN n.name as name"
                    }
                }
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            assert "result" in result
            assert "content" in result["result"]

@pytest.mark.asyncio
async def test_http_invalid_method(http_server):
    """Test handling of invalid method over HTTP."""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "invalid_method"
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            # Accept either JSON-RPC error or result with isError
            assert ("result" in result and result["result"].get("isError", False)) or ("error" in result)

@pytest.mark.asyncio
async def test_http_invalid_tool(http_server):
    """Test handling of invalid tool over HTTP."""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {
                    "name": "invalid_tool",
                    "arguments": {}
                }
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            # FastMCP returns errors in result field with isError: True
            assert "result" in result
            assert result["result"].get("isError", False)


    




@pytest.mark.asyncio
async def test_http_full_workflow(http_server):
    """Test complete workflow over HTTP transport."""

    async with aiohttp.ClientSession() as session:
        # 1. List tools
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/list"
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            assert "result" in result

        # 2. Write data
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 2,
                "method": "tools/call",
                "params": {
                    "name": "write_neo4j_cypher",
                    "arguments": {
                        "query": "CREATE (n:IntegrationTest {name: 'workflow_test'})"
                    }
                }
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            assert "result" in result

        # 3. Read data
        async with session.post(
            "http://127.0.0.1:8001/mcp/",
            json={
                "jsonrpc": "2.0",
                "id": 3,
                "method": "tools/call",
                "params": {
                    "name": "read_neo4j_cypher",
                    "arguments": {
                        "query": "MATCH (n:IntegrationTest) RETURN n.name as name"
                    }
                }
            },
            headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": "test-session"}
        ) as response:
            result = await parse_sse_response(response)
            assert response.status == 200
            assert "result" in result
</file>

<file path="mcp-neo4j-cypher/tests/integration/test_server_tools_IT.py">
import json
from typing import Any

import pytest
from fastmcp.server import FastMCP


@pytest.mark.asyncio(loop_scope="function")
async def test_get_neo4j_schema(mcp_server: FastMCP, init_data: Any):
    tool = await mcp_server.get_tool("get_neo4j_schema")
    response = await tool.run(dict())

    schema = json.loads(response.content[0].text)
    
    # Verify the schema result
    assert "Person" in schema
    assert schema['Person']['count'] == 3
    assert len(schema['Person']['properties']) == 2
    assert "FRIEND" in schema['Person']['relationships']
    


@pytest.mark.asyncio(loop_scope="function")
async def test_write_neo4j_cypher(mcp_server: FastMCP):
    query = "CREATE (n:Test {name: 'test', age: 123}) RETURN n.name"
    tool = await mcp_server.get_tool("write_neo4j_cypher")
    response = await tool.run(dict(query=query))

    result = json.loads(response.content[0].text)

    assert "nodes_created" in result
    assert "labels_added" in result
    assert "properties_set" in result
    assert result["nodes_created"] == 1
    assert result["labels_added"] == 1
    assert result["properties_set"] == 2


@pytest.mark.asyncio(loop_scope="function")
async def test_read_neo4j_cypher(mcp_server: FastMCP, init_data: Any):
    query = """
    MATCH (p:Person)-[:FRIEND]->(friend)
    RETURN p.name AS person, friend.name AS friend_name
    ORDER BY p.name, friend.name
    """

    tool = await mcp_server.get_tool("read_neo4j_cypher")
    response = await tool.run(dict(query=query))

    result = json.loads(response.content[0].text)

    assert len(result) == 2
    assert result[0]["person"] == "Alice"
    assert result[0]["friend_name"] == "Bob"
    assert result[1]["person"] == "Bob"
    assert result[1]["friend_name"] == "Charlie"
</file>

<file path="mcp-neo4j-cypher/tests/integration/test_sse_transport_IT.py">
import aiohttp
import pytest


@pytest.mark.asyncio
async def test_sse_endpoint(sse_server):
    """Test that SSE endpoint is accessible."""
    async with aiohttp.ClientSession() as session:
        async with session.get("http://127.0.0.1:8002/mcp/") as response:
            # SSE endpoint should be accessible
            assert response.status in [200, 404]  # 404 is okay if no specific endpoint
</file>

<file path="mcp-neo4j-cypher/tests/integration/test_stdio_transport_IT.py">
import asyncio
import os
import subprocess

import pytest
from testcontainers.neo4j import Neo4jContainer




@pytest.mark.asyncio
async def test_stdio_transport(setup: Neo4jContainer):
    """Test that stdio transport can be started."""
    
    # Test that stdio transport can be started (it should not crash)
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-cypher", 
        "--transport", "stdio",
        "--db-url", setup.get_connection_url(),
        "--username", setup.username,
        "--password", setup.password,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    # Give it a moment to start
    await asyncio.sleep(1)
    
    # Check if process is still running before trying to terminate
    if process.returncode is None:
        # Process is still running, terminate it
        try:
            process.terminate()
            await asyncio.wait_for(process.wait(), timeout=5.0)
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
    else:
        # Process has already exited, which is fine for this test
        # We just want to verify it didn't crash immediately
        pass
    
    # Process should have started successfully (no immediate crash)
    # If returncode is None, it means the process was still running when we tried to terminate it
    # If returncode is not None, it means the process exited (which is also acceptable for this test)
    assert True  # If we get here, the process started without immediate crash
</file>

<file path="mcp-neo4j-cypher/.dockerignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Git
.git
.gitignore

# Docker
Dockerfile
.dockerignore

# Documentation
docs/
*.md
!README.md
!pyproject.toml

# Tests
tests/
test/
testing/
</file>

<file path="mcp-neo4j-cypher/.flake8">
[flake8]
exclude =
	.git,
	__pycache__,
	build,
	dist,
	.tox,
	venv,
	.venv,
	.pytest_cache
max-line-length = 120
</file>

<file path="mcp-neo4j-cypher/.python-version">
3.12.7
</file>

<file path="mcp-neo4j-cypher/CHANGELOG.md">
## Next

### Fixed

### Changed

### Added

## v0.3.0

### Fixed
* Updated the `get_neo4j_schema` tool to include Relationship properties as well
* Fix bug where `params` arg wouldn't be parsed correctly

### Changed
* Update error handling in read and write tools
* Update `get_neo4j_schema` tool description
* Update `get_neo4j_schema` tool to catch missing apoc plugin error explicitly and provide guidance to client and user
* Update error handling for tools to explicitly catch and return Neo4j based errors with details

### Added
* Add .dxt file for Cypher MCP server
* Add .dxt file generation to Cypher MCP Publish GitHub action
* Add HTTP transport option
* Migrate to FastMCP v2.x
* Add tool annotations
* Update Dockerfile for http configuration

## v0.2.4

### Fixed
* Fixed Cypher MCP Docker deployments by allowing user to declare NEO4J_MCP_SERVER_HOST and NEO4J_MCP_SERVER_PORT. Can now declare NEO4J_MCP_SERVER_HOST=0.0.0.0 to use Docker hosted Cypher MCP server.

### Added
* NEO4J_MCP_SERVER_HOST and NEO4J_MCP_SERVER_PORT env variables
* --server-host and --server-port cli variables

## v0.2.3

### Added
* Namespace option via CLI or env variables. This allows many Cypher MCP servers to be used at once.
* Allow transport to be specified via env variables

## v0.2.2 

### Fixed

* IT no longer has risk of affecting locally deployed Neo4j instances
* Env config now supports NEO4J_URI and NEO4J_URL variables
* Fixed async issues with main server function not being async

### Changed

* IT now uses Testcontainers library instead of Docker scripts 
* Remove healthcheck from main function

### Added
* Support for transport config in cli args

## v0.2.1

### Fixed

* Fixed MCP version notation for declaration in config files - README

## v0.2.0

### Changed

* Refactor mcp-neo4j-cypher to use the FastMCP class
* Implement Neo4j async driver
* Tool responses now return JSON serialized results
* Update README with new config options 
* Update integration tests

### Added

* Add support for environment variables
* Add Github workflow to test and format mcp-neo4j-cypher


## v0.1.1

...
</file>

<file path="mcp-neo4j-cypher/docker-compose.yml">
services:
  # Deploy Neo4j Database (optional)
  neo4j:
    image: neo4j:5.26.1 # or another version
    environment:
      - NEO4J_AUTH=neo4j/password
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data

  # Deploy Cypher MCP Server
  mcp-neo4j-cypher-server:
    image: mcp/neo4j-cypher:latest
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://host.docker.internal:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=password
      - NEO4J_DATABASE=neo4j
      - NEO4J_TRANSPORT=http
      - NEO4J_MCP_SERVER_HOST=0.0.0.0 # must be 0.0.0.0 for sse transport in Docker
      - NEO4J_MCP_SERVER_PORT=8000
      - NEO4J_MCP_SERVER_PATH=/api/mcp/
      - NEO4J_NAMESPACE=local
    depends_on:
      - neo4j

volumes:
  neo4j_data:
</file>

<file path="mcp-neo4j-cypher/Dockerfile">
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install build dependencies
RUN pip install --no-cache-dir hatchling

COPY pyproject.toml /app/

# Install dependencies
RUN pip install --no-cache-dir neo4j>=5.26.0 fastmcp>=2.10.5


# Copy the source code
COPY src/ /app/src/
COPY README.md /app/

RUN pip install --no-cache-dir -e .

# Environment variables for Neo4j connection
ENV NEO4J_URI="bolt://host.docker.internal:7687"
ENV NEO4J_USERNAME="neo4j"
ENV NEO4J_PASSWORD="password"
ENV NEO4J_DATABASE="neo4j"
ENV NEO4J_NAMESPACE=""
ENV NEO4J_TRANSPORT="http"
ENV NEO4J_MCP_SERVER_HOST="0.0.0.0"
ENV NEO4J_MCP_SERVER_PORT="8000"
ENV NEO4J_MCP_SERVER_PATH="/api/mcp/"

EXPOSE 8000

# Command to run the server using the package entry point
CMD ["mcp-neo4j-cypher"]
</file>

<file path="mcp-neo4j-cypher/inspector.sh">
# test mcp-neo4j-cypher with a local database and Inspector
npx @modelcontextprotocol/inspector uv --directory src/mcp_neo4j_cypher run mcp-neo4j-cypher --db-url bolt://localhost:7687 --username neo4j --password password --database neo4j
</file>

<file path="mcp-neo4j-cypher/Makefile">
install-dev:
	uv sync

test-unit:
	uv run pytest tests/unit/ -v

test-integration:
	uv run pytest tests/integration/ -v

test-http:
	uv run pytest tests/integration/test_http_transport.py -v

test-all:
	uv run pytest tests/ -v

all: install-dev test-all
</file>

<file path="mcp-neo4j-cypher/manifest.json">
{
  "dxt_version": "0.1",
  "name": "mcp-neo4j-cypher",
  "display_name": "Neo4j Cypher MCP Server",
  "version": "0.3.0",
  "description": "Execute read and write Cypher queries on your Neo4j database.",
  "long_description": "A Model Context Protocol (MCP) server that provides tools for interacting with Neo4j graph databases using Cypher queries. Supports both read and write operations with proper validation and error handling.",
  "author": {
    "name": "Alexander Gilmore"
  },
  "keywords": ["neo4j", "cypher", "graph", "database", "mcp", "ai", "llm"],
  "categories": ["database", "graph", "query"],
  "repository": {
    "type": "git",
    "url": "https://github.com/neo4j-contrib/mcp-neo4j/tree/main/servers/mcp-neo4j-cypher"
  },
  "documentation": "https://github.com/neo4j-contrib/mcp-neo4j/blob/main/servers/mcp-neo4j-cypher/README.md",
  "support": "https://github.com/neo4j-contrib/mcp-neo4j/issues",
  "server": {
    "type": "python",
    "entry_point": "src/mcp_neo4j_cypher/__init__.py",
    "mcp_config": {
      "command": "uvx",
      "args": ["mcp-neo4j-cypher"],
      "env": {
        "NEO4J_URI": "${user_config.neo4j_uri}",
        "NEO4J_USERNAME": "${user_config.neo4j_username}",
        "NEO4J_PASSWORD": "${user_config.neo4j_password}",
        "NEO4J_DATABASE": "${user_config.neo4j_database}",
        "NEO4J_TRANSPORT": "${user_config.transport}",
        "NEO4J_NAMESPACE": "${user_config.neo4j_namespace}",
        "NEO4J_MCP_SERVER_HOST": "${user_config.mcp_server_host}",
        "NEO4J_MCP_SERVER_PORT": "${user_config.mcp_server_port}",
        "NEO4J_MCP_SERVER_PATH": "${user_config.mcp_server_path}"
      }
    }
  },
  "tools": [
    {
      "name": "get_neo4j_schema",
      "description": "Retrieve the schema of the Neo4j database, including node labels, properties, and relationships. Requires that APOC plugin is installed."
    },
    {
      "name": "read_neo4j_cypher",
      "description": "Execute read-only Cypher queries (MATCH, RETURN, etc.) on the Neo4j database"
    },
    {
      "name": "write_neo4j_cypher",
      "description": "Execute write Cypher queries (CREATE, MERGE, SET, DELETE, etc.) on the Neo4j database"
    }
  ],
  "prompts": [],
  "tools_generated": false,
  "license": "MIT",
  "user_config": {
    "neo4j_username": {
      "type": "string",
      "title": "Neo4j Username",
      "description": "The username for logging into Neo4j",
      "default": "neo4j",
      "required": true,
      "sensitive": false
    },
    "neo4j_password": {
      "type": "string",
      "title": "Neo4j Password",
      "description": "The password for logging into Neo4j",
      "default": "password",
      "required": true,
      "sensitive": true
    },
    "neo4j_database": {
      "type": "string",
      "title": "Neo4j Database",
      "description": "The database to use in Neo4j, defaults to neo4j",
      "default": "neo4j",
      "required": false,
      "sensitive": false
    },
    "neo4j_uri": {
      "type": "string",
      "title": "Neo4j URI",
      "description": "The URI for connecting to Neo4j",
      "default": "bolt://localhost:7687",
      "required": true,
      "sensitive": false
    },
    "neo4j_namespace": {
      "type": "string",
      "title": "Namespace",
      "description": "An optional namespace for the MCP server tools",
      "default": "",
      "required": false,
      "sensitive": false
    },
    "transport": {
      "type": "string",
      "title": "Transport",
      "description": "The MCP transport, defaults to stdio",
      "default": "stdio",
      "required": false,
      "sensitive": false
    },
    "mcp_server_host": {
      "type": "string",
      "title": "MCP Server Host",
      "description": "The host for the MCP server, if not using stdio. Defaults to 127.0.0.1",
      "default": "127.0.0.1",
      "required": false,
      "sensitive": false
    },
    "mcp_server_port": {
      "type": "number",
      "title": "MCP Server Port",
      "description": "The port for the MCP server, if not using stdio. Defaults to 8000",
      "default": 8000,
      "required": false,
      "sensitive": false
    },
    "mcp_server_path": {
      "type": "string",
      "title": "MCP Server Path",
      "description": "The path for the MCP server, if not using stdio. Defaults to /mcp/",
      "default": "/mcp/",
      "required": false,
      "sensitive": false
    }
  }
}
</file>

<file path="mcp-neo4j-cypher/pyproject.toml">
[project]
name = "mcp-neo4j-cypher"
version = "0.3.0"
description = "A simple Neo4j MCP server"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastmcp>=2.10.5",
    "neo4j>=5.26.0",
    "pydantic>=2.10.1",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
    "pyright>=1.1.389",
    "pytest>=7.0.0",
    "pytest-asyncio>=0.20.3",
    "ruff>=0.11.5",
    "testcontainers[neo4j]>=4.10.0",
    "aiohttp>=3.8.0"
]

[project.scripts]
mcp-neo4j-cypher = "mcp_neo4j_cypher:main"
</file>

<file path="mcp-neo4j-cypher/pyrightconfig.json">
{
    "venvPath": ".",
    "venv": ".venv"
}
</file>

<file path="mcp-neo4j-cypher/README.md">
# 🔍⁉️ Neo4j MCP Server

## 🌟 Overview

A Model Context Protocol (MCP) server implementation that provides database interaction and allows graph exploration capabilities through Neo4j. This server enables running Cypher graph queries, analyzing complex domain data, and automatically generating business insights that can be enhanced with Claude's analysis.

## 🧩 Components

### 🛠️ Tools

The server offers these core tools:

#### 📊 Query Tools
- `read_neo4j_cypher`
   - Execute Cypher read queries to read data from the database
   - Input: 
     - `query` (string): The Cypher query to execute
     - `params` (dictionary, optional): Parameters to pass to the Cypher query
   - Returns: Query results as JSON serialized array of objects

- `write_neo4j_cypher`
   - Execute updating Cypher queries
   - Input:
     - `query` (string): The Cypher update query
     - `params` (dictionary, optional): Parameters to pass to the Cypher query
   - Returns: A JSON serialized result summary counter with `{ nodes_updated: number, relationships_created: number, ... }`

#### 🕸️ Schema Tools
- `get_neo4j_schema`
   - Get a list of all nodes types in the graph database, their attributes with name, type and relationships to other node types
   - No input required
   - Returns: JSON serialized list of node labels with two dictionaries: one for attributes and one for relationships

### 🏷️ Namespacing

The server supports namespacing to allow multiple Neo4j MCP servers to be used simultaneously. When a namespace is provided, all tool names are prefixed with the namespace followed by a hyphen (e.g., `mydb-read_neo4j_cypher`).

This is useful when you need to connect to multiple Neo4j databases or instances from the same session.

## 🏗️ Local Development & Deployment

### 🐳 Local Docker Development

Build and run locally for testing or remote deployment:

```bash
# Build the Docker image with a custom name
docker build -t mcp-neo4j-cypher:latest .

# Run locally (uses http transport by default for Docker)
docker run -p 8000:8000 \
  -e NEO4J_URI="bolt://host.docker.internal:7687" \
  -e NEO4J_USERNAME="neo4j" \
  -e NEO4J_PASSWORD="your-password" \
  mcp-neo4j-cypher:latest

# Access the server at http://localhost:8000/api/mcp/
```

### 🚀 Transport Modes

The server supports different transport protocols depending on your deployment:

- **STDIO** (default for local development): Standard input/output for Claude Desktop and local tools
- **HTTP** (default for Docker): RESTful HTTP for web deployments and microservices  
- **SSE**: Server-Sent Events for legacy web-based deployments

Choose your transport based on use case:
- **Local development/Claude Desktop**: Use `stdio` 
- **Docker/Remote deployment**: Use `http`
- **Legacy web clients**: Use `sse`

## 🔧 Usage with Claude Desktop

### Using DXT
Download the latest `.dxt` file from the [releases page](https://github.com/neo4j-contrib/mcp-neo4j/releases/latest) and install it with your MCP client.

Or use this direct link:
[Download mcp-neo4j-cypher.dxt](https://github.com/neo4j-contrib/mcp-neo4j/releases/latest/download/mcp-neo4j-cypher.dxt)

### 💾 Released Package

Can be found on PyPi https://pypi.org/project/mcp-neo4j-cypher/

Add the server to your `claude_desktop_config.json` with the database connection configuration through environment variables. You may also specify the transport method and namespace with cli arguments or environment variables.

```json
"mcpServers": {
  "neo4j-aura": {
    "command": "uvx",
    "args": [ "mcp-neo4j-cypher@0.3.0", "--transport", "stdio"  ],
    "env": {
      "NEO4J_URI": "bolt://localhost:7687",
      "NEO4J_USERNAME": "neo4j",
      "NEO4J_PASSWORD": "<your-password>",
      "NEO4J_DATABASE": "neo4j"
    }
  }
}
```

### 🌐 HTTP Transport Configuration

For custom HTTP configurations beyond the defaults:

```bash
# Custom HTTP configuration
mcp-neo4j-cypher --transport http --host 0.0.0.0 --port 8080 --path /api/mcp/

# Or using environment variables
export NEO4J_TRANSPORT=http
export NEO4J_MCP_SERVER_HOST=0.0.0.0
export NEO4J_MCP_SERVER_PORT=8080
export NEO4J_MCP_SERVER_PATH=/api/mcp/
mcp-neo4j-cypher
```

### Multiple Database Example

Here's an example of connecting to multiple Neo4j databases using namespaces:

```json
{
  "mcpServers": {
    "movies-neo4j": {
      "command": "uvx",
      "args": [ "mcp-neo4j-cypher@0.3.0", "--namespace", "movies" ],
      "env": {
        "NEO4J_URI": "neo4j+s://demo.neo4jlabs.com",
        "NEO4J_USERNAME": "recommendations",
        "NEO4J_PASSWORD": "recommendations",
        "NEO4J_DATABASE": "recommendations"
      }
    },
    "local-neo4j": {
      "command": "uvx",
      "args": [ "mcp-neo4j-cypher@0.3.0" ],
      "env": {
        "NEO4J_URI": "bolt://localhost:7687",
        "NEO4J_USERNAME": "neo4j",
        "NEO4J_PASSWORD": "password",
        "NEO4J_DATABASE": "neo4j",
        "NEO4J_NAMESPACE": "local"
      }
    }
  }
}
```

In this setup:
- The movies database tools will be prefixed with `movies-` (e.g., `movies-read_neo4j_cypher`)
- The local database tools will be prefixed with `local-` (e.g., `local-get_neo4j_schema`)


Syntax with `--db-url`, `--username`, `--password` and other command line arguments is still supported but environment variables are preferred:

<details>
  <summary>Legacy Syntax</summary>

```json
"mcpServers": {
  "neo4j": {
    "command": "uvx",
    "args": [
      "mcp-neo4j-cypher@0.3.0",
      "--db-url",
      "bolt://localhost",
      "--username",
      "neo4j",
      "--password",
      "<your-password>",
      "--namespace",
      "mydb",
      "--transport",
      "sse",
      "--server-host",
      "0.0.0.0",
      "--server-port",
      "8000"
      "--server-path",
      "/api/mcp/"
    ]
  }
}
```

</details>

### 🐳 Using with Docker

```json
"mcpServers": {
  "neo4j": {
    "command": "docker",
    "args": [
      "run",
      "--rm",
      "-e", "NEO4J_URI=bolt://host.docker.internal:7687",
      "-e", "NEO4J_USERNAME=neo4j",
      "-e", "NEO4J_PASSWORD=<your-password>",
      "-e", "NEO4J_NAMESPACE=mydb",
      "-e", "NEO4J_TRANSPORT=http",
      "-e", "NEO4J_MCP_SERVER_HOST=0.0.0.0",
      "-e", "NEO4J_MCP_SERVER_PORT=8000",
      "-e", "NEO4J_MCP_SERVER_PATH=/api/mcp/",
      "mcp/neo4j-cypher:latest"
    ]
  }
}
```

**Note**: This assumes you've built the image locally with `docker build -t mcp-neo4j-cypher:latest .`. Docker transport defaults to HTTP mode.

## 🐳 Docker Deployment

The Neo4j MCP server can be deployed using Docker for remote deployments. Docker deployment uses HTTP transport by default for web accessibility.

### 📦 Using Your Built Image

After building locally with `docker build -t mcp-neo4j-cypher:latest .`:

```bash
# Run with http transport (default for Docker)
docker run --rm -p 8000:8000 \
  -e NEO4J_URI="bolt://host.docker.internal:7687" \
  -e NEO4J_USERNAME="neo4j" \
  -e NEO4J_PASSWORD="password" \
  -e NEO4J_DATABASE="neo4j" \
  -e NEO4J_TRANSPORT="http" \
  -e NEO4J_MCP_SERVER_HOST="0.0.0.0" \
  -e NEO4J_MCP_SERVER_PORT="8000" \
  -e NEO4J_MCP_SERVER_PATH="/api/mcp/" \
  mcp/neo4j-cypher:latest
```

### 🔧 Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `NEO4J_URI` | `bolt://localhost:7687` | Neo4j connection URI |
| `NEO4J_USERNAME` | `neo4j` | Neo4j username |
| `NEO4J_PASSWORD` | `password` | Neo4j password |
| `NEO4J_DATABASE` | `neo4j` | Neo4j database name |
| `NEO4J_TRANSPORT` | `stdio` (local), `http` (Docker) | Transport protocol (`stdio`, `http`, or `sse`) |
| `NEO4J_NAMESPACE` | _(empty)_ | Tool namespace prefix |
| `NEO4J_MCP_SERVER_HOST` | `127.0.0.1` (local), `0.0.0.0` (Docker) | Host to bind to |
| `NEO4J_MCP_SERVER_PORT` | `8000` | Port for HTTP/SSE transport |
| `NEO4J_MCP_SERVER_PATH` | `/api/mcp/` | Path for accessing MCP server |

### 🌐 SSE Transport for Legacy Web Access

When using SSE transport (for legacy web clients), the server exposes an HTTP endpoint:

```bash
# Start the server with SSE transport
docker run -d -p 8000:8000 \
  -e NEO4J_URI="neo4j+s://demo.neo4jlabs.com" \
  -e NEO4J_USERNAME="recommendations" \
  -e NEO4J_PASSWORD="recommendations" \
  -e NEO4J_DATABASE="recommendations" \
  -e NEO4J_TRANSPORT="sse" \
  -e NEO4J_MCP_SERVER_HOST="0.0.0.0" \
  -e NEO4J_MCP_SERVER_PORT="8000" \
  --name neo4j-mcp-server \
  mcp-neo4j-cypher:latest

# Test the SSE endpoint
curl http://localhost:8000/sse

# Use with MCP Inspector
npx @modelcontextprotocol/inspector http://localhost:8000/sse
```

### 🐳 Docker Compose

For more complex deployments, you may use Docker Compose:

```yaml
version: '3.8'

services:
  # Deploy Neo4j Database (optional)
  neo4j:
    image: neo4j:5.26.1 # or another version
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc"]
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j_data:/data

  # Deploy Cypher MCP Server
  mcp-neo4j-cypher-server:
    image: mcp/neo4j-cypher:latest
    ports:
      - "8000:8000"
    environment:
      - NEO4J_URI=bolt://host.docker.internal:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=password
      - NEO4J_DATABASE=neo4j
      - NEO4J_TRANSPORT=http
      - NEO4J_MCP_SERVER_HOST=0.0.0.0 # must be 0.0.0.0 for sse  or http transport in Docker
      - NEO4J_MCP_SERVER_PORT=8000
      - NEO4J_MCP_SERVER_PATH=/api/mcp/
      - NEO4J_NAMESPACE=local
    depends_on:
      - neo4j

volumes:
  neo4j_data:
```

Run with: `docker-compose up -d`

### 🔗 Claude Desktop Integration with Docker

For Claude Desktop integration with a Dockerized server using http transport:

```json
{
  "mcpServers": {
    "neo4j-docker": {
      "command": "npx",
      "args": ["-y", "mcp-remote@latest", "http://localhost:8000/api/mcp/"]
    }
  }
}
```

**Note**: First start your Docker container with HTTP transport, then Claude Desktop can connect to it via the HTTP endpoint.

## 🚀 Development

### 📦 Prerequisites

1. Install `uv` (Universal Virtualenv):
```bash
# Using pip
pip install uv

# Using Homebrew on macOS
brew install uv

# Using cargo (Rust package manager)
cargo install uv
```

2. Clone the repository and set up development environment:
```bash
# Clone the repository
git clone https://github.com/neo4j-contrib/mcp-neo4j.git
cd mcp-neo4j-cypher

# Create and activate virtual environment using uv
uv venv
source .venv/bin/activate  # On Unix/macOS
.venv\Scripts\activate     # On Windows

# Install dependencies including dev dependencies
uv pip install -e ".[dev]"
```

3. Run Integration Tests

```bash
./tests.sh
```

### 🔧 Development Configuration

For development with Claude Desktop using the local source:

```json
{
  "mcpServers": {
    "neo4j-dev": {
      "command": "uv",
      "args": [
        "--directory", 
        "/path/to/mcp-neo4j-cypher",
        "run", 
        "mcp-neo4j-cypher", 
        "--transport", 
        "stdio", 
        "--namespace", 
        "dev"
      ],
      "env": {
        "NEO4J_URI": "bolt://localhost:7687",
        "NEO4J_USERNAME": "neo4j",
        "NEO4J_PASSWORD": "<your-password>",
        "NEO4J_DATABASE": "neo4j"
      }
    }
  }
}
```

Replace `/path/to/mcp-neo4j-cypher` with your actual project directory path.



## 📄 License

This MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.
</file>

<file path="mcp-neo4j-cypher/test.sh">
uv run pytest tests/integration -s
</file>

<file path="mcp-neo4j-data-modeling/src/mcp_neo4j_data_modeling/__init__.py">
import argparse
import asyncio
import os

from . import server


def main():
    """Main entry point for the package."""
    parser = argparse.ArgumentParser(description="Neo4j Data Modeling MCP Server")
    parser.add_argument(
        "--transport", default="stdio", help="Transport type (stdio, sse, http)"
    )
    parser.add_argument("--server-host", default=None, help="HTTP host (default: 127.0.0.1)")
    parser.add_argument(
        "--server-port", type=int, default=None, help="HTTP port (default: 8000)"
    )
    parser.add_argument("--server-path", default=None, help="HTTP path (default: /mcp/)")

    args = parser.parse_args()
    asyncio.run(
        server.main(
            args.transport or os.getenv("NEO4J_TRANSPORT", "stdio"),
            args.server_host or os.getenv("NEO4J_MCP_SERVER_HOST", "127.0.0.1"),
            args.server_port or int(os.getenv("NEO4J_MCP_SERVER_PORT", "8000")),
            args.server_path or os.getenv("NEO4J_MCP_SERVER_PATH", "/mcp/"),
        )
    )


__all__ = ["main", "server"]
</file>

<file path="mcp-neo4j-data-modeling/src/mcp_neo4j_data_modeling/data_model.py">
import json
from collections import Counter
from typing import Any

from pydantic import BaseModel, Field, ValidationInfo, field_validator

NODE_COLOR_PALETTE = [
    ("#e3f2fd", "#1976d2"),  # Light Blue / Blue
    ("#f3e5f5", "#7b1fa2"),  # Light Purple / Purple
    ("#e8f5e8", "#388e3c"),  # Light Green / Green
    ("#fff3e0", "#f57c00"),  # Light Orange / Orange
    ("#fce4ec", "#c2185b"),  # Light Pink / Pink
    ("#e0f2f1", "#00695c"),  # Light Teal / Teal
    ("#f1f8e9", "#689f38"),  # Light Lime / Lime
    ("#fff8e1", "#ffa000"),  # Light Amber / Amber
    ("#e8eaf6", "#3f51b5"),  # Light Indigo / Indigo
    ("#efebe9", "#5d4037"),  # Light Brown / Brown
    ("#fafafa", "#424242"),  # Light Grey / Dark Grey
    ("#e1f5fe", "#0277bd"),  # Light Cyan / Cyan
    ("#f9fbe7", "#827717"),  # Light Yellow-Green / Olive
    ("#fff1f0", "#d32f2f"),  # Light Red / Red
    ("#f4e6ff", "#6a1b9a"),  # Light Violet / Violet
    ("#e6f7ff", "#1890ff"),  # Very Light Blue / Bright Blue
]


def _generate_relationship_pattern(
    start_node_label: str, relationship_type: str, end_node_label: str
) -> str:
    "Helper function to generate a pattern for a relationship."
    return f"(:{start_node_label})-[:{relationship_type}]->(:{end_node_label})"


class PropertySource(BaseModel):
    "The source of a property."

    column_name: str | None = Field(
        default=None, description="The column name this property maps to, if known."
    )
    table_name: str | None = Field(
        default=None,
        description="The name of the table this property's column is in, if known. May also be the name of a file.",
    )
    location: str | None = Field(
        default=None,
        description="The location of the property, if known. May be a file path, URL, etc.",
    )


class Property(BaseModel):
    "A Neo4j Property."

    name: str = Field(description="The name of the property. Should be in camelCase.")
    type: str = Field(
        default="STRING",
        description="The Neo4j type of the property. Should be all caps.",
    )
    source: PropertySource | None = Field(
        default=None, description="The source of the property, if known."
    )
    description: str | None = Field(
        default=None, description="The description of the property"
    )

    @field_validator("type")
    def validate_type(cls, v: str) -> str:
        "Validate the type."

        return v.upper()

    @classmethod
    def from_arrows(cls, arrows_property: dict[str, str]) -> "Property":
        "Convert an Arrows Property in dict format to a Property."

        description = None

        if "|" in list(arrows_property.values())[0]:
            prop_props = [
                x.strip() for x in list(arrows_property.values())[0].split("|")
            ]

            prop_type = prop_props[0]
            description = prop_props[1] if prop_props[1].lower() != "key" else None
        else:
            prop_type = list(arrows_property.values())[0]

        return cls(
            name=list(arrows_property.keys())[0],
            type=prop_type,
            description=description,
        )

    def to_arrows(self, is_key: bool = False) -> dict[str, Any]:
        "Convert a Property to an Arrows property dictionary. Final JSON string formatting is done at the data model level."
        value = f"{self.type}"
        if self.description:
            value += f" | {self.description}"
        if is_key:
            value += " | KEY"
        return {
            self.name: value,
        }


class Node(BaseModel):
    "A Neo4j Node."

    label: str = Field(
        description="The label of the node. Should be in PascalCase.", min_length=1
    )
    key_property: Property = Field(description="The key property of the node")
    properties: list[Property] = Field(
        default_factory=list, description="The properties of the node"
    )
    metadata: dict[str, Any] = Field(
        default_factory=dict,
        description="The metadata of the node. This should only be used when converting data models.",
    )

    @field_validator("properties")
    def validate_properties(
        cls, properties: list[Property], info: ValidationInfo
    ) -> list[Property]:
        "Validate the properties."
        properties = [p for p in properties if p.name != info.data["key_property"].name]

        counts = Counter([p.name for p in properties])
        for name, count in counts.items():
            if count > 1:
                raise ValueError(
                    f"Property {name} appears {count} times in node {info.data['label']}"
                )
        return properties

    def add_property(self, prop: Property) -> None:
        "Add a new property to the node."
        if prop.name in [p.name for p in self.properties]:
            raise ValueError(
                f"Property {prop.name} already exists in node {self.label}"
            )
        self.properties.append(prop)

    def remove_property(self, prop: Property) -> None:
        "Remove a property from the node."
        try:
            self.properties.remove(prop)
        except ValueError:
            pass

    @property
    def all_properties_dict(self) -> dict[str, str]:
        "Return a dictionary of all properties of the node. {property_name: property_type}"
        props = {p.name: p.type for p in self.properties} if self.properties else {}
        if self.key_property:
            props.update({self.key_property.name: f"{self.key_property.type} | KEY"})
        return props

    def get_mermaid_config_str(self) -> str:
        "Get the Mermaid configuration string for the node."
        props = [f"<br/>{self.key_property.name}: {self.key_property.type} | KEY"]
        props.extend([f"<br/>{p.name}: {p.type}" for p in self.properties])
        return f'{self.label}["{self.label}{"".join(props)}"]'

    @classmethod
    def from_arrows(cls, arrows_node_dict: dict[str, Any]) -> "Node":
        "Convert an Arrows Node to a Node."
        props = [
            Property.from_arrows({k: v})
            for k, v in arrows_node_dict["properties"].items()
            if "KEY" not in v.upper()
        ]
        keys = [
            {k: v}
            for k, v in arrows_node_dict["properties"].items()
            if "KEY" in v.upper()
        ]
        key_prop = Property.from_arrows(keys[0]) if keys else None
        metadata = {
            "position": arrows_node_dict["position"],
            "caption": arrows_node_dict["caption"],
            "style": arrows_node_dict["style"],
        }
        return cls(
            label=arrows_node_dict["labels"][0],
            key_property=key_prop,
            properties=props,
            metadata=metadata,
        )

    def to_arrows(
        self, default_position: dict[str, float] = {"x": 0.0, "y": 0.0}
    ) -> dict[str, Any]:
        "Convert a Node to an Arrows Node dictionary. Final JSON string formatting is done at the data model level."
        props = dict()
        [props.update(p.to_arrows(is_key=False)) for p in self.properties]
        props.update(self.key_property.to_arrows(is_key=True))
        return {
            "id": self.label,
            "labels": [self.label],
            "properties": props,
            "style": self.metadata.get("style", {}),
            "position": self.metadata.get("position", default_position),
            "caption": self.metadata.get("caption", ""),
        }

    def get_cypher_ingest_query_for_many_records(self) -> str:
        """
        Generate a Cypher query to ingest a list of Node records into a Neo4j database.
        This query takes a parameter $records that is a list of dictionaries, each representing a Node record.
        """
        formatted_props = ", ".join(
            [f"{p.name}: record.{p.name}" for p in self.properties]
        )
        return f"""UNWIND $records as record
MERGE (n: {self.label} {{{self.key_property.name}: record.{self.key_property.name}}})
SET n += {{{formatted_props}}}"""

    def get_cypher_constraint_query(self) -> str:
        """
        Generate a Cypher query to create a NODE KEY constraint on the node.
        This creates a range index on the key property of the node and enforces uniqueness and existence of the key property.
        """
        return f"CREATE CONSTRAINT {self.label}_constraint IF NOT EXISTS FOR (n:{self.label}) REQUIRE (n.{self.key_property.name}) IS NODE KEY"


class Relationship(BaseModel):
    "A Neo4j Relationship."

    type: str = Field(
        description="The type of the relationship. Should be in SCREAMING_SNAKE_CASE.",
        min_length=1,
    )
    start_node_label: str = Field(description="The label of the start node")
    end_node_label: str = Field(description="The label of the end node")
    key_property: Property | None = Field(
        default=None, description="The key property of the relationship, if any."
    )
    properties: list[Property] = Field(
        default_factory=list, description="The properties of the relationship, if any."
    )
    metadata: dict[str, Any] = Field(
        default_factory=dict,
        description="The metadata of the relationship. This should only be used when converting data models.",
    )

    @field_validator("properties")
    def validate_properties(
        cls, properties: list[Property], info: ValidationInfo
    ) -> list[Property]:
        "Validate the properties."
        if info.data.get("key_property"):
            properties = [
                p for p in properties if p.name != info.data["key_property"].name
            ]

        counts = Counter([p.name for p in properties])
        for name, count in counts.items():
            if count > 1:
                raise ValueError(
                    f"Property {name} appears {count} times in relationship {_generate_relationship_pattern(info.data['start_node_label'], info.data['type'], info.data['end_node_label'])}"
                )
        return properties

    def add_property(self, prop: Property) -> None:
        "Add a new property to the relationship."
        if prop.name in [p.name for p in self.properties]:
            raise ValueError(
                f"Property {prop.name} already exists in relationship {self.pattern}"
            )
        self.properties.append(prop)

    def remove_property(self, prop: Property) -> None:
        "Remove a property from the relationship."
        try:
            self.properties.remove(prop)
        except ValueError:
            pass

    @property
    def pattern(self) -> str:
        "Return the pattern of the relationship."
        return _generate_relationship_pattern(
            self.start_node_label, self.type, self.end_node_label
        )

    @property
    def all_properties_dict(self) -> dict[str, str]:
        "Return a dictionary of all properties of the relationship. {property_name: property_type}"

        props = {p.name: p.type for p in self.properties} if self.properties else {}
        if self.key_property:
            props.update({self.key_property.name: f"{self.key_property.type} | KEY"})
        return props

    def get_mermaid_config_str(self) -> str:
        "Get the Mermaid configuration string for the relationship."
        props = (
            [f"<br/>{self.key_property.name}: {self.key_property.type} | KEY"]
            if self.key_property
            else []
        )
        props.extend([f"<br/>{p.name}: {p.type}" for p in self.properties])
        return f"{self.start_node_label} -->|{self.type}{''.join(props)}| {self.end_node_label}"

    @classmethod
    def from_arrows(
        cls,
        arrows_relationship_dict: dict[str, Any],
        node_id_to_label_map: dict[str, str],
    ) -> "Relationship":
        "Convert an Arrows Relationship to a Relationship."
        props = [
            Property.from_arrows({k: v})
            for k, v in arrows_relationship_dict["properties"].items()
            if "KEY" not in v.upper()
        ]
        keys = [
            {k: v}
            for k, v in arrows_relationship_dict["properties"].items()
            if "KEY" in v.upper()
        ]
        key_prop = Property.from_arrows(keys[0]) if keys else None
        metadata = {
            "style": arrows_relationship_dict["style"],
        }
        return cls(
            type=arrows_relationship_dict["type"],
            start_node_label=node_id_to_label_map[arrows_relationship_dict["fromId"]],
            end_node_label=node_id_to_label_map[arrows_relationship_dict["toId"]],
            key_property=key_prop,
            properties=props,
            metadata=metadata,
        )

    def to_arrows(self) -> dict[str, Any]:
        "Convert a Relationship to an Arrows Relationship dictionary. Final JSON string formatting is done at the data model level."
        props = dict()
        [props.update(p.to_arrows(is_key=False)) for p in self.properties]
        if self.key_property:
            props.update(self.key_property.to_arrows(is_key=True))
        return {
            "fromId": self.start_node_label,
            "toId": self.end_node_label,
            "type": self.type,
            "properties": props,
            "style": self.metadata.get("style", {}),
        }

    def get_cypher_ingest_query_for_many_records(
        self, start_node_key_property_name: str, end_node_key_property_name: str
    ) -> str:
        """
        Generate a Cypher query to ingest a list of Relationship records into a Neo4j database.
        The sourceId and targetId properties are used to match the start and end nodes.
        This query takes a parameter $records that is a list of dictionaries, each representing a Relationship record.
        """
        formatted_props = ", ".join(
            [f"{p.name}: record.{p.name}" for p in self.properties]
        )
        key_prop = (
            f" {{{self.key_property.name}: record.{self.key_property.name}}}"
            if self.key_property
            else ""
        )
        query = f"""UNWIND $records as record
MATCH (start: {self.start_node_label} {{{start_node_key_property_name}: record.sourceId}})
MATCH (end: {self.end_node_label} {{{end_node_key_property_name}: record.targetId}})
MERGE (start)-[:{self.type}{key_prop}]->(end)"""
        if formatted_props:
            query += f"""
SET end += {{{formatted_props}}}"""
        return query

    def get_cypher_constraint_query(self) -> str | None:
        """
        Generate a Cypher query to create a RELATIONSHIP KEY constraint on the relationship.
        This creates a range index on the key property of the relationship and enforces uniqueness and existence of the key property.
        """
        if self.key_property:
            return f"CREATE CONSTRAINT {self.type}_constraint IF NOT EXISTS FOR ()-[r:{self.type}]->() REQUIRE (r.{self.key_property.name}) IS RELATIONSHIP KEY"
        else:
            return None


class DataModel(BaseModel):
    "A Neo4j Graph Data Model."

    nodes: list[Node] = Field(
        default_factory=list, description="The nodes of the data model"
    )
    relationships: list[Relationship] = Field(
        default_factory=list, description="The relationships of the data model"
    )
    metadata: dict[str, Any] = Field(
        default_factory=dict,
        description="The metadata of the data model. This should only be used when converting data models.",
    )

    @field_validator("nodes")
    def validate_nodes(cls, nodes: list[Node]) -> list[Node]:
        "Validate the nodes."

        counts = Counter([n.label for n in nodes])
        for label, count in counts.items():
            if count > 1:
                raise ValueError(
                    f"Node with label {label} appears {count} times in data model"
                )
        return nodes

    @field_validator("relationships")
    def validate_relationships(
        cls, relationships: list[Relationship], info: ValidationInfo
    ) -> list[Relationship]:
        "Validate the relationships."

        # check for duplicate relationships
        counts = Counter([r.pattern for r in relationships])
        for pattern, count in counts.items():
            if count > 1:
                raise ValueError(
                    f"Relationship with pattern {pattern} appears {count} times in data model"
                )

        # ensure source and target nodes exist
        for relationship in relationships:
            if relationship.start_node_label not in [
                n.label for n in info.data["nodes"]
            ]:
                raise ValueError(
                    f"Relationship {relationship.pattern} has a start node that does not exist in data model"
                )
            if relationship.end_node_label not in [n.label for n in info.data["nodes"]]:
                raise ValueError(
                    f"Relationship {relationship.pattern} has an end node that does not exist in data model"
                )

        return relationships

    @property
    def nodes_dict(self) -> dict[str, Node]:
        "Return a dictionary of the nodes of the data model. {node_label: node_dict}"
        return {n.label: n for n in self.nodes}

    @property
    def relationships_dict(self) -> dict[str, Relationship]:
        "Return a dictionary of the relationships of the data model. {relationship_pattern: relationship_dict}"
        return {r.pattern: r for r in self.relationships}

    def add_node(self, node: Node) -> None:
        "Add a new node to the data model."
        if node.label in [n.label for n in self.nodes]:
            raise ValueError(
                f"Node with label {node.label} already exists in data model"
            )
        self.nodes.append(node)

    def add_relationship(self, relationship: Relationship) -> None:
        "Add a new relationship to the data model."
        if relationship.pattern in [r.pattern for r in self.relationships]:
            raise ValueError(
                f"Relationship {relationship.pattern} already exists in data model"
            )
        self.relationships.append(relationship)

    def remove_node(self, node_label: str) -> None:
        "Remove a node from the data model."
        try:
            [self.nodes.remove(x) for x in self.nodes if x.label == node_label]
        except ValueError:
            pass

    def remove_relationship(
        self,
        relationship_type: str,
        relationship_start_node_label: str,
        relationship_end_node_label: str,
    ) -> None:
        "Remove a relationship from the data model."
        pattern = _generate_relationship_pattern(
            relationship_start_node_label,
            relationship_type,
            relationship_end_node_label,
        )
        try:
            [
                self.relationships.remove(x)
                for x in self.relationships
                if x.pattern == pattern
            ]
        except ValueError:
            pass

    def _generate_mermaid_config_styling_str(self) -> str:
        "Generate the Mermaid configuration string for the data model."
        node_color_config = ""

        for idx, node in enumerate(self.nodes):
            node_color_config += f"classDef node_{idx}_color fill:{NODE_COLOR_PALETTE[idx % len(NODE_COLOR_PALETTE)][0]},stroke:{NODE_COLOR_PALETTE[idx % len(NODE_COLOR_PALETTE)][1]},stroke-width:3px,color:#000,font-size:12px\nclass {node.label} node_{idx}_color\n\n"

        return f"""
%% Styling 
{node_color_config}
        """

    def get_mermaid_config_str(self) -> str:
        "Get the Mermaid configuration string for the data model."
        mermaid_nodes = [n.get_mermaid_config_str() for n in self.nodes]
        mermaid_relationships = [r.get_mermaid_config_str() for r in self.relationships]
        mermaid_styling = self._generate_mermaid_config_styling_str()
        return f"""graph TD
%% Nodes
{"\n".join(mermaid_nodes)}

%% Relationships
{"\n".join(mermaid_relationships)}

{mermaid_styling}
"""

    @classmethod
    def from_arrows(cls, arrows_data_model_dict: dict[str, Any]) -> "DataModel":
        "Convert an Arrows Data Model to a Data Model."
        nodes = [Node.from_arrows(n) for n in arrows_data_model_dict["nodes"]]
        node_id_to_label_map = {
            n["id"]: n["labels"][0] for n in arrows_data_model_dict["nodes"]
        }
        relationships = [
            Relationship.from_arrows(r, node_id_to_label_map)
            for r in arrows_data_model_dict["relationships"]
        ]
        metadata = {
            "style": arrows_data_model_dict["style"],
        }
        return cls(nodes=nodes, relationships=relationships, metadata=metadata)

    def to_arrows_dict(self) -> dict[str, Any]:
        "Convert the data model to an Arrows Data Model Python dictionary."
        node_spacing: int = 200
        y_current = 0
        arrows_nodes = []
        for idx, n in enumerate(self.nodes):
            if (idx + 1) % 5 == 0:
                y_current -= 200
            arrows_nodes.append(
                n.to_arrows(
                    default_position={"x": node_spacing * (idx % 5), "y": y_current}
                )
            )
        arrows_relationships = [r.to_arrows() for r in self.relationships]
        return {
            "nodes": arrows_nodes,
            "relationships": arrows_relationships,
            "style": self.metadata.get("style", {}),
        }

    def to_arrows_json_str(self) -> str:
        "Convert the data model to an Arrows Data Model JSON string."
        return json.dumps(self.to_arrows_dict(), indent=2)

    def get_node_cypher_ingest_query_for_many_records(self, node_label: str) -> str:
        "Generate a Cypher query to ingest a list of Node records into a Neo4j database."
        node = self.nodes_dict[node_label]
        return node.get_cypher_ingest_query_for_many_records()

    def get_relationship_cypher_ingest_query_for_many_records(
        self,
        relationship_type: str,
        relationship_start_node_label: str,
        relationship_end_node_label: str,
    ) -> str:
        "Generate a Cypher query to ingest a list of Relationship records into a Neo4j database."
        pattern = _generate_relationship_pattern(
            relationship_start_node_label,
            relationship_type,
            relationship_end_node_label,
        )
        relationship = self.relationships_dict[pattern]
        start_node = self.nodes_dict[relationship.start_node_label]
        end_node = self.nodes_dict[relationship.end_node_label]
        return relationship.get_cypher_ingest_query_for_many_records(
            start_node.key_property.name, end_node.key_property.name
        )

    def get_cypher_constraints_query(self) -> list[str]:
        """
        Generate a list of Cypher queries to create constraints on the data model.
        This creates range indexes on the key properties of the nodes and relationships and enforces uniqueness and existence of the key properties.
        """
        node_queries = [n.get_cypher_constraint_query() + ";" for n in self.nodes]
        relationship_queries = [
            r.get_cypher_constraint_query() + ";"
            for r in self.relationships
            if r.key_property is not None
        ]
        return node_queries + relationship_queries
</file>

<file path="mcp-neo4j-data-modeling/src/mcp_neo4j_data_modeling/server.py">
import logging
from typing import Any, Literal

from fastmcp.server import FastMCP
from pydantic import Field, ValidationError

from .data_model import (
    DataModel,
    Node,
    Property,
    Relationship,
)
from .static import DATA_INGEST_PROCESS

logger = logging.getLogger("mcp_neo4j_data_modeling")


def create_mcp_server() -> FastMCP:
    """Create an MCP server instance for data modeling."""

    mcp: FastMCP = FastMCP(
        "mcp-neo4j-data-modeling", dependencies=["pydantic"], stateless_http=True
    )

    @mcp.resource("resource://schema/node")
    def node_schema() -> dict[str, Any]:
        """Get the schema for a node."""
        logger.info("Getting the schema for a node.")
        return Node.model_json_schema()

    @mcp.resource("resource://schema/relationship")
    def relationship_schema() -> dict[str, Any]:
        """Get the schema for a relationship."""
        logger.info("Getting the schema for a relationship.")
        return Relationship.model_json_schema()

    @mcp.resource("resource://schema/property")
    def property_schema() -> dict[str, Any]:
        """Get the schema for a property."""
        logger.info("Getting the schema for a property.")
        return Property.model_json_schema()

    @mcp.resource("resource://schema/data_model")
    def data_model_schema() -> dict[str, Any]:
        """Get the schema for a data model."""
        logger.info("Getting the schema for a data model.")
        return DataModel.model_json_schema()

    @mcp.resource("resource://static/neo4j_data_ingest_process")
    def neo4j_data_ingest_process() -> str:
        """Get the process for ingesting data into a Neo4j database."""
        logger.info("Getting the process for ingesting data into a Neo4j database.")
        return DATA_INGEST_PROCESS

    @mcp.tool()
    def validate_node(
        node: Node, return_validated: bool = False
    ) -> bool | dict[str, Any]:
        "Validate a single node. Returns True if the node is valid, otherwise raises a ValueError. If return_validated is True, returns the validated node."
        logger.info("Validating a single node.")
        try:
            validated_node = Node.model_validate(node, strict=True)
            logger.info("Node validated successfully")
            if return_validated:
                return validated_node
            else:
                return True
        except ValidationError as e:
            logger.error(f"Validation error: {e}")
            raise ValueError(f"Validation error: {e}")

    @mcp.tool()
    def validate_relationship(
        relationship: Relationship, return_validated: bool = False
    ) -> bool | dict[str, Any]:
        "Validate a single relationship. Returns True if the relationship is valid, otherwise raises a ValueError. If return_validated is True, returns the validated relationship."
        logger.info("Validating a single relationship.")
        try:
            validated_relationship = Relationship.model_validate(
                relationship, strict=True
            )
            logger.info("Relationship validated successfully")
            if return_validated:
                return validated_relationship
            else:
                return True
        except ValidationError as e:
            logger.error(f"Validation error: {e}")
            raise ValueError(f"Validation error: {e}")

    @mcp.tool()
    def validate_data_model(
        data_model: DataModel, return_validated: bool = False
    ) -> bool | dict[str, Any]:
        "Validate the entire data model. Returns True if the data model is valid, otherwise raises a ValueError. If return_validated is True, returns the validated data model."
        logger.info("Validating the entire data model.")
        try:
            DataModel.model_validate(data_model, strict=True)
            logger.info("Data model validated successfully")
            if return_validated:
                return data_model
            else:
                return True
        except ValidationError as e:
            logger.error(f"Validation error: {e}")
            raise ValueError(f"Validation error: {e}")

    @mcp.tool()
    def load_from_arrows_json(arrows_data_model_dict: dict[str, Any]) -> DataModel:
        "Load a data model from the Arrows web application format. Returns a data model as a JSON string."
        logger.info("Loading a data model from the Arrows web application format.")
        return DataModel.from_arrows(arrows_data_model_dict)

    @mcp.tool()
    def export_to_arrows_json(data_model: DataModel) -> str:
        "Export the data model to the Arrows web application format. Returns a JSON string. This should be presented to the user as an artifact if possible."
        logger.info("Exporting the data model to the Arrows web application format.")
        return data_model.to_arrows_json_str()

    @mcp.tool()
    def get_mermaid_config_str(data_model: DataModel) -> str:
        "Get the Mermaid configuration string for the data model. This may be visualized in Claude Desktop and other applications with Mermaid support."
        logger.info("Getting the Mermaid configuration string for the data model.")
        try:
            dm_validated = DataModel.model_validate(data_model, strict=True)
        except ValidationError as e:
            logger.error(f"Validation error: {e}")
            raise ValueError(f"Validation error: {e}")
        return dm_validated.get_mermaid_config_str()

    @mcp.tool()
    def get_node_cypher_ingest_query(
        node: Node = Field(description="The node to get the Cypher query for."),
    ) -> str:
        """
        Get the Cypher query to ingest a list of Node records into a Neo4j database.
        This should be used to ingest data into a Neo4j database.
        This is a parameterized Cypher query that takes a list of records as input to the $records parameter.
        """
        logger.info(
            f"Getting the Cypher query to ingest a list of Node records into a Neo4j database for node {node.label}."
        )
        return node.get_cypher_ingest_query_for_many_records()

    @mcp.tool()
    def get_relationship_cypher_ingest_query(
        data_model: DataModel = Field(
            description="The data model snippet that contains the relationship, start node and end node."
        ),
        relationship_type: str = Field(
            description="The type of the relationship to get the Cypher query for."
        ),
        relationship_start_node_label: str = Field(
            description="The label of the relationship start node."
        ),
        relationship_end_node_label: str = Field(
            description="The label of the relationship end node."
        ),
    ) -> str:
        """
        Get the Cypher query to ingest a list of Relationship records into a Neo4j database.
        This should be used to ingest data into a Neo4j database.
        This is a parameterized Cypher query that takes a list of records as input to the $records parameter.
        The records must contain the Relationship properties, if any, as well as the sourceId and targetId properties of the start and end nodes respectively.
        """
        logger.info(
            "Getting the Cypher query to ingest a list of Relationship records into a Neo4j database."
        )
        return data_model.get_relationship_cypher_ingest_query_for_many_records(
            relationship_type,
            relationship_start_node_label,
            relationship_end_node_label,
        )

    @mcp.tool()
    def get_constraints_cypher_queries(data_model: DataModel) -> list[str]:
        "Get the Cypher queries to create constraints on the data model. This creates range indexes on the key properties of the nodes and relationships and enforces uniqueness and existence of the key properties."
        logger.info(
            "Getting the Cypher queries to create constraints on the data model."
        )
        return data_model.get_cypher_constraints_query()

    return mcp


async def main(
    transport: Literal["stdio", "sse", "http"] = "stdio",
    host: str = "127.0.0.1",
    port: int = 8000,
    path: str = "/mcp/",
) -> None:
    logger.info("Starting MCP Neo4j Data Modeling Server")

    mcp = create_mcp_server()

    match transport:
        case "http":
            await mcp.run_http_async(host=host, port=port, path=path)
        case "stdio":
            await mcp.run_stdio_async()
        case "sse":
            await mcp.run_sse_async(host=host, port=port, path=path)


if __name__ == "__main__":
    main()
</file>

<file path="mcp-neo4j-data-modeling/src/mcp_neo4j_data_modeling/static.py">
DATA_INGEST_PROCESS = """
Follow these steps when ingesting data into Neo4j.
1. Create constraints before loading any data.
2. Load all nodes before relationships.
3. Then load relationships serially to avoid deadlocks.
"""
</file>

<file path="mcp-neo4j-data-modeling/tests/integration/conftest.py">
import os
from typing import Any
import asyncio
import subprocess
import pytest
import pytest_asyncio
from neo4j import AsyncGraphDatabase
from testcontainers.neo4j import Neo4jContainer

from mcp_neo4j_data_modeling.server import create_mcp_server

neo4j = (
    Neo4jContainer("neo4j:latest")
    .with_env("NEO4J_apoc_export_file_enabled", "true")
    .with_env("NEO4J_apoc_import_file_enabled", "true")
    .with_env("NEO4J_apoc_import_file_use__neo4j__config", "true")
    .with_env("NEO4J_PLUGINS", '["apoc"]')
)


@pytest.fixture(scope="module", autouse=True)
def setup(request):
    neo4j.start()

    def remove_container():
        neo4j.get_driver().close()
        neo4j.stop()

    request.addfinalizer(remove_container)
    os.environ["NEO4J_URI"] = neo4j.get_connection_url()
    os.environ["NEO4J_HOST"] = neo4j.get_container_host_ip()
    os.environ["NEO4J_PORT"] = neo4j.get_exposed_port(7687)

    yield neo4j


@pytest_asyncio.fixture(scope="function")
async def async_neo4j_driver(setup: Neo4jContainer):
    driver = AsyncGraphDatabase.driver(
        setup.get_connection_url(), auth=(setup.username, setup.password)
    )
    try:
        yield driver
    finally:
        await driver.close()


@pytest_asyncio.fixture(scope="function")
async def mcp_server():
    mcp = create_mcp_server()
    return mcp


@pytest.fixture(scope="function")
def init_data(setup: Neo4jContainer, clear_data: Any):
    with setup.get_driver().session(database="neo4j") as session:
        session.run("CREATE (a:Person {name: 'Alice', age: 30})")
        session.run("CREATE (b:Person {name: 'Bob', age: 25})")
        session.run("CREATE (c:Person {name: 'Charlie', age: 35})")
        session.run(
            "MATCH (a:Person {name: 'Alice'}), (b:Person {name: 'Bob'}) CREATE (a)-[:FRIEND]->(b)"
        )
        session.run(
            "MATCH (b:Person {name: 'Bob'}), (c:Person {name: 'Charlie'}) CREATE (b)-[:FRIEND]->(c)"
        )


@pytest.fixture(scope="function")
def clear_data(setup: Neo4jContainer):
    with setup.get_driver().session(database="neo4j") as session:
        session.run("MATCH (n) DETACH DELETE n")

@pytest_asyncio.fixture
async def sse_server():
    """Start the MCP server in SSE mode."""

    
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-data-modeling", 
        "--transport", "sse", 
        "--server-host", "127.0.0.1", 
        "--server-port", "8002",
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    await asyncio.sleep(3)
    
    if process.returncode is not None:
        stdout, stderr = await process.communicate()
        raise RuntimeError(f"Server failed to start. stdout: {stdout.decode()}, stderr: {stderr.decode()}")
    
    yield process
    
    try:
        process.terminate()
        await asyncio.wait_for(process.wait(), timeout=5.0)
    except asyncio.TimeoutError:
        process.kill()
        await process.wait()
</file>

<file path="mcp-neo4j-data-modeling/tests/integration/test_http_transport_IT.py">
import asyncio
import json
import subprocess

import aiohttp
import pytest
import pytest_asyncio

from mcp_neo4j_data_modeling.server import create_mcp_server


async def parse_sse_response(response: aiohttp.ClientResponse) -> dict:
    """Parse Server-Sent Events response from FastMCP 2.0."""
    content = await response.text()
    lines = content.strip().split("\n")

    # Find the data line that contains the JSON
    for line in lines:
        if line.startswith("data: "):
            json_str = line[6:]  # Remove 'data: ' prefix
            return json.loads(json_str)

    raise ValueError("No data line found in SSE response")



    @pytest.mark.asyncio
    async def test_http_transport_creation(self, mcp_server):
        """Test that HTTP transport can be created."""
        # Test that the server can be created
        tools = await mcp_server.get_tools()
        assert len(tools) > 0


class TestHTTPEndpoints:
    """Test HTTP endpoints work correctly."""

    @pytest_asyncio.fixture
    async def http_server(self):
        """Start the server in HTTP mode."""
        import os

        # Get the current directory - we're already in the server directory
        server_dir = os.getcwd()

        # Start server process from the correct directory
        process = await asyncio.create_subprocess_exec(
            "uv",
            "run",
            "mcp-neo4j-data-modeling",
            "--transport",
            "http",
            "--server-host",
            "127.0.0.1",
            "--server-port",
            "8007",
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=server_dir,
        )

        # Wait for server to start
        await asyncio.sleep(3)

        yield process

        # Cleanup
        try:
            process.terminate()
            await process.wait()
        except ProcessLookupError:
            pass  # Process already terminated

    @pytest.mark.asyncio
    async def test_http_tools_list(self, http_server):
        """Test that tools/list endpoint works."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8007/mcp/",
                json={"jsonrpc": "2.0", "id": 1, "method": "tools/list"},
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                assert response.status == 200
                result = await parse_sse_response(response)
                assert "result" in result
                assert "tools" in result["result"]
                tools = result["result"]["tools"]
                assert len(tools) > 0
                tool_names = [tool["name"] for tool in tools]
                assert "validate_node" in tool_names

    @pytest.mark.asyncio
    async def test_http_validate_node(self, http_server):
        """Test that validate_node endpoint works."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8007/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "validate_node",
                        "arguments": {
                            "node": {
                                "label": "Person",
                                "key_property": {"name": "name", "type": "STRING"},
                                "properties": [],
                            }
                        },
                    },
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                assert response.status == 200
                result = await parse_sse_response(response)
                assert "result" in result
                assert "content" in result["result"]

    @pytest.mark.asyncio
    async def test_http_validate_data_model(self, http_server):
        """Test that validate_data_model endpoint works."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8007/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "validate_data_model",
                        "arguments": {
                            "data_model": {
                                "nodes": [
                                    {
                                        "label": "Person",
                                        "key_property": {
                                            "name": "name",
                                            "type": "STRING",
                                        },
                                        "properties": [],
                                    }
                                ],
                                "relationships": [],
                            }
                        },
                    },
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                assert response.status == 200
                result = await parse_sse_response(response)
                assert "result" in result
                assert "content" in result["result"]

    @pytest.mark.asyncio
    async def test_http_get_mermaid_config(self, http_server):
        """Test that get_mermaid_config_str endpoint works."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8007/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "get_mermaid_config_str",
                        "arguments": {
                            "data_model": {
                                "nodes": [
                                    {
                                        "label": "Person",
                                        "key_property": {
                                            "name": "name",
                                            "type": "STRING",
                                        },
                                        "properties": [],
                                    }
                                ],
                                "relationships": [],
                            }
                        },
                    },
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                assert response.status == 200
                result = await parse_sse_response(response)
                assert "result" in result
                assert "content" in result["result"]

    @pytest.mark.asyncio
    async def test_http_resources(self, http_server):
        """Test that resource endpoints work."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8007/mcp/",
                json={"jsonrpc": "2.0", "id": 1, "method": "resources/list"},
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                assert response.status == 200
                result = await parse_sse_response(response)
                assert "result" in result
                assert "resources" in result["result"]


class TestErrorHandling:
    """Test error handling in HTTP transport."""

    @pytest_asyncio.fixture
    async def http_server(self):
        """Start the server in HTTP mode."""
        import os

        # Get the current directory - we're already in the server directory
        server_dir = os.getcwd()

        process = await asyncio.create_subprocess_exec(
            "uv",
            "run",
            "mcp-neo4j-data-modeling",
            "--transport",
            "http",
            "--server-host",
            "127.0.0.1",
            "--server-port",
            "8008",
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=server_dir,
        )

        await asyncio.sleep(3)
        yield process
        process.terminate()
        await process.wait()

    @pytest.mark.asyncio
    async def test_invalid_json(self, http_server):
        """Test handling of invalid JSON."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                data="invalid json",
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                # FastMCP returns 406 for missing Accept header, but with proper headers it should handle invalid JSON
                assert response.status in [400, 406]

    @pytest.mark.asyncio
    async def test_invalid_method(self, http_server):
        """Test handling of invalid method."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                json={"jsonrpc": "2.0", "id": 1, "method": "invalid_method"},
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Accept either JSON-RPC error or result with isError
                assert (
                    "result" in result and result["result"].get("isError", False)
                ) or ("error" in result)

    @pytest.mark.asyncio
    async def test_invalid_tool_call(self, http_server):
        """Test handling of invalid tool call."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {"name": "nonexistent_tool", "arguments": {}},
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # FastMCP returns errors in result field with isError: True
                assert "result" in result
                assert result["result"].get("isError", False)

    @pytest.mark.asyncio
    async def test_invalid_node_data(self, http_server):
        """Test handling of invalid node data."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "validate_node",
                        "arguments": {"node": {"invalid_field": "invalid_value"}},
                    },
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Should return an error or handle gracefully
                assert "result" in result

    @pytest.mark.asyncio
    async def test_invalid_data_model(self, http_server):
        """Test handling of invalid data model."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8008/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "validate_data_model",
                        "arguments": {"data_model": {"invalid_field": "invalid_value"}},
                    },
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                },
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Should return an error or handle gracefully
                assert "result" in result


class TestHTTPTransportIntegration:
    """Integration tests for HTTP transport."""

    @pytest.mark.asyncio
    async def test_full_workflow(self):
        """Test a complete workflow over HTTP transport."""
        import os

        # Get the current directory - we're already in the server directory
        server_dir = os.getcwd()

        process = await asyncio.create_subprocess_exec(
            "uv",
            "run",
            "mcp-neo4j-data-modeling",
            "--transport",
            "http",
            "--server-host",
            "127.0.0.1",
            "--server-port",
            "8009",
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=server_dir,
        )

        await asyncio.sleep(3)

        try:
            async with aiohttp.ClientSession() as session:
                # 1. List tools
                async with session.post(
                    "http://127.0.0.1:8009/mcp/",
                    json={"jsonrpc": "2.0", "id": 1, "method": "tools/list"},
                    headers={
                        "Accept": "application/json, text/event-stream",
                        "Content-Type": "application/json",
                    },
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result

                # 2. List resources
                async with session.post(
                    "http://127.0.0.1:8009/mcp/",
                    json={"jsonrpc": "2.0", "id": 2, "method": "resources/list"},
                    headers={
                        "Accept": "application/json, text/event-stream",
                        "Content-Type": "application/json",
                    },
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result

                # 3. Validate a node
                async with session.post(
                    "http://127.0.0.1:8009/mcp/",
                    json={
                        "jsonrpc": "2.0",
                        "id": 3,
                        "method": "tools/call",
                        "params": {
                            "name": "validate_node",
                            "arguments": {
                                "node": {
                                    "label": "IntegrationTest",
                                    "properties": [
                                        {
                                            "name": "test_field",
                                            "type": "string",
                                            "required": True,
                                        }
                                    ],
                                }
                            },
                        },
                    },
                    headers={
                        "Accept": "application/json, text/event-stream",
                        "Content-Type": "application/json",
                    },
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result

                # 4. Validate a data model
                async with session.post(
                    "http://127.0.0.1:8009/mcp/",
                    json={
                        "jsonrpc": "2.0",
                        "id": 4,
                        "method": "tools/call",
                        "params": {
                            "name": "validate_data_model",
                            "arguments": {
                                "data_model": {
                                    "nodes": [
                                        {
                                            "label": "IntegrationTest",
                                            "properties": [
                                                {
                                                    "name": "test_field",
                                                    "type": "string",
                                                    "required": True,
                                                }
                                            ],
                                        }
                                    ],
                                    "relationships": [],
                                }
                            },
                        },
                    },
                    headers={
                        "Accept": "application/json, text/event-stream",
                        "Content-Type": "application/json",
                    },
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result

        finally:
            process.terminate()
            await process.wait()
</file>

<file path="mcp-neo4j-data-modeling/tests/integration/test_sse_transport_IT.py">
import aiohttp
import pytest


@pytest.mark.asyncio
async def test_sse_endpoint(sse_server):
    """Test that SSE endpoint is accessible."""
    async with aiohttp.ClientSession() as session:
        async with session.get("http://127.0.0.1:8002/mcp/") as response:
            # SSE endpoint should be accessible
            assert response.status in [200, 404]  # 404 is okay if no specific endpoint
</file>

<file path="mcp-neo4j-data-modeling/tests/integration/test_stdio_transport_IT.py">
import pytest
import asyncio
import subprocess
import os

from testcontainers.neo4j import Neo4jContainer




@pytest.mark.asyncio
async def test_stdio_transport(setup: Neo4jContainer):
    """Test that stdio transport can be started."""
    
    # Test that stdio transport can be started (it should not crash)
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-cypher", 
        "--transport", "stdio",
        "--db-url", setup.get_connection_url(),
        "--username", setup.username,
        "--password", setup.password,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    # Give it a moment to start
    await asyncio.sleep(1)
    
    # Check if process is still running before trying to terminate
    if process.returncode is None:
        # Process is still running, terminate it
        try:
            process.terminate()
            await asyncio.wait_for(process.wait(), timeout=5.0)
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
    else:
        # Process has already exited, which is fine for this test
        # We just want to verify it didn't crash immediately
        pass
    
    # Process should have started successfully (no immediate crash)
    # If returncode is None, it means the process was still running when we tried to terminate it
    # If returncode is not None, it means the process exited (which is also acceptable for this test)
    assert True  # If we get here, the process started without immediate crash
</file>

<file path="mcp-neo4j-data-modeling/tests/unit/conftest.py">
from typing import Any

import pytest

from mcp_neo4j_data_modeling.data_model import DataModel, Node, Property, Relationship


@pytest.fixture(scope="function")
def arrows_data_model_dict() -> dict[str, Any]:
    return {
        "style": {
            "font-family": "sans-serif",
            "background-color": "#ffffff",
            "background-image": "",
            "background-size": "100%",
            "node-color": "#ffffff",
            "border-width": 4,
            "border-color": "#000000",
            "radius": 50,
            "node-padding": 5,
            "node-margin": 2,
            "outside-position": "auto",
            "node-icon-image": "",
            "node-background-image": "",
            "icon-position": "inside",
            "icon-size": 64,
            "caption-position": "inside",
            "caption-max-width": 200,
            "caption-color": "#000000",
            "caption-font-size": 50,
            "caption-font-weight": "normal",
            "label-position": "inside",
            "label-display": "pill",
            "label-color": "#000000",
            "label-background-color": "#ffffff",
            "label-border-color": "#000000",
            "label-border-width": 4,
            "label-font-size": 40,
            "label-padding": 5,
            "label-margin": 4,
            "directionality": "directed",
            "detail-position": "inline",
            "detail-orientation": "parallel",
            "arrow-width": 5,
            "arrow-color": "#000000",
            "margin-start": 5,
            "margin-end": 5,
            "margin-peer": 20,
            "attachment-start": "normal",
            "attachment-end": "normal",
            "relationship-icon-image": "",
            "type-color": "#000000",
            "type-background-color": "#ffffff",
            "type-border-color": "#000000",
            "type-border-width": 0,
            "type-font-size": 16,
            "type-padding": 5,
            "property-position": "outside",
            "property-alignment": "colon",
            "property-color": "#000000",
            "property-font-size": 16,
            "property-font-weight": "normal",
        },
        "nodes": [
            {
                "id": "n0",
                "position": {"x": 105.3711141386136, "y": -243.80584874322315},
                "caption": "",
                "labels": ["Person"],
                "properties": {"name": "STRING | KEY", "age": "INTEGER"},
                "style": {},
            },
            {
                "id": "n1",
                "position": {"x": 142.1337531280864, "y": 50},
                "caption": "",
                "labels": ["Address"],
                "properties": {
                    "fullAddress": "STRING | KEY",
                },
                "style": {},
            },
            {
                "id": "n2",
                "position": {"x": 484.55353547755726, "y": -279.86295267473423},
                "caption": "",
                "labels": ["Pet"],
                "properties": {"name": "STRING | KEY", "kind": "STRING"},
                "style": {},
            },
            {
                "id": "n3",
                "position": {"x": 675, "y": 50},
                "caption": "",
                "labels": ["Toy"],
                "properties": {"name": "STRING | KEY", "kind": "STRING"},
                "style": {},
            },
        ],
        "relationships": [
            {
                "id": "n0",
                "fromId": "n0",
                "toId": "n1",
                "type": "HAS_ADDRESS",
                "properties": {},
                "style": {},
            },
            {
                "id": "n1",
                "fromId": "n0",
                "toId": "n0",
                "type": "KNOWS",
                "properties": {},
                "style": {},
            },
            {
                "id": "n2",
                "fromId": "n0",
                "toId": "n2",
                "type": "HAS_PET",
                "properties": {},
                "style": {},
            },
            {
                "id": "n3",
                "fromId": "n2",
                "toId": "n3",
                "type": "PLAYS_WITH",
                "properties": {},
                "style": {},
            },
        ],
    }


@pytest.fixture(scope="function")
def valid_data_model() -> DataModel:
    "A simple valid data model with a Person node, a Place node, and a LIVES_IN relationship."
    nodes = [
        Node(
            label="Person",
            key_property=Property(
                name="id", type="STRING", description="Unique identifier"
            ),
            properties=[
                Property(name="name", type="STRING", description="Name of the person"),
                Property(name="age", type="INTEGER", description="Age of the person"),
            ],
        ),
        Node(
            label="Place",
            key_property=Property(
                name="id", type="STRING", description="Unique identifier"
            ),
            properties=[
                Property(name="name", type="STRING", description="Name of the place")
            ],
        ),
    ]

    relationship = Relationship(
        type="LIVES_IN",
        start_node_label="Person",
        end_node_label="Place",
    )
    return DataModel(nodes=nodes, relationships=[relationship])
</file>

<file path="mcp-neo4j-data-modeling/tests/unit/test_data_model.py">
import json
from typing import Any

import pytest
from pydantic import ValidationError

from mcp_neo4j_data_modeling.data_model import DataModel, Node, Property, Relationship


def test_node_add_property_new():
    """Test adding a new property to a node."""
    key_prop = Property(name="id", type="string", description="Unique identifier")
    node = Node(
        label="Person",
        key_property=key_prop,
        properties=[Property(name="name", type="string", description="Full name")],
    )

    new_prop = Property(name="age", type="integer", description="Age in years")
    node.add_property(new_prop)

    assert len(node.properties) == 2
    assert any(p.name == "age" for p in node.properties)


def test_node_add_property_existing():
    """Test adding an existing property to a node should raise an error."""
    key_prop = Property(name="id", type="string", description="Unique identifier")
    node = Node(
        label="Person",
        key_property=key_prop,
        properties=[Property(name="name", type="string", description="Full name")],
    )

    duplicate_prop = Property(name="name", type="string", description="Another name")

    with pytest.raises(ValueError, match="Property name already exists"):
        node.add_property(duplicate_prop)


def test_node_remove_property():
    """Test removing a property from a node."""
    key_prop = Property(name="id", type="string", description="Unique identifier")
    name_prop = Property(name="name", type="string", description="Full name")
    age_prop = Property(name="age", type="integer", description="Age in years")

    node = Node(label="Person", key_property=key_prop, properties=[name_prop, age_prop])

    node.remove_property(name_prop)

    assert len(node.properties) == 1
    assert not any(p.name == "name" for p in node.properties)


def test_node_validate_properties_key_prop_in_properties_list():
    """Test validating properties of a node when key property is in properties list."""
    key_prop = Property(name="id", type="string", description="Unique identifier")
    node = Node(
        label="Person",
        key_property=key_prop,
        properties=[
            Property(name="name", type="string", description="Full name"),
            Property(name="id", type="string", description="Unique identifier"),
        ],
    )

    assert len(node.properties) == 1
    assert not any(p.name == "id" for p in node.properties)


def test_node_validate_properties_dupe_property_names():
    """Test validating properties of a node when there are duplicate property names."""
    with pytest.raises(
        ValidationError, match="Property name appears 2 times in node Person"
    ):
        Node(
            label="Person",
            key_property=Property(
                name="id", type="string", description="Unique identifier"
            ),
            properties=[
                Property(name="name", type="string", description="Full name"),
                Property(name="name", type="string", description="Another name"),
            ],
        )


def test_relationship_add_property_new():
    """Test adding a new property to a relationship."""
    key_prop = Property(name="since", type="date", description="Start date")
    relationship = Relationship(
        type="KNOWS",
        start_node_label="Person",
        end_node_label="Person",
        key_property=key_prop,
        properties=[
            Property(name="weight", type="float", description="Relationship strength")
        ],
    )

    new_prop = Property(name="context", type="string", description="How they met")
    relationship.add_property(new_prop)

    assert len(relationship.properties) == 2
    assert any(p.name == "context" for p in relationship.properties)


def test_relationship_add_property_existing():
    """Test adding an existing property to a relationship should raise an error."""
    relationship = Relationship(
        type="KNOWS",
        start_node_label="Person",
        end_node_label="Person",
        properties=[
            Property(name="weight", type="float", description="Relationship strength")
        ],
    )

    duplicate_prop = Property(name="weight", type="float", description="Another weight")

    with pytest.raises(ValueError, match="Property weight already exists"):
        relationship.add_property(duplicate_prop)


def test_relationship_remove_property():
    """Test removing a property from a relationship."""
    weight_prop = Property(
        name="weight", type="float", description="Relationship strength"
    )
    context_prop = Property(name="context", type="string", description="How they met")

    relationship = Relationship(
        type="KNOWS",
        start_node_label="Person",
        end_node_label="Person",
        properties=[weight_prop, context_prop],
    )

    relationship.remove_property(weight_prop)

    assert len(relationship.properties) == 1
    assert not any(p.name == "weight" for p in relationship.properties)


def test_generate_relationship_pattern():
    """Test generating relationship pattern string."""
    relationship = Relationship(
        type="KNOWS", start_node_label="Person", end_node_label="Person", properties=[]
    )

    expected_pattern = "(:Person)-[:KNOWS]->(:Person)"
    assert relationship.pattern == expected_pattern


def test_relationship_validate_properties_key_prop_in_properties_list():
    """Test validating properties of a relationship when key property is in properties list."""
    key_prop = Property(name="id", type="string", description="Unique identifier")
    relationship = Relationship(
        start_node_label="Person",
        end_node_label="Person",
        type="KNOWS",
        key_property=key_prop,
        properties=[
            Property(name="name", type="string", description="Full name"),
            Property(name="id", type="string", description="Unique identifier"),
        ],
    )

    assert len(relationship.properties) == 1
    assert not any(p.name == "id" for p in relationship.properties)


def test_relationship_validate_properties_dupe_property_names():
    """Test validating properties of a relationship when there are duplicate property names."""
    with pytest.raises(
        ValidationError,
        match=r"Property name appears 2 times in relationship \(:Person\)-\[:KNOWS\]->\(:Person\)",
    ):
        Relationship(
            start_node_label="Person",
            end_node_label="Person",
            type="KNOWS",
            key_property=Property(
                name="id", type="string", description="Unique identifier"
            ),
            properties=[
                Property(name="name", type="string", description="Full name"),
                Property(name="name", type="string", description="Another name"),
            ],
        )


def test_data_model_validate_nodes_valid():
    """Test data model validation with valid nodes."""
    key_prop1 = Property(name="id", type="string", description="Unique identifier")
    key_prop2 = Property(name="code", type="string", description="Company code")

    nodes = [
        Node(label="Person", key_property=key_prop1, properties=[]),
        Node(label="Company", key_property=key_prop2, properties=[]),
    ]

    data_model = DataModel(nodes=nodes, relationships=[])

    # Should not raise an exception
    assert len(data_model.nodes) == 2


def test_data_model_validate_nodes_invalid_dupe_labels():
    """Test data model validation with duplicate node labels."""
    key_prop = Property(name="id", type="string", description="Unique identifier")

    nodes = [
        Node(label="Person", key_property=key_prop, properties=[]),
        Node(label="Person", key_property=key_prop, properties=[]),
    ]

    with pytest.raises(
        ValidationError, match="Node with label Person appears 2 times in data model"
    ):
        DataModel(nodes=nodes, relationships=[])


def test_data_model_validate_relationships_valid():
    """Test data model validation with valid relationships."""
    nodes = [
        Node(
            label="Person",
            key_property=Property(
                name="id", type="STRING", description="Unique identifier"
            ),
            properties=[],
        ),
        Node(
            label="Company",
            key_property=Property(
                name="id", type="STRING", description="Unique identifier"
            ),
            properties=[],
        ),
    ]
    relationships = [
        Relationship(
            type="KNOWS",
            start_node_label="Person",
            end_node_label="Person",
            properties=[],
        ),
        Relationship(
            type="WORKS_FOR",
            start_node_label="Person",
            end_node_label="Company",
            properties=[],
        ),
    ]

    data_model = DataModel(nodes=nodes, relationships=relationships)

    # Should not raise an exception
    assert len(data_model.relationships) == 2


def test_data_model_validate_relationships_invalid_dupe_patterns():
    """Test data model validation with duplicate relationship patterns."""
    relationships = [
        Relationship(
            type="KNOWS",
            start_node_label="Person",
            end_node_label="Person",
            properties=[],
        ),
        Relationship(
            type="KNOWS",
            start_node_label="Person",
            end_node_label="Person",
            properties=[],
        ),
    ]
    with pytest.raises(
        ValidationError,
        match=r"Relationship with pattern \(:Person\)-\[:KNOWS\]->\(:Person\) appears 2 times in data model",
    ):
        DataModel(nodes=[], relationships=relationships)


def test_data_model_validate_relationships_invalid_start_node_does_not_exist():
    """Test data model validation with a start node that does not exist."""
    nodes = [
        Node(
            label="Pet",
            key_property=Property(
                name="id", type="string", description="Unique identifier"
            ),
        ),
        Node(
            label="Place",
            key_property=Property(
                name="id", type="string", description="Unique identifier"
            ),
        ),
    ]
    relationships = [
        Relationship(
            type="KNOWS", start_node_label="Person", end_node_label="Pet", properties=[]
        )
    ]
    with pytest.raises(
        ValidationError,
        match=r"Relationship \(:Person\)-\[:KNOWS\]->\(:Pet\) has a start node that does not exist in data model",
    ):
        DataModel(nodes=nodes, relationships=relationships)


def test_data_model_validate_relationships_invalid_end_node_does_not_exist():
    """Test data model validation with an end node that does not exist."""
    nodes = [
        Node(
            label="Person",
            key_property=Property(
                name="id", type="string", description="Unique identifier"
            ),
        ),
        Node(
            label="Place",
            key_property=Property(
                name="id", type="string", description="Unique identifier"
            ),
        ),
    ]

    relationships = [
        Relationship(
            type="KNOWS", start_node_label="Person", end_node_label="Pet", properties=[]
        )
    ]
    with pytest.raises(
        ValidationError,
        match=r"Relationship \(:Person\)-\[:KNOWS\]->\(:Pet\) has an end node that does not exist in data model",
    ):
        DataModel(nodes=nodes, relationships=relationships)


def test_data_model_from_arrows(arrows_data_model_dict: dict[str, Any]):
    """Test converting an Arrows Data Model to a Data Model."""
    data_model = DataModel.from_arrows(arrows_data_model_dict)
    assert len(data_model.nodes) == 4
    assert len(data_model.relationships) == 4
    assert data_model.nodes[0].label == "Person"
    assert data_model.nodes[0].key_property.name == "name"
    assert data_model.nodes[0].key_property.type == "STRING"
    assert data_model.nodes[0].metadata == {
        "position": {"x": 105.3711141386136, "y": -243.80584874322315},
        "caption": "",
        "style": {},
    }
    assert len(data_model.nodes[0].properties) == 1
    assert data_model.nodes[0].properties[0].name == "age"
    assert data_model.nodes[0].properties[0].type == "INTEGER"
    assert data_model.nodes[0].properties[0].description is None
    assert data_model.nodes[1].label == "Address"
    assert data_model.nodes[1].key_property.name == "fullAddress"
    assert data_model.nodes[1].key_property.type == "STRING"
    assert data_model.relationships[0].metadata == {
        "style": {},
    }
    assert {"Person", "Address", "Pet", "Toy"} == {n.label for n in data_model.nodes}
    assert {"KNOWS", "HAS_ADDRESS", "HAS_PET", "PLAYS_WITH"} == {
        r.type for r in data_model.relationships
    }
    assert data_model.metadata == {
        "style": {
            "font-family": "sans-serif",
            "background-color": "#ffffff",
            "background-image": "",
            "background-size": "100%",
            "node-color": "#ffffff",
            "border-width": 4,
            "border-color": "#000000",
            "radius": 50,
            "node-padding": 5,
            "node-margin": 2,
            "outside-position": "auto",
            "node-icon-image": "",
            "node-background-image": "",
            "icon-position": "inside",
            "icon-size": 64,
            "caption-position": "inside",
            "caption-max-width": 200,
            "caption-color": "#000000",
            "caption-font-size": 50,
            "caption-font-weight": "normal",
            "label-position": "inside",
            "label-display": "pill",
            "label-color": "#000000",
            "label-background-color": "#ffffff",
            "label-border-color": "#000000",
            "label-border-width": 4,
            "label-font-size": 40,
            "label-padding": 5,
            "label-margin": 4,
            "directionality": "directed",
            "detail-position": "inline",
            "detail-orientation": "parallel",
            "arrow-width": 5,
            "arrow-color": "#000000",
            "margin-start": 5,
            "margin-end": 5,
            "margin-peer": 20,
            "attachment-start": "normal",
            "attachment-end": "normal",
            "relationship-icon-image": "",
            "type-color": "#000000",
            "type-background-color": "#ffffff",
            "type-border-color": "#000000",
            "type-border-width": 0,
            "type-font-size": 16,
            "type-padding": 5,
            "property-position": "outside",
            "property-alignment": "colon",
            "property-color": "#000000",
            "property-font-size": 16,
            "property-font-weight": "normal",
        }
    }


def test_data_model_to_arrows():
    nodes = [
        Node(
            label="Person",
            key_property=Property(
                name="id", type="STRING", description="Unique identifier"
            ),
            properties=[
                Property(name="name", type="STRING", description="Name of the person")
            ],
        ),
        Node(
            label="Company",
            key_property=Property(
                name="id2", type="STRING", description="Unique identifier 2"
            ),
            properties=[],
        ),
    ]
    relationships = [
        Relationship(
            type="KNOWS",
            start_node_label="Person",
            end_node_label="Person",
            properties=[],
        ),
        Relationship(
            type="WORKS_FOR",
            start_node_label="Person",
            end_node_label="Company",
            properties=[],
        ),
    ]

    data_model = DataModel(nodes=nodes, relationships=relationships)

    arrows_data_model_dict = data_model.to_arrows_dict()
    assert len(arrows_data_model_dict["nodes"]) == 2
    assert len(arrows_data_model_dict["relationships"]) == 2
    assert arrows_data_model_dict["nodes"][0]["id"] == "Person"
    assert arrows_data_model_dict["nodes"][0]["properties"] == {
        "id": "STRING | Unique identifier | KEY",
        "name": "STRING | Name of the person",
    }
    assert arrows_data_model_dict["nodes"][0]["position"] == {"x": 0.0, "y": 0.0}
    assert arrows_data_model_dict["nodes"][0]["caption"] == ""
    assert arrows_data_model_dict["nodes"][0]["style"] == {}
    assert arrows_data_model_dict["nodes"][1]["id"] == "Company"
    assert arrows_data_model_dict["nodes"][1]["properties"] == {
        "id2": "STRING | Unique identifier 2 | KEY"
    }
    assert arrows_data_model_dict["nodes"][1]["position"] == {"x": 200.0, "y": 0.0}
    assert arrows_data_model_dict["nodes"][1]["caption"] == ""
    assert arrows_data_model_dict["nodes"][1]["style"] == {}
    assert arrows_data_model_dict["relationships"][0]["fromId"] == "Person"


def test_data_model_arrows_round_trip(arrows_data_model_dict: dict[str, Any]):
    """Test converting a Data Model to an Arrows Data Model and back."""
    data_model = DataModel.from_arrows(arrows_data_model_dict)
    arrows_data_model_dict_copy = json.loads(data_model.to_arrows_json_str())

    assert (
        arrows_data_model_dict_copy["nodes"][0]["properties"]["name"]
        == arrows_data_model_dict["nodes"][0]["properties"]["name"]
    )
    assert (
        arrows_data_model_dict_copy["nodes"][0]["properties"]["name"]
        == arrows_data_model_dict["nodes"][0]["properties"]["name"]
    )
    assert (
        arrows_data_model_dict_copy["nodes"][1]["properties"]
        == arrows_data_model_dict["nodes"][1]["properties"]
    )
    assert (
        arrows_data_model_dict_copy["relationships"][0]["type"]
        == arrows_data_model_dict["relationships"][0]["type"]
    )
    assert (
        arrows_data_model_dict_copy["relationships"][1]["type"]
        == arrows_data_model_dict["relationships"][1]["type"]
    )
    assert arrows_data_model_dict_copy["style"] == arrows_data_model_dict["style"]


def test_node_cypher_generation_for_many_records():
    """Test generating a Cypher query to ingest a list of Node records into a Neo4j database."""
    node = Node(
        label="Person",
        key_property=Property(
            name="id", type="STRING", description="Unique identifier"
        ),
        properties=[
            Property(name="name", type="STRING", description="Name of the person"),
            Property(name="age", type="INTEGER", description="Age of the person"),
        ],
    )

    query = node.get_cypher_ingest_query_for_many_records()

    assert (
        query
        == """UNWIND $records as record
MERGE (n: Person {id: record.id})
SET n += {name: record.name, age: record.age}"""
    )


def test_relationship_cypher_generation_for_many_records():
    """Test generating a Cypher query to ingest a list of Relationship records into a Neo4j database."""
    relationship = Relationship(
        type="KNOWS",
        start_node_label="Person",
        end_node_label="Place",
        key_property=Property(
            name="relId", type="STRING", description="Unique identifier"
        ),
        properties=[Property(name="since", type="DATE", description="Since date")],
    )

    query = relationship.get_cypher_ingest_query_for_many_records(
        start_node_key_property_name="personId", end_node_key_property_name="placeId"
    )

    assert (
        query
        == """UNWIND $records as record
MATCH (start: Person {personId: record.sourceId})
MATCH (end: Place {placeId: record.targetId})
MERGE (start)-[:KNOWS {relId: record.relId}]->(end)
SET end += {since: record.since}"""
    )


def test_relationship_cypher_generation_for_many_records_no_key_property():
    """Test generating a Cypher query to ingest a list of Relationship records into a Neo4j database."""
    relationship = Relationship(
        type="KNOWS",
        start_node_label="Person",
        end_node_label="Place",
        properties=[Property(name="since", type="DATE", description="Since date")],
    )

    query = relationship.get_cypher_ingest_query_for_many_records(
        start_node_key_property_name="personId", end_node_key_property_name="placeId"
    )

    assert (
        query
        == """UNWIND $records as record
MATCH (start: Person {personId: record.sourceId})
MATCH (end: Place {placeId: record.targetId})
MERGE (start)-[:KNOWS]->(end)
SET end += {since: record.since}"""
    )


def test_relationship_cypher_generation_for_many_records_no_properties():
    """Test generating a Cypher query to ingest a list of Relationship records into a Neo4j database."""
    relationship = Relationship(
        type="KNOWS",
        start_node_label="Person",
        end_node_label="Place",
    )
    query = relationship.get_cypher_ingest_query_for_many_records(
        start_node_key_property_name="personId", end_node_key_property_name="placeId"
    )

    assert (
        query
        == """UNWIND $records as record
MATCH (start: Person {personId: record.sourceId})
MATCH (end: Place {placeId: record.targetId})
MERGE (start)-[:KNOWS]->(end)"""
    )


def test_get_node_cypher_ingest_query_for_many_records(valid_data_model: DataModel):
    """Test generating a Cypher query to ingest a list of Node records into a Neo4j database."""

    query = valid_data_model.get_node_cypher_ingest_query_for_many_records("Person")

    assert (
        query
        == """UNWIND $records as record
MERGE (n: Person {id: record.id})
SET n += {name: record.name, age: record.age}"""
    )


def test_get_relationship_cypher_ingest_query_for_many_records(
    valid_data_model: DataModel,
):
    """Test generating a Cypher query to ingest a list of Relationship records into a Neo4j database."""
    query = valid_data_model.get_relationship_cypher_ingest_query_for_many_records(
        "LIVES_IN", "Person", "Place"
    )

    assert (
        query
        == """UNWIND $records as record
MATCH (start: Person {id: record.sourceId})
MATCH (end: Place {id: record.targetId})
MERGE (start)-[:LIVES_IN]->(end)"""
    )


def test_get_cypher_constraints_query(valid_data_model: DataModel):
    """Test generating a list of Cypher queries to create constraints on the data model."""
    queries = valid_data_model.get_cypher_constraints_query()

    assert len(queries) == 2
    assert (
        queries[0]
        == "CREATE CONSTRAINT Person_constraint IF NOT EXISTS FOR (n:Person) REQUIRE (n.id) IS NODE KEY;"
    )
    assert (
        queries[1]
        == "CREATE CONSTRAINT Place_constraint IF NOT EXISTS FOR (n:Place) REQUIRE (n.id) IS NODE KEY;"
    )
</file>

<file path="mcp-neo4j-data-modeling/.dockerignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Git
.git
.gitignore

# Docker
Dockerfile
.dockerignore

# Documentation
docs/
*.md
!README.md
!pyproject.toml

# Tests
tests/
test/
testing/
</file>

<file path="mcp-neo4j-data-modeling/.flake8">
[flake8]
exclude =
	.git,
	__pycache__,
	build,
	dist,
	.tox,
	venv,
	.venv,
	.pytest_cache
max-line-length = 120
</file>

<file path="mcp-neo4j-data-modeling/.python-version">
3.12.7
</file>

<file path="mcp-neo4j-data-modeling/CHANGELOG.md">
## Next

### Fixed

### Changed

### Added

## v0.2.0

### Added
* Add HTTP transport option
* Migrate to FastMCP v2.x

## v0.1.1

### Fixed
* Shorten tool names to comply with Cursor name length restrictions

### Changed
* Removed NVL visualization due to compatibility issues

### Added
* Code generation tools for ingestion queries
* Resource that explains the recommended process of ingesting data into Neo4j
* Mermaid visualization configuration generation

## v0.1.0

* Basic functionality 
  * Expose schemas for Data Model, Node, Relationship and Property
  * Validation tools
* Visualize data model in interactive browser window   
* Import / Export from Arrows web application
</file>

<file path="mcp-neo4j-data-modeling/Dockerfile">
FROM python:3.12-slim

# Set working directory
WORKDIR /app

# Install build dependencies
RUN pip install uv

# Copy dependency files first
COPY pyproject.toml /app/
COPY uv.lock /app/

# Copy the source code
COPY src/ /app/src/
COPY README.md /app/

# Install the package
RUN uv sync


# Command to run the server using the package entry point
CMD ["sh", "-c", "uv run mcp-neo4j-data-modeling --transport ${MCP_TRANSPORT}"]
</file>

<file path="mcp-neo4j-data-modeling/Makefile">
# Makefile for cypher-guard Python bindings

.PHONY: format test clean inspector build_local_docker_image install-dev test-unit test-integration test-http test-all all

format:
	uv run ruff check --select I . --fix
	uv run ruff check --fix .
	uv run ruff format .

test:
	uv run pytest tests/ -s 

inspector:
	npx @modelcontextprotocol/inspector uv --directory src/mcp_neo4j_data_modeling run mcp-neo4j-data-modeling

build_local_docker_image:
	docker build -t mcp-neo4j-data-modeling .

clean:
	rm -rf .mypy_cache/
	rm -rf .ruff_cache/
	rm -rf .pytest_cache/
	rm -rf .vscode/
	rm -rf .venv/
	rm -rf .mypy_cache/
	rm -rf .ruff_cache/
	rm -rf .pytest_cache/

install-dev:
	 uv pip install -e .

test-unit:
	uv run pytest tests/unit/ -v

test-integration:
	uv run pytest tests/integration/ -v

test-http:
	uv run pytest tests/integration/test_http_transport.py -v

test-all:
	uv run pytest tests/ -v

all: install-dev test-all
</file>

<file path="mcp-neo4j-data-modeling/pyproject.toml">
[project]
name = "mcp-neo4j-data-modeling"
version = "0.2.0"
description = "A simple Neo4j MCP server for creating graph data models."
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastmcp>=2.0.0",
    "pydantic>=2.10.1",
]


[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
    "ipykernel>=6.29.5",
    "pyright>=1.1.389",
    "pytest>=7.0.0",
    "pytest-asyncio>=0.20.3",
    "ruff>=0.11.5",
    "testcontainers[neo4j]>=4.10.0",
    "aiohttp>=3.8.0"
]

[project.scripts]
mcp-neo4j-data-modeling = "mcp_neo4j_data_modeling:main"
</file>

<file path="mcp-neo4j-data-modeling/pyrightconfig.json">
{
    "venvPath": ".",
    "venv": ".venv"
}
</file>

<file path="mcp-neo4j-data-modeling/README.md">
# 🔍📊 Neo4j Data Modeling MCP Server

## 🌟 Overview

A Model Context Protocol (MCP) server implementation that provides tools for creating, visualizing, and managing Neo4j graph data models. This server enables you to define nodes, relationships, and properties to design graph database schemas that can be visualized interactively.

## 🧩 Components

### 📦 Resources

The server provides these resources:

- `resource://schema/node`
   - Get the JSON schema for a Node object
   - Returns: JSON schema defining the structure of a Node

- `resource://schema/relationship`
   - Get the JSON schema for a Relationship object
   - Returns: JSON schema defining the structure of a Relationship

- `resource://schema/property`
   - Get the JSON schema for a Property object
   - Returns: JSON schema defining the structure of a Property

- `resource://schema/data_model`
   - Get the JSON schema for a DataModel object
   - Returns: JSON schema defining the structure of a DataModel
  
- `resource://neo4j_data_ingest_process`
   - Get a detailed explanation of the recommended process for ingesting data into Neo4j using the data model
   - Returns: Markdown document explaining the ingest process


### 🛠️ Tools

The server offers these core tools:

#### ✅ Validation Tools
- `validate_node`
   - Validate a single node structure
   - Input:
     - `node` (Node): The node to validate
   - Returns: True if valid, raises ValueError if invalid

- `validate_relationship`
   - Validate a single relationship structure
   - Input:
     - `relationship` (Relationship): The relationship to validate
   - Returns: True if valid, raises ValueError if invalid

- `validate_data_model`
   - Validate the entire data model structure
   - Input:
     - `data_model` (DataModel): The data model to validate
   - Returns: True if valid, raises ValueError if invalid

#### 👁️ Visualization Tools
- `get_mermaid_config_str`
   - Generate a Mermaid diagram configuration string for the data model, suitable for visualization in tools that support Mermaid
   - Input:
     - `data_model` (DataModel): The data model to visualize
   - Returns: Mermaid configuration string representing the data model

#### 🔄 Import/Export Tools

These tools provide integration with **[Arrows](https://arrows.app/)** - a graph drawing web application for creating detailed Neo4j data models with an intuitive visual interface.

- `load_from_arrows_json`
   - Load a data model from Arrows app JSON format
   - Input:
     - `arrows_data_model_dict` (dict): JSON dictionary from Arrows app export
   - Returns: DataModel object

- `export_to_arrows_json`
   - Export a data model to Arrows app JSON format
   - Input:
     - `data_model` (DataModel): The data model to export
   - Returns: JSON string compatible with Arrows app

#### 📝 Cypher Ingest Tools

These tools may be used to create Cypher ingest queries based on the data model. These queries may then be used by other MCP servers or applications to load data into Neo4j.

- `get_constraints_cypher_queries`
   - Generate Cypher queries to create constraints (e.g., unique keys) for all nodes in the data model
   - Input:
     - `data_model` (DataModel): The data model to generate constraints for
   - Returns: List of Cypher statements for constraints

- `get_node_cypher_ingest_query`
   - Generate a Cypher query to ingest a list of node records into Neo4j
   - Input:
     - `node` (Node): The node definition (label, key property, properties)
   - Returns: Parameterized Cypher query for bulk node ingestion (using `$records`)

- `get_relationship_cypher_ingest_query`
   - Generate a Cypher query to ingest a list of relationship records into Neo4j
   - Input:
     - `data_model` (DataModel): The data model containing nodes and relationships
     - `relationship_type` (str): The type of the relationship
     - `relationship_start_node_label` (str): The label of the start node
     - `relationship_end_node_label` (str): The label of the end node
   - Returns: Parameterized Cypher query for bulk relationship ingestion (using `$records`)

## 🔧 Usage with Claude Desktop

### 💾 Released Package

Can be found on PyPi https://pypi.org/project/mcp-neo4j-data-modeling/

Add the server to your `claude_desktop_config.json` with the transport method specified:

```json
"mcpServers": {
  "neo4j-data-modeling": {
    "command": "uvx",
    "args": [ "mcp-neo4j-data-modeling@0.2.0", "--transport", "stdio" ]
  }
}
```

### 🌐 HTTP Transport Mode

The server supports HTTP transport for web-based deployments and microservices:

```bash
# Basic HTTP mode (defaults: host=127.0.0.1, port=8000, path=/mcp/)
mcp-neo4j-data-modeling --transport http

# Custom HTTP configuration
mcp-neo4j-data-modeling --transport http --host 0.0.0.0 --port 8080 --path /api/mcp/
```

Environment variables for HTTP configuration:

```bash
export MCP_TRANSPORT=http
export NEO4J_MCP_SERVER_HOST=0.0.0.0
export NEO4J_MCP_SERVER_PORT=8080
export NEO4J_MCP_SERVER_PATH=/api/mcp/
mcp-neo4j-data-modeling
```

### 🔄 Transport Modes

The server supports three transport modes:

- **STDIO** (default): Standard input/output for local tools and Claude Desktop
- **SSE**: Server-Sent Events for web-based deployments  
- **HTTP**: Streamable HTTP for modern web deployments and microservices

### 🐳 Using with Docker

```json
"mcpServers": {
  "neo4j-data-modeling": {
    "command": "docker",
    "args": [
      "run",
      "--rm",
      "mcp/neo4j-data-modeling:latest"
    ]
  }
}
```

## 🚀 Development

### 📦 Prerequisites

1. Install `uv` (Universal Virtualenv):
```bash
# Using pip
pip install uv

# Using Homebrew on macOS
brew install uv

# Using cargo (Rust package manager)
cargo install uv
```

2. Clone the repository and set up development environment:
```bash
# Clone the repository
git clone https://github.com/yourusername/mcp-neo4j-data-modeling.git
cd mcp-neo4j-data-modeling

# Create and activate virtual environment using uv
uv venv
source .venv/bin/activate  # On Unix/macOS
.venv\Scripts\activate     # On Windows

# Install dependencies including dev dependencies
uv pip install -e ".[dev]"
```

3. Run Tests

```bash
./test.sh
```

### 🔧 Development Configuration

```json
# Add the server to your claude_desktop_config.json
"mcpServers": {
  "neo4j-data-modeling": {
    "command": "uv",
    "args": [
      "--directory", "path_to_repo/src",
      "run", "mcp-neo4j-data-modeling", "--transport", "stdio"]
  }
}
```

### 🐳 Docker

Build and run the Docker container:

```bash
# Build the image
docker build -t mcp/neo4j-data-modeling:latest .

# Run the container
docker run mcp/neo4j-data-modeling:latest
```

## 📄 License

This MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.
</file>

<file path="mcp-neo4j-memory/src/mcp_neo4j_memory/__init__.py">
from . import server
import asyncio
import argparse
import os


def main():
    """Main entry point for the package."""
    parser = argparse.ArgumentParser(description='Neo4j Memory MCP Server')
    parser.add_argument('--db-url', default=None, help='Neo4j connection URL')
    parser.add_argument('--username', default=None, help='Neo4j username')
    parser.add_argument('--password', default=None, help='Neo4j password')
    parser.add_argument("--database", default=None, help="Neo4j database name")
    parser.add_argument("--transport", default=None, help="Transport type (stdio, sse, http)")
    parser.add_argument("--server-host", default=None, help="HTTP host (default: 127.0.0.1)")
    parser.add_argument("--server-port", type=int, default=None, help="HTTP port (default: 8000)")
    parser.add_argument("--server-path", default=None, help="HTTP path (default: /mcp/)")
    
    args = parser.parse_args()
    asyncio.run(server.main(
        args.db_url or os.getenv("NEO4J_URL") or os.getenv("NEO4J_URI", "bolt://localhost:7687"),
        args.username or os.getenv("NEO4J_USERNAME", "neo4j"),
        args.password or os.getenv("NEO4J_PASSWORD", "password"),
        args.database or os.getenv("NEO4J_DATABASE", "neo4j"),
        args.transport or os.getenv("NEO4J_TRANSPORT", "stdio"),
        args.server_host or os.getenv("NEO4J_MCP_SERVER_HOST", "127.0.0.1"),
        args.server_port or int(os.getenv("NEO4J_MCP_SERVER_PORT", "8000")),
        args.server_path or os.getenv("NEO4J_MCP_SERVER_PATH", "/mcp/"),
    ))


# Optionally expose other important items at package level
__all__ = ["main", "server"]
</file>

<file path="mcp-neo4j-memory/src/mcp_neo4j_memory/neo4j_memory.py">
import logging
from typing import Any, Dict, List

from neo4j import AsyncDriver, RoutingControl
from pydantic import BaseModel


# Set up logging
logger = logging.getLogger('mcp_neo4j_memory')
logger.setLevel(logging.INFO)

# Models for our knowledge graph
class Entity(BaseModel):
    name: str
    type: str
    observations: List[str]

class Relation(BaseModel):
    source: str
    target: str
    relationType: str

class KnowledgeGraph(BaseModel):
    entities: List[Entity]
    relations: List[Relation]

class ObservationAddition(BaseModel):
    entityName: str
    observations: List[str]

class ObservationDeletion(BaseModel):
    entityName: str
    observations: List[str]

class Neo4jMemory:
    def __init__(self, neo4j_driver: AsyncDriver):
        self.driver = neo4j_driver

    async def create_fulltext_index(self):
        """Create a fulltext search index for entities if it doesn't exist."""
        try:
            query = "CREATE FULLTEXT INDEX search IF NOT EXISTS FOR (m:Memory) ON EACH [m.name, m.type, m.observations];"
            await self.driver.execute_query(query, routing_control=RoutingControl.WRITE)
            logger.info("Created fulltext search index")
        except Exception as e:
            # Index might already exist, which is fine
            logger.debug(f"Fulltext index creation: {e}")

    async def load_graph(self, filter_query: str = "*"):
        """Load the entire knowledge graph from Neo4j."""
        logger.info("Loading knowledge graph from Neo4j")
        query = """
            CALL db.index.fulltext.queryNodes('search', $filter) yield node as entity, score
            OPTIONAL MATCH (entity)-[r]-(other)
            RETURN collect(distinct {
                name: entity.name, 
                type: entity.type, 
                observations: entity.observations
            }) as nodes,
            collect(distinct {
                source: startNode(r).name, 
                target: endNode(r).name, 
                relationType: type(r)
            }) as relations
        """
        
        result = await self.driver.execute_query(query, {"filter": filter_query}, routing_control=RoutingControl.READ)
        
        if not result.records:
            return KnowledgeGraph(entities=[], relations=[])
        
        record = result.records[0]
        nodes = record.get('nodes', list())
        rels = record.get('relations', list())
        
        entities = [
            Entity(
                name=node['name'],
                type=node['type'],
                observations=node.get('observations', list())
            )
            for node in nodes if node.get('name')
        ]
        
        relations = [
            Relation(
                source=rel['source'],
                target=rel['target'],
                relationType=rel['relationType']
            )
            for rel in rels if rel.get('relationType')
        ]
        
        logger.debug(f"Loaded entities: {entities}")
        logger.debug(f"Loaded relations: {relations}")
        
        return KnowledgeGraph(entities=entities, relations=relations)

    async def create_entities(self, entities: List[Entity]) -> List[Entity]:
        """Create multiple new entities in the knowledge graph."""
        logger.info(f"Creating {len(entities)} entities")
        for entity in entities:
            query = f"""
            WITH $entity as entity
            MERGE (e:Memory {{ name: entity.name }})
            SET e += entity {{ .type, .observations }}
            SET e:{entity.type}
            """
            await self.driver.execute_query(query, {"entity": entity.model_dump()}, routing_control=RoutingControl.WRITE)

        return entities

    async def create_relations(self, relations: List[Relation]) -> List[Relation]:
        """Create multiple new relations between entities."""
        logger.info(f"Creating {len(relations)} relations")
        for relation in relations:
            query = f"""
            WITH $relation as relation
            MATCH (from:Memory),(to:Memory)
            WHERE from.name = relation.source
            AND  to.name = relation.target
            MERGE (from)-[r:{relation.relationType}]->(to)
            """
            
            await self.driver.execute_query(
                query, 
                {"relation": relation.model_dump()},
                routing_control=RoutingControl.WRITE
            )

        return relations

    async def add_observations(self, observations: List[ObservationAddition]) -> List[Dict[str, Any]]:
        """Add new observations to existing entities."""
        logger.info(f"Adding observations to {len(observations)} entities")
        query = """
        UNWIND $observations as obs  
        MATCH (e:Memory { name: obs.entityName })
        WITH e, [o in obs.observations WHERE NOT o IN e.observations] as new
        SET e.observations = coalesce(e.observations,[]) + new
        RETURN e.name as name, new
        """
            
        result = await self.driver.execute_query(
            query, 
            {"observations": [obs.model_dump() for obs in observations]},
            routing_control=RoutingControl.WRITE
        )

        results = [{"entityName": record.get("name"), "addedObservations": record.get("new")} for record in result.records]
        return results

    async def delete_entities(self, entity_names: List[str]) -> None:
        """Delete multiple entities and their associated relations."""
        logger.info(f"Deleting {len(entity_names)} entities")
        query = """
        UNWIND $entities as name
        MATCH (e:Memory { name: name })
        DETACH DELETE e
        """
        
        await self.driver.execute_query(query, {"entities": entity_names}, routing_control=RoutingControl.WRITE)
        logger.info(f"Successfully deleted {len(entity_names)} entities")

    async def delete_observations(self, deletions: List[ObservationDeletion]) -> None:
        """Delete specific observations from entities."""
        logger.info(f"Deleting observations from {len(deletions)} entities")
        query = """
        UNWIND $deletions as d  
        MATCH (e:Memory { name: d.entityName })
        SET e.observations = [o in coalesce(e.observations,[]) WHERE NOT o IN d.observations]
        """
        await self.driver.execute_query(
            query, 
            {"deletions": [deletion.model_dump() for deletion in deletions]},
            routing_control=RoutingControl.WRITE
        )
        logger.info(f"Successfully deleted observations from {len(deletions)} entities")

    async def delete_relations(self, relations: List[Relation]) -> None:
        """Delete multiple relations from the graph."""
        logger.info(f"Deleting {len(relations)} relations")
        for relation in relations:
            query = f"""
            WITH $relation as relation
            MATCH (source:Memory)-[r:{relation.relationType}]->(target:Memory)
            WHERE source.name = relation.source
            AND target.name = relation.target
            DELETE r
            """
            await self.driver.execute_query(
                query, 
                {"relation": relation.model_dump()},
                routing_control=RoutingControl.WRITE
            )
        logger.info(f"Successfully deleted {len(relations)} relations")

    async def read_graph(self) -> KnowledgeGraph:
        """Read the entire knowledge graph."""
        return await self.load_graph()

    async def search_memories(self, query: str) -> KnowledgeGraph:
        """Search for memories based on a query with Fulltext Search."""
        logger.info(f"Searching for memories with query: '{query}'")
        return await self.load_graph(query)

    async def find_memories_by_name(self, names: List[str]) -> KnowledgeGraph:
        """Find specific memories by their names. This does not use fulltext search."""
        logger.info(f"Finding {len(names)} memories by name")
        query = """
        MATCH (e:Memory)
        WHERE e.name IN $names
        RETURN  e.name as name, 
                e.type as type, 
                e.observations as observations
        """
        result_nodes = await self.driver.execute_query(query, {"names": names}, routing_control=RoutingControl.READ)
        entities: list[Entity] = list()
        for record in result_nodes.records:
            entities.append(Entity(
                name=record['name'],
                type=record['type'],
                observations=record.get('observations', list())
            ))
        
        # Get relations for found entities
        relations: list[Relation] = list()
        if entities:
            query = """
            MATCH (source:Memory)-[r]->(target:Memory)
            WHERE source.name IN $names OR target.name IN $names
            RETURN  source.name as source, 
                    target.name as target, 
                    type(r) as relationType
            """
            result_relations = await self.driver.execute_query(query, {"names": names}, routing_control=RoutingControl.READ)
            for record in result_relations.records:
                relations.append(Relation(
                    source=record["source"],
                    target=record["target"],
                    relationType=record["relationType"]
                ))
        
        logger.info(f"Found {len(entities)} entities and {len(relations)} relations")
        return KnowledgeGraph(entities=entities, relations=relations)
</file>

<file path="mcp-neo4j-memory/src/mcp_neo4j_memory/server.py">
import json
import logging
from typing import Literal

from neo4j import AsyncGraphDatabase
from pydantic import Field

from fastmcp.server import FastMCP
from fastmcp.exceptions import ToolError
from fastmcp.tools.tool import ToolResult, TextContent
from neo4j.exceptions import Neo4jError
from mcp.types import ToolAnnotations

from .neo4j_memory import Neo4jMemory, Entity, Relation, ObservationAddition, ObservationDeletion, KnowledgeGraph

# Set up logging
logger = logging.getLogger('mcp_neo4j_memory')
logger.setLevel(logging.INFO)


def create_mcp_server(memory: Neo4jMemory) -> FastMCP:
    """Create an MCP server instance for memory management."""
    
    mcp: FastMCP = FastMCP("mcp-neo4j-memory", dependencies=["neo4j", "pydantic"], stateless_http=True)

    @mcp.tool(annotations=ToolAnnotations(title="Read Graph", 
                                          readOnlyHint=True, 
                                          destructiveHint=False, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def read_graph() -> KnowledgeGraph:
        """Read the entire knowledge graph."""
        logger.info("MCP tool: read_graph")
        try:
            result = await memory.read_graph()
            return ToolResult(content=[TextContent(type="text", text=result.model_dump_json())],
                          structured_content=result)
        except Neo4jError as e:
            logger.error(f"Neo4j error reading full knowledge graph: {e}")
            raise ToolError(f"Neo4j error reading full knowledge graph: {e}")
        except Exception as e:
            logger.error(f"Error reading full knowledge graph: {e}")
            raise ToolError(f"Error reading full knowledge graph: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Create Entities", 
                                          readOnlyHint=False, 
                                          destructiveHint=False, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def create_entities(entities: list[Entity] = Field(..., description="List of entities to create")) -> list[Entity]:
        """Create multiple new entities in the knowledge graph."""
        logger.info(f"MCP tool: create_entities ({len(entities)} entities)")
        try:
            entity_objects = [Entity.model_validate(entity) for entity in entities]
            result = await memory.create_entities(entity_objects)
            return ToolResult(content=[TextContent(type="text", text=json.dumps([e.model_dump() for e in result]))],
                          structured_content={"result": result})
        except Neo4jError as e:
            logger.error(f"Neo4j error creating entities: {e}")
            raise ToolError(f"Neo4j error creating entities: {e}")
        except Exception as e:
            logger.error(f"Error creating entities: {e}")
            raise ToolError(f"Error creating entities: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Create Relations", 
                                          readOnlyHint=False, 
                                          destructiveHint=False, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def create_relations(relations: list[Relation] = Field(..., description="List of relations to create")) -> list[Relation]:
        """Create multiple new relations between entities."""
        logger.info(f"MCP tool: create_relations ({len(relations)} relations)")
        try:
            relation_objects = [Relation.model_validate(relation) for relation in relations]
            result = await memory.create_relations(relation_objects)
            return ToolResult(content=[TextContent(type="text", text=json.dumps([r.model_dump() for r in result]))],
                          structured_content={"result": result})
        except Neo4jError as e:
            logger.error(f"Neo4j error creating relations: {e}")
            raise ToolError(f"Neo4j error creating relations: {e}")
        except Exception as e:
            logger.error(f"Error creating relations: {e}")
            raise ToolError(f"Error creating relations: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Add Observations", 
                                          readOnlyHint=False, 
                                          destructiveHint=False, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def add_observations(observations: list[ObservationAddition] = Field(..., description="List of observations to add")) -> list[dict[str, str | list[str]]]:
        """Add new observations to existing entities."""
        logger.info(f"MCP tool: add_observations ({len(observations)} additions)")
        try:
            observation_objects = [ObservationAddition.model_validate(obs) for obs in observations]
            result = await memory.add_observations(observation_objects)
            return ToolResult(content=[TextContent(type="text", text=json.dumps(result))],
                          structured_content={"result": result})
        except Neo4jError as e:
            logger.error(f"Neo4j error adding observations: {e}")
            raise ToolError(f"Neo4j error adding observations: {e}")
        except Exception as e:
            logger.error(f"Error adding observations: {e}")
            raise ToolError(f"Error adding observations: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Delete Entities", 
                                          readOnlyHint=False, 
                                          destructiveHint=True, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def delete_entities(entityNames: list[str] = Field(..., description="List of entity names to delete")) -> str:
        """Delete multiple entities and their associated relations."""
        logger.info(f"MCP tool: delete_entities ({len(entityNames)} entities)")
        try:
            await memory.delete_entities(entityNames)
            return ToolResult(content=[TextContent(type="text", text="Entities deleted successfully")],
                              structured_content={"result": "Entities deleted successfully"})
        except Neo4jError as e:
            logger.error(f"Neo4j error deleting entities: {e}")
            raise ToolError(f"Neo4j error deleting entities: {e}")
        except Exception as e:
            logger.error(f"Error deleting entities: {e}")
            raise ToolError(f"Error deleting entities: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Delete Observations", 
                                          readOnlyHint=False, 
                                          destructiveHint=True, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def delete_observations(deletions: list[ObservationDeletion] = Field(..., description="List of observations to delete")) -> str:
        """Delete specific observations from entities."""
        logger.info(f"MCP tool: delete_observations ({len(deletions)} deletions)")
        try:    
            deletion_objects = [ObservationDeletion.model_validate(deletion) for deletion in deletions]
            await memory.delete_observations(deletion_objects)
            return ToolResult(content=[TextContent(type="text", text="Observations deleted successfully")],
                          structured_content={"result": "Observations deleted successfully"})
        except Neo4jError as e:
            logger.error(f"Neo4j error deleting observations: {e}")
            raise ToolError(f"Neo4j error deleting observations: {e}")
        except Exception as e:
            logger.error(f"Error deleting observations: {e}")
            raise ToolError(f"Error deleting observations: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Delete Relations", 
                                          readOnlyHint=False, 
                                          destructiveHint=True, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def delete_relations(relations: list[Relation] = Field(..., description="List of relations to delete")) -> str:
        """Delete multiple relations from the graph."""
        logger.info(f"MCP tool: delete_relations ({len(relations)} relations)")
        try:
            relation_objects = [Relation.model_validate(relation) for relation in relations]
            await memory.delete_relations(relation_objects)
            return ToolResult(content=[TextContent(type="text", text="Relations deleted successfully")],
                          structured_content={"result": "Relations deleted successfully"})
        except Neo4jError as e:
            logger.error(f"Neo4j error deleting relations: {e}")
            raise ToolError(f"Neo4j error deleting relations: {e}")
        except Exception as e:
            logger.error(f"Error deleting relations: {e}")
            raise ToolError(f"Error deleting relations: {e}")

    @mcp.tool(annotations=ToolAnnotations(title="Search Memories", 
                                          readOnlyHint=True, 
                                          destructiveHint=False, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def search_memories(query: str = Field(..., description="Search query for nodes")) -> KnowledgeGraph:
        """Search for memories based on a query containing search terms."""
        logger.info(f"MCP tool: search_memories ('{query}')")
        try:
            result = await memory.search_memories(query)
            return ToolResult(content=[TextContent(type="text", text=result.model_dump_json())],
                              structured_content=result)
        except Neo4jError as e:
            logger.error(f"Neo4j error searching memories: {e}")
            raise ToolError(f"Neo4j error searching memories: {e}")
        except Exception as e:
            logger.error(f"Error searching memories: {e}")
            raise ToolError(f"Error searching memories: {e}")
        
    @mcp.tool(annotations=ToolAnnotations(title="Find Memories by Name", 
                                          readOnlyHint=True, 
                                          destructiveHint=False, 
                                          idempotentHint=True, 
                                          openWorldHint=True))
    async def find_memories_by_name(names: list[str] = Field(..., description="List of node names to find")) -> KnowledgeGraph:
        """Find specific memories by name."""
        logger.info(f"MCP tool: find_memories_by_name ({len(names)} names)")
        try:
            result = await memory.find_memories_by_name(names)
            return ToolResult(content=[TextContent(type="text", text=result.model_dump_json())],
                              structured_content=result)
        except Neo4jError as e:
            logger.error(f"Neo4j error finding memories by name: {e}")
            raise ToolError(f"Neo4j error finding memories by name: {e}")
        except Exception as e:
            logger.error(f"Error finding memories by name: {e}")
            raise ToolError(f"Error finding memories by name: {e}")

    return mcp


async def main(
    neo4j_uri: str, 
    neo4j_user: str, 
    neo4j_password: str, 
    neo4j_database: str,
    transport: Literal["stdio", "sse", "http"] = "stdio",
    host: str = "127.0.0.1",
    port: int = 8000,
    path: str = "/mcp/",
) -> None:
    logger.info(f"Starting Neo4j MCP Memory Server")
    logger.info(f"Connecting to Neo4j with DB URL: {neo4j_uri}")

    # Connect to Neo4j
    neo4j_driver = AsyncGraphDatabase.driver(
        neo4j_uri,
        auth=(neo4j_user, neo4j_password), 
        database=neo4j_database
    )
    
    # Verify connection
    try:
        await neo4j_driver.verify_connectivity()
        logger.info(f"Connected to Neo4j at {neo4j_uri}")
    except Exception as e:
        logger.error(f"Failed to connect to Neo4j: {e}")
        exit(1)

    # Initialize memory
    memory = Neo4jMemory(neo4j_driver)
    logger.info("Neo4jMemory initialized")
    
    # Create fulltext index
    await memory.create_fulltext_index()
    
    # Create MCP server
    mcp = create_mcp_server(memory)
    logger.info("MCP server created")

    # Run the server with the specified transport
    logger.info(f"Starting server with transport: {transport}")
    match transport:
        case "http":
            logger.info(f"HTTP server starting on {host}:{port}{path}")
            await mcp.run_http_async(host=host, port=port, path=path)
        case "stdio":
            logger.info("STDIO server starting")
            await mcp.run_stdio_async()
        case "sse":
            logger.info(f"SSE server starting on {host}:{port}{path}")
            await mcp.run_sse_async(host=host, port=port, path=path)
        case _:
            raise ValueError(f"Unsupported transport: {transport}")
</file>

<file path="mcp-neo4j-memory/tests/integration/conftest.py">
import asyncio
import os
import subprocess
from typing import Any

import pytest
import pytest_asyncio
from neo4j import GraphDatabase
from testcontainers.neo4j import Neo4jContainer

from mcp_neo4j_memory.server import Neo4jMemory, create_mcp_server

neo4j = (
    Neo4jContainer("neo4j:latest")
    .with_env("NEO4J_apoc_export_file_enabled", "true")
    .with_env("NEO4J_apoc_import_file_enabled", "true")
    .with_env("NEO4J_apoc_import_file_use__neo4j__config", "true")
    .with_env("NEO4J_PLUGINS", '["apoc"]')
)

@pytest.fixture(scope="module", autouse=True)
def setup(request):
    neo4j.start()

    def remove_container():
        neo4j.get_driver().close()
        neo4j.stop()

    request.addfinalizer(remove_container)
    os.environ["NEO4J_URI"] = neo4j.get_connection_url()
    os.environ["NEO4J_HOST"] = neo4j.get_container_host_ip()
    os.environ["NEO4J_PORT"] = neo4j.get_exposed_port(7687)

    yield neo4j

@pytest_asyncio.fixture(scope="function")
async def async_neo4j_driver(setup: Neo4jContainer):
    driver = GraphDatabase.driver(
        setup.get_connection_url(), auth=(setup.username, setup.password)
    )
    try:
        yield driver
    finally:
        await driver.close() 

@pytest.fixture
def memory(neo4j_driver):
    """Create a memory instance."""
    return Neo4jMemory(neo4j_driver)

@pytest.fixture
def mcp_server(neo4j_driver, memory):
    """Create an MCP server instance."""
    return create_mcp_server(neo4j_driver, memory)


@pytest_asyncio.fixture
async def sse_server(setup: Neo4jContainer):
    """Start the MCP server in SSE mode."""

    
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-memory", 
        "--transport", "sse", 
        "--server-host", "127.0.0.1", 
        "--server-port", "8002",
        "--db-url", setup.get_connection_url(),
        "--username", setup.username,
        "--password", setup.password,
        "--database", "neo4j",
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    await asyncio.sleep(3)
    
    if process.returncode is not None:
        stdout, stderr = await process.communicate()
        raise RuntimeError(f"Server failed to start. stdout: {stdout.decode()}, stderr: {stderr.decode()}")
    
    yield process
    
    try:
        process.terminate()
        await asyncio.wait_for(process.wait(), timeout=5.0)
    except asyncio.TimeoutError:
        process.kill()
        await process.wait()
</file>

<file path="mcp-neo4j-memory/tests/integration/test_http_transport_IT.py">
import asyncio
import json
import os
import pytest
import aiohttp
import subprocess
import uuid

import pytest_asyncio
from testcontainers.neo4j import Neo4jContainer



async def parse_sse_response(response: aiohttp.ClientResponse) -> dict:
    """Parse Server-Sent Events response from FastMCP 2.0."""
    content = await response.text()
    lines = content.strip().split('\n')
    
    # Find the data line that contains the JSON
    for line in lines:
        if line.startswith('data: '):
            json_str = line[6:]  # Remove 'data: ' prefix
            return json.loads(json_str)
    
    raise ValueError("No data line found in SSE response")



class TestHTTPEndpoints:
    """Test HTTP endpoints work correctly."""

    @pytest_asyncio.fixture
    async def http_server(self, setup: Neo4jContainer):
        """Start the MCP server in HTTP mode."""
        # Set environment variables for the server
        env = os.environ.copy()
        env.update({
            "NEO4J_URI": setup.get_connection_url(),
            "NEO4J_USERNAME": setup.username,
            "NEO4J_PASSWORD": setup.password,
            "NEO4J_DATABASE": "neo4j",
        })
        
        # Start server process in HTTP mode using the installed binary
        process = await asyncio.create_subprocess_exec(
            "uv", "run", "mcp-neo4j-memory", 
            "--transport", "http", 
            "--server-host", "127.0.0.1", 
            "--server-port", "8004",
            "--db-url", setup.get_connection_url(),
            "--username", setup.username,
            "--password", setup.password,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=os.getcwd()
        )
        
        # Wait for server to start (increase to 10 seconds)
        await asyncio.sleep(10)
        
        # Check if process is still running
        if process.returncode is not None:
            stdout, stderr = await process.communicate()
            print(f"Server failed to start. stdout: {stdout.decode()}")
            print(f"Server failed to start. stderr: {stderr.decode()}")
            raise RuntimeError(f"Server failed to start. stdout: {stdout.decode()}, stderr: {stderr.decode()}")
        
        yield process
        
        # Cleanup
        try:
            process.terminate()
            await asyncio.wait_for(process.wait(), timeout=5.0)
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()

    @pytest.mark.asyncio
    async def test_http_tools_list(self, http_server):
        """Test that tools/list endpoint works."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8004/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/list"
                },
                headers={
                    "Accept": "application/json, text/event-stream",
                    "Content-Type": "application/json",
                    "mcp-session-id": session_id
                }
            ) as response:
                print(f"Response status: {response.status}")
                print(f"Response headers: {response.headers}")
                response_text = await response.text()
                print(f"Response text: {response_text}")
                
                assert response.status == 200, f"Server returned status {response.status}: {response_text}"
                result = await parse_sse_response(response)
                assert "result" in result
                assert "tools" in result["result"]
                tools = result["result"].get("tools")
                assert tools is not None
                tool_names = [tool.get("name") for tool in tools]
                assert "read_graph" in tool_names

    @pytest.mark.asyncio
    async def test_http_read_graph(self, http_server):
        """Test that read_graph endpoint works."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8004/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "read_graph",
                        "arguments": {}
                    }
                },
                headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                assert "result" in result
                assert "content" in result["result"]
                # Parse the content
                content = result["result"]["content"] # type: ignore
                assert len(content) > 0
                # The content contains the actual data directly
                actual_data = content[0].get("text", "")
                assert "entities" in actual_data
                assert "relations" in actual_data

    @pytest.mark.asyncio
    async def test_http_create_entities(self, http_server):
        """Test that create_entities endpoint works."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8004/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "create_entities",
                        "arguments": {
                            "entities": [
                                {
                                    "name": "Test Entity",
                                    "type": "Test",
                                    "observations": ["This is a test entity"]
                                }
                            ]
                        }
                    }
                },
                headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                assert "result" in result
                assert "content" in result["result"]
                # Parse the content
                content = result["result"]["content"] # type: ignore
                assert len(content) > 0
                # The content contains the actual data directly
                actual_data = content[0].get("text", "")
                assert "name" in actual_data
                assert "type" in actual_data
                assert "observations" in actual_data

    @pytest.mark.asyncio
    async def test_http_search_nodes(self, http_server):
        """Test that search_nodes endpoint works."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8004/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "search_nodes",
                        "arguments": {
                            "query": "test"
                        }
                    }
                },
                headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                assert "result" in result
                assert "content" in result["result"]
                # Parse the content
                content = result["result"]["content"] # type: ignore
                assert len(content) > 0
                # The content contains the actual data directly
                actual_data = content[0]
                # For now, just verify we get a response (the search tool has a parameter conflict)
                # TODO: Fix the search_nodes tool parameter conflict
                assert isinstance(actual_data, dict)


class TestErrorHandling:
    """Test error handling in HTTP transport."""

    @pytest_asyncio.fixture
    async def http_server(self, setup: Neo4jContainer):
        """Start the MCP server in HTTP mode."""
        env = os.environ.copy()
        env.update({
            "NEO4J_URI": setup.get_connection_url(),
            "NEO4J_USERNAME": setup.username,
            "NEO4J_PASSWORD": setup.password,
            "NEO4J_DATABASE": "neo4j",
        })
        
        process = await asyncio.create_subprocess_exec(
            "uv", "run", "mcp-neo4j-memory", "--transport", "http", "--server-host", "127.0.0.1", "--server-port", "8005",
            "--db-url", setup.get_connection_url(),
            "--username", setup.username,
            "--password", setup.password,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=os.getcwd()
        )
        await asyncio.sleep(3)
        yield process
        process.terminate()
        await process.wait()

    @pytest.mark.asyncio
    async def test_invalid_json(self, http_server):
        """Test handling of invalid JSON."""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8005/mcp/",
                data="invalid json",
                headers={"Content-Type": "application/json"}
            ) as response:
                assert response.status == 406  # FastMCP returns 406 for missing Accept header

    @pytest.mark.asyncio
    async def test_invalid_method(self, http_server):
        """Test handling of invalid method."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8005/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "invalid_method"
                },
                headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Accept either JSON-RPC error or result with isError
                assert ("result" in result and result["result"].get("isError", False)) or ("error" in result)

    @pytest.mark.asyncio
    async def test_invalid_tool_call(self, http_server):
        """Test handling of invalid tool call."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8005/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "nonexistent_tool",
                        "arguments": {}
                    }
                },
                headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # FastMCP returns errors in result field with isError: True
                assert "result" in result
                assert result["result"].get("isError", False)

    @pytest.mark.asyncio
    async def test_invalid_entity_data(self, http_server):
        """Test handling of invalid entity data."""
        session_id = str(uuid.uuid4())
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://127.0.0.1:8005/mcp/",
                json={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "method": "tools/call",
                    "params": {
                        "name": "create_entities",
                        "arguments": {
                            "entities": [
                                {
                                    "name": "Test Entity",
                                    # Missing required fields
                                }
                            ]
                        }
                    }
                },
                headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
            ) as response:
                result = await parse_sse_response(response)
                assert response.status == 200
                # Should return an error or handle gracefully
                assert "result" in result 


class TestHTTPTransportIntegration:
    """Integration tests for HTTP transport."""

    @pytest.mark.asyncio
    async def test_full_workflow(self, setup: Neo4jContainer):
        """Test a complete workflow over HTTP transport."""
        env = os.environ.copy()
        env.update({
            "NEO4J_URI": setup.get_connection_url(),
            "NEO4J_USERNAME": setup.username,
            "NEO4J_PASSWORD": setup.password,
            "NEO4J_DATABASE": "neo4j",
        })
        
        process = await asyncio.create_subprocess_exec(
            "uv", "run", "mcp-neo4j-memory", "--transport", "http", "--server-host", "127.0.0.1", "--server-port", "8006",
            "--db-url", setup.get_connection_url(),
            "--username", setup.username,
            "--password", setup.password,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd=os.getcwd()
        )
        
        await asyncio.sleep(3)
        
        if process.returncode is not None:
            stdout, stderr = await process.communicate()
            raise RuntimeError(f"Server failed to start. stdout: {stdout.decode()}, stderr: {stderr.decode()}")

        try:
            session_id = str(uuid.uuid4())
            async with aiohttp.ClientSession() as session:
                # 1. List tools
                async with session.post(
                    "http://127.0.0.1:8006/mcp/",
                    json={
                        "jsonrpc": "2.0",
                        "id": 1,
                        "method": "tools/list"
                    },
                    headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result
                
                # 2. Read empty graph
                async with session.post(
                    "http://127.0.0.1:8006/mcp/",
                    json={
                        "jsonrpc": "2.0",
                        "id": 2,
                        "method": "tools/call",
                        "params": {
                            "name": "read_graph",
                            "arguments": {}
                        }
                    },
                    headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result
                
                # 3. Create entities
                async with session.post(
                    "http://127.0.0.1:8006/mcp/",
                    json={
                        "jsonrpc": "2.0",
                        "id": 3,
                        "method": "tools/call",
                        "params": {
                            "name": "create_entities",
                            "arguments": {
                                "entities": [
                                    {
                                        "name": "Integration Test Entity",
                                        "type": "Test",
                                        "observations": ["Created via HTTP transport"]
                                    }
                                ]
                            }
                        }
                    },
                    headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result
                
                # 4. Search for the entity
                async with session.post(
                    "http://127.0.0.1:8006/mcp/",
                    json={
                        "jsonrpc": "2.0",
                        "id": 4,
                        "method": "tools/call",
                        "params": {
                            "name": "search_nodes",
                            "arguments": {
                                "query": "Integration Test"
                            }
                        }
                    },
                    headers={"Accept": "application/json, text/event-stream", "Content-Type": "application/json", "mcp-session-id": session_id}
                ) as response:
                    result = await parse_sse_response(response)
                    assert response.status == 200
                    assert "result" in result
                    
        finally:
            process.terminate()
            await process.wait()
</file>

<file path="mcp-neo4j-memory/tests/integration/test_neo4j_memory_IT.py">
import os
import pytest
import pytest_asyncio

from neo4j import AsyncGraphDatabase
from mcp_neo4j_memory.server import Neo4jMemory, Entity, Relation, ObservationAddition, ObservationDeletion, KnowledgeGraph

def get_neo4j_driver():
    uri = os.environ.get("NEO4J_URI", "neo4j://localhost:7687")
    user = os.environ.get("NEO4J_USERNAME", "neo4j")
    password = os.environ.get("NEO4J_PASSWORD", "password")
    return AsyncGraphDatabase.driver(uri, auth=(user, password))

@pytest_asyncio.fixture(scope="function")
async def neo4j_driver():
    driver = get_neo4j_driver()
    # Verify connection
    try:
        await driver.verify_connectivity()
    except Exception as e:
        pytest.skip(f"Could not connect to Neo4j: {e}")
    yield driver
    async with driver.session() as session:
        await session.run("MATCH (n:Memory) DETACH DELETE n")
    await driver.close()

@pytest_asyncio.fixture(scope="function")
async def memory(neo4j_driver) -> Neo4jMemory:
    """Create a Neo4jMemory instance with the Neo4j driver."""
    mem = Neo4jMemory(neo4j_driver)
    await mem.create_fulltext_index()
    return mem

@pytest.mark.asyncio
async def test_create_and_read_entities(memory: Neo4jMemory):
    # Create test entities
    test_entities = [
        Entity(name="Alice", type="Person", observations=["Likes reading", "Works at Company X"]),
        Entity(name="Bob", type="Person", observations=["Enjoys hiking"])
    ]
    # Create entities in the graph
    created_entities = await memory.create_entities(test_entities)
    assert len(created_entities) == 2
    
    # Read the graph
    graph = await memory.read_graph()
    
    # Verify entities were created
    assert len(graph.entities) == 2
    
    # Check if entities have correct data
    entities_by_name = {entity.name: entity for entity in graph.entities}
    assert "Alice" in entities_by_name
    assert "Bob" in entities_by_name
    assert entities_by_name["Alice"].type == "Person"
    assert "Likes reading" in entities_by_name["Alice"].observations
    assert "Enjoys hiking" in entities_by_name["Bob"].observations

@pytest.mark.asyncio
async def test_create_and_read_relations(memory: Neo4jMemory):
    # Create test entities
    test_entities = [
        Entity(name="Alice", type="Person", observations=[]),
        Entity(name="Bob", type="Person", observations=[])
    ]
    await memory.create_entities(test_entities)
    
    # Create test relation
    test_relations = [
        Relation(source="Alice", target="Bob", relationType="KNOWS")
    ]
    
    # Create relation in the graph
    created_relations = await memory.create_relations(test_relations)
    assert len(created_relations) == 1
    
    # Read the graph
    graph: KnowledgeGraph = await memory.read_graph()
    
    # Verify relation was created
    assert len(graph.relations) == 1
    relation = graph.relations[0]
    assert relation.source == "Alice"
    assert relation.target == "Bob"
    assert relation.relationType == "KNOWS"

@pytest.mark.asyncio
async def test_add_observations(memory: Neo4jMemory):
    # Create test entity
    test_entity = Entity(name="Charlie", type="Person", observations=["Initial observation"])
    await memory.create_entities([test_entity])
    
    # Add observations
    observation_additions = [
        ObservationAddition(entityName="Charlie", observations=["New observation 1", "New observation 2"])
    ]
    
    result = await memory.add_observations(observation_additions)
    assert len(result) == 1
    
    # Read the graph
    graph = await memory.read_graph()
    
    # Find Charlie
    charlie = next((e for e in graph.entities if e.name == "Charlie"), None)
    assert charlie is not None
    
    # Verify observations were added
    assert "Initial observation" in charlie.observations
    assert "New observation 1" in charlie.observations
    assert "New observation 2" in charlie.observations

@pytest.mark.asyncio
async def test_delete_observations(memory: Neo4jMemory):
    # Create test entity with observations
    test_entity = Entity(
        name="Dave", 
        type="Person", 
        observations=["Observation 1", "Observation 2", "Observation 3"]
    )
    await memory.create_entities([test_entity])
    
    # Delete specific observations
    observation_deletions = [
        ObservationDeletion(entityName="Dave", observations=["Observation 2"])
    ]
    
    await memory.delete_observations(observation_deletions)
    
    # Read the graph
    graph = await memory.read_graph()
    
    # Find Dave
    dave = next((e for e in graph.entities if e.name == "Dave"), None)
    assert dave is not None
    
    # Verify observation was deleted
    assert "Observation 1" in dave.observations
    assert "Observation 2" not in dave.observations
    assert "Observation 3" in dave.observations

@pytest.mark.asyncio
async def test_delete_entities(memory: Neo4jMemory):
    # Create test entities
    test_entities = [
        Entity(name="Eve", type="Person", observations=[]),
        Entity(name="Frank", type="Person", observations=[])
    ]
    await memory.create_entities(test_entities)
    
    # Delete one entity
    await memory.delete_entities(["Eve"])
    
    # Read the graph
    graph = await memory.read_graph()
    
    # Verify Eve was deleted but Frank remains
    entity_names = [e.name for e in graph.entities]
    assert "Eve" not in entity_names
    assert "Frank" in entity_names

@pytest.mark.asyncio
async def test_delete_relations(memory: Neo4jMemory):
    # Create test entities
    test_entities = [
        Entity(name="Grace", type="Person", observations=[]),
        Entity(name="Hank", type="Person", observations=[])
    ]
    await memory.create_entities(test_entities)
    
    # Create test relations
    test_relations = [
        Relation(source="Grace", target="Hank", relationType="KNOWS"),
        Relation(source="Grace", target="Hank", relationType="WORKS_WITH")
    ]
    await memory.create_relations(test_relations)
    
    # Delete one relation
    relations_to_delete = [
        Relation(source="Grace", target="Hank", relationType="KNOWS")
    ]
    await memory.delete_relations(relations_to_delete)
    
    # Read the graph
    graph: KnowledgeGraph = await memory.read_graph()
    
    # Verify only the WORKS_WITH relation remains
    assert len(graph.relations) == 1
    assert graph.relations[0].relationType == "WORKS_WITH"

@pytest.mark.asyncio
async def test_search_nodes(memory: Neo4jMemory):
    # Create test entities
    test_entities = [
        Entity(name="Ian", type="Person", observations=["Likes coffee"]),
        Entity(name="Jane", type="Person", observations=["Likes tea"]),
        Entity(name="coffee", type="Beverage", observations=["Hot drink"])
    ]
    await memory.create_entities(test_entities)
    
    # Search for coffee-related nodes
    result = await memory.search_memories("coffee")
    
    # Verify search results
    entity_names = [e.name for e in result.entities]
    assert "Ian" in entity_names
    assert "coffee" in entity_names
    assert "Jane" not in entity_names

@pytest.mark.asyncio
async def test_find_nodes(memory: Neo4jMemory):
    # Create test entities
    test_entities = [
        Entity(name="Kevin", type="Person", observations=[]),
        Entity(name="Laura", type="Person", observations=[]),
        Entity(name="Mike", type="Person", observations=[])
    ]
    await memory.create_entities(test_entities)


    # Open specific nodes
    result = await memory.find_memories_by_name(["Kevin", "Laura"])

    # Verify only requested nodes are returned
    entity_names = [e.name for e in result.entities]
    assert "Kevin" in entity_names
    assert "Laura" in entity_names
    assert "Mike" not in entity_names
</file>

<file path="mcp-neo4j-memory/tests/integration/test_sse_transport_IT.py">
import aiohttp
import pytest


@pytest.mark.asyncio
async def test_sse_endpoint(sse_server):
    """Test that SSE endpoint is accessible."""
    async with aiohttp.ClientSession() as session:
        async with session.get("http://127.0.0.1:8002/mcp/") as response:
            # SSE endpoint should be accessible
            assert response.status in [200, 404]  # 404 is okay if no specific endpoint
</file>

<file path="mcp-neo4j-memory/tests/integration/test_stdio_transport_IT.py">
import asyncio
import os
import subprocess

import pytest
from testcontainers.neo4j import Neo4jContainer




@pytest.mark.asyncio
async def test_stdio_transport(setup: Neo4jContainer):
    """Test that stdio transport can be started."""
    
    # Test that stdio transport can be started (it should not crash)
    process = await asyncio.create_subprocess_exec(
        "uv", "run", "mcp-neo4j-memory", 
        "--transport", "stdio",
        "--db-url", setup.get_connection_url(),
        "--username", setup.username,
        "--password", setup.password,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=os.getcwd()
    )
    
    # Give it a moment to start
    await asyncio.sleep(1)
    
    # Check if process is still running before trying to terminate
    if process.returncode is None:
        # Process is still running, terminate it
        try:
            process.terminate()
            await asyncio.wait_for(process.wait(), timeout=5.0)
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
    else:
        # Process has already exited, which is fine for this test
        # We just want to verify it didn't crash immediately
        pass
    
    # Process should have started successfully (no immediate crash)
    # If returncode is None, it means the process was still running when we tried to terminate it
    # If returncode is not None, it means the process exited (which is also acceptable for this test)
    assert True  # If we get here, the process started without immediate crash
</file>

<file path="mcp-neo4j-memory/.dockerignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Git
.git
.gitignore

# Docker
Dockerfile
.dockerignore

# Documentation
docs/
*.md
!README.md
!pyproject.toml

# Tests
tests/
test/
testing/
</file>

<file path="mcp-neo4j-memory/CHANGELOG.md">
## Next

### Fixed

### Changed
* Update tool return type hints for structured output
* Move `Neo4jMemory` class and related classes to separate file
* Change tool responses to return the `ToolResponse` object
* Updated tool argument types with Pydantic models

### Added
* Add structured output to tool responses
* Add error handling to catch Neo4j specific errors and improve error responses
* Implement `ToolError` class from FastMCP
* Add tool annotations

## v0.2.0

### Fixed
* Fix bug in `search_nodes` method where query arg wasn't passed properly
* Fix bug where stdio transport was always selected
* Fixed argument parsing in server init

### Changed
* Implement FastMCP with function decorators to simplify server code
* Add HTTP transport option
* Migrate to FastMCP v2.x
* rename tools to be more clear - `search_nodes` into `search_memories` and `find_nodes` into `find_memories_by_name`
* Update underlying Pydantic class `ObservationAddition` to have `observations` field to be consistent with `ObservationDeletion` class
* Update Dockerfile to include `NEO4J_DATABASE`, `NEO4J_TRANSPORT`, `NEO4J_MCP_SERVER_HOST`, `NEO4J_MCP_SERVER_PORT` and `NEO4J_MCP_SERVER_PATH` env variables

### Added
* Add compatibility for NEO4J_URI and NEO4J_URL env variables
* Command in Makefile to easily build and deploy Docker image locally

## v0.1.5

### Fixed
* Remove use of dynamic node labels and relationship types to be compatible with Neo4j versions < 5.26

## v0.1.4

* Create, Read, Update and Delete semantic memories
</file>

<file path="mcp-neo4j-memory/Dockerfile">
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install build dependencies
RUN pip install --no-cache-dir hatchling

# Copy dependency files first
COPY pyproject.toml /app/

# Install runtime dependencies
RUN pip install --no-cache-dir fastmcp>=2.0.0 neo4j>=5.26.0

# Copy the source code
COPY src/ /app/src/
COPY README.md /app/

# Install the package
RUN pip install --no-cache-dir -e .

# Environment variables for Neo4j connection
ENV NEO4J_URL="bolt://host.docker.internal:7687"
ENV NEO4J_USERNAME="neo4j"
ENV NEO4J_PASSWORD="password"
ENV NEO4J_DATABASE="neo4j"
ENV NEO4J_TRANSPORT="http"
ENV NEO4J_MCP_SERVER_HOST="0.0.0.0"
ENV NEO4J_MCP_SERVER_PORT="8000"
ENV NEO4J_MCP_SERVER_PATH="/api/mcp/"

# Command to run the server using the package entry point
CMD ["sh", "-c", "mcp-neo4j-memory"]
</file>

<file path="mcp-neo4j-memory/Makefile">
docker-local-build-run:
	docker build -t mcp-neo4j-memory .
	docker run -p 8000:8000 mcp-neo4j-memory:latest

install-dev:
	uv run python3 -m uv pip install -e .

test-unit:
	uv run python3 -m pytest tests/unit/ -v

test-integration:
	uv run python3 -m pytest tests/integration/ -v

test-http:
	uv run python3 -m pytest tests/integration/test_http_transport.py -v

test-all:
	uv run python3 -m pytest tests/ -v

all: install-dev test-all
</file>

<file path="mcp-neo4j-memory/pyproject.toml">
[project]
name = "mcp-neo4j-memory"
version = "0.2.0"
description = "MCP Neo4j Knowledge Graph Memory Server"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "fastmcp>=2.0.0",
    "neo4j>=5.26.0",
    "pydantic>=2.10.1",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
    "pyright>=1.1.389",
    "pytest>=8.3.5",
    "pytest-asyncio>=0.25.3",
    "testcontainers[neo4j]>=4.10.0",
    "aiohttp>=3.8.0"
]

[project.scripts]
mcp-neo4j-memory = "mcp_neo4j_memory:main"

[tool.pytest.ini_options]
pythonpath = [
  "src"
]
</file>

<file path="mcp-neo4j-memory/README.md">
# 🧠🕸️ Neo4j Knowledge Graph Memory MCP Server

## 🌟 Overview

A Model Context Protocol (MCP) server implementation that provides persistent memory capabilities through Neo4j graph database integration.

By storing information in a graph structure, this server maintains complex relationships between entities as memory nodes and enables long-term retention of knowledge that can be queried and analyzed across multiple conversations or sessions.

With [Neo4j Aura](https://console.neo4j.io) you can host your own database server for free or share it with your collaborators. Otherwise you can run your own Neo4j server locally.

The MCP server leverages Neo4j's graph database capabilities to create an interconnected knowledge base that serves as an external memory system. Through Cypher queries, it allows exploration and retrieval of stored information, relationship analysis between different data points, and generation of insights from the accumulated knowledge. This memory can be further enhanced with Claude's capabilities.

### 🕸️ Graph Schema

* `Memory` - A node representing an entity with a name, type, and observations.
* `Relationship` - A relationship between two entities with a type.

### 🔍 Usage Example

```
Let's add some memories 
I, Michael, living in Dresden, Germany work at Neo4j which is headquartered in Sweden with my colleagues Andreas (Cambridge, UK) and Oskar (Gothenburg, Sweden)
I work in Product Management, Oskar in Engineering and Andreas in Developer Relations.
```

Results in Claude calling the create_entities and create_relations tools.

![](./docs/images/employee_create_entities_and_relations.png)

![](./docs/images/employee_graph.png)

## 📦 Components

### 🔧 Tools

The server offers these core tools:

#### 🔎 Query Tools
- `read_graph`
   - Read the entire knowledge graph
   - No input required
   - Returns: Complete graph with entities and relations

- `search_nodes`
   - Search for nodes based on a query
   - Input:
     - `query` (string): Search query matching names, types, observations
   - Returns: Matching subgraph

- `find_nodes`
   - Find specific nodes by name
   - Input:
     - `names` (array of strings): Entity names to retrieve
   - Returns: Subgraph with specified nodes

#### ♟️ Entity Management Tools
- `create_entities`
   - Create multiple new entities in the knowledge graph
   - Input:
     - `entities`: Array of objects with:
       - `name` (string): Name of the entity
       - `type` (string): Type of the entity  
       - `observations` (array of strings): Initial observations about the entity
   - Returns: Created entities

- `delete_entities` 
   - Delete multiple entities and their associated relations
   - Input:
     - `entityNames` (array of strings): Names of entities to delete
   - Returns: Success confirmation

#### 🔗 Relation Management Tools
- `create_relations`
   - Create multiple new relations between entities
   - Input:
     - `relations`: Array of objects with:
       - `source` (string): Name of source entity
       - `target` (string): Name of target entity
       - `relationType` (string): Type of relation
   - Returns: Created relations

- `delete_relations`
   - Delete multiple relations from the graph
   - Input:
     - `relations`: Array of objects with same schema as create_relations
   - Returns: Success confirmation

#### 📝 Observation Management Tools
- `add_observations`
   - Add new observations to existing entities
   - Input:
     - `observations`: Array of objects with:
       - `entityName` (string): Entity to add to
       - `contents` (array of strings): Observations to add
   - Returns: Added observation details

- `delete_observations`
   - Delete specific observations from entities
   - Input:
     - `deletions`: Array of objects with:
       - `entityName` (string): Entity to delete from
       - `observations` (array of strings): Observations to remove
   - Returns: Success confirmation

## 🔧 Usage with Claude Desktop

### 💾 Installation

```bash
pip install mcp-neo4j-memory
```

### ⚙️ Configuration

Add the server to your `claude_desktop_config.json` with configuration of:

```json
"mcpServers": {
  "neo4j": {
    "command": "uvx",
    "args": [
      "mcp-neo4j-memory@0.2.0",
      "--db-url",
      "neo4j+s://xxxx.databases.neo4j.io",
      "--username",
      "<your-username>",
      "--password",
      "<your-password>"
    ]
  }
}
```

Alternatively, you can set environment variables:

```json
"mcpServers": {
  "neo4j": {
    "command": "uvx",
    "args": [ "mcp-neo4j-memory@0.2.0" ],
    "env": {
      "NEO4J_URL": "neo4j+s://xxxx.databases.neo4j.io",
      "NEO4J_USERNAME": "<your-username>",
      "NEO4J_PASSWORD": "<your-password>"
    }
  }
}
```

### 🌐 HTTP Transport Mode

The server supports HTTP transport for web-based deployments and microservices:

```bash
# Basic HTTP mode (defaults: host=127.0.0.1, port=8000, path=/mcp/)
mcp-neo4j-memory --transport http

# Custom HTTP configuration
mcp-neo4j-memory --transport http --host 0.0.0.0 --port 8080 --path /api/mcp/
```

Environment variables for HTTP configuration:

```bash
export NEO4J_TRANSPORT=http
export NEO4J_MCP_SERVER_HOST=0.0.0.0
export NEO4J_MCP_SERVER_PORT=8080
export NEO4J_MCP_SERVER_PATH=/api/mcp/
mcp-neo4j-memory
```

### 🔄 Transport Modes

The server supports three transport modes:

- **STDIO** (default): Standard input/output for local tools and Claude Desktop
- **SSE**: Server-Sent Events for web-based deployments  
- **HTTP**: Streamable HTTP for modern web deployments and microservices

### 🐳 Using with Docker

```json
"mcpServers": {
  "neo4j": {
    "command": "docker",
    "args": [
      "run",
      "--rm",
      "-e", "NEO4J_URL=neo4j+s://xxxx.databases.neo4j.io",
      "-e", "NEO4J_USERNAME=<your-username>",
      "-e", "NEO4J_PASSWORD=<your-password>",
      "mcp/neo4j-memory:0.2.0"
    ]
  }
}
```

## 🚀 Development

### 📦 Prerequisites

1. Install `uv` (Universal Virtualenv):
```bash
# Using pip
pip install uv

# Using Homebrew on macOS
brew install uv

# Using cargo (Rust package manager)
cargo install uv
```

2. Clone the repository and set up development environment:
```bash
# Clone the repository
git clone https://github.com/yourusername/mcp-neo4j-memory.git
cd mcp-neo4j-memory

# Create and activate virtual environment using uv
uv venv
source .venv/bin/activate  # On Unix/macOS
.venv\Scripts\activate     # On Windows

# Install dependencies including dev dependencies
uv pip install -e ".[dev]"
```

### 🐳 Docker

Build and run the Docker container:

```bash
# Build the image
docker build -t mcp/neo4j-memory:latest .

# Run the container
docker run -e NEO4J_URL="neo4j+s://xxxx.databases.neo4j.io" \
          -e NEO4J_USERNAME="your-username" \
          -e NEO4J_PASSWORD="your-password" \
          mcp/neo4j-memory:latest
```

## 📄 License

This MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.
</file>

<file path="mcp-neo4j-memory/test.sh">
export NEO4J_URI=neo4j://localhost:7687
export NEO4J_USERNAME=neo4j
export NEO4J_PASSWORD=password
uv run pytest tests
</file>

</files>
</file>

<file path="demo/check_data.py">
#!/usr/bin/env python3
"""
Quick script to check what data is available in the Neo4j database.
"""

import asyncio
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Add parent directory to path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

# Load environment variables
env_path = parent_dir / '.env'
if env_path.exists():
    load_dotenv(env_path)

from src.mcp_server_neo4j_ehr.modules.db_connection import create_neo4j_driver, Neo4jConnection

async def check_database():
    """Check what data is available in the database."""
    # Create driver
    uri = os.getenv('NEO4J_URI')
    username = os.getenv('NEO4J_USERNAME')
    password = os.getenv('NEO4J_PASSWORD')
    database = os.getenv('NEO4J_DATABASE', 'neo4j')
    
    print(f"Connecting to: {uri}")
    print(f"Database: {database}")
    
    driver = create_neo4j_driver(uri, username, password)
    db = Neo4jConnection(driver, database)
    
    try:
        # Test connection
        print("\n1. Testing connection...")
        if await db.test_connection():
            print("✅ Connection successful")
        else:
            print("❌ Connection failed")
            return
        
        # Count nodes of each type
        print("\n2. Counting nodes by type...")
        node_types = ['Patient', 'Admission', 'DischargeNote', 'RadiologyReport', 
                      'LabEvent', 'Medication', 'Diagnosis', 'Procedure']
        
        for node_type in node_types:
            query = f"MATCH (n:{node_type}) RETURN count(n) as count"
            result = await db.execute_read(query)
            count = result[0]['count'] if result else 0
            print(f"   {node_type}: {count:,}")
        
        # Get sample patient IDs
        print("\n3. Sample Patient IDs:")
        query = "MATCH (p:Patient) RETURN p.subject_id as patient_id LIMIT 10"
        results = await db.execute_read(query)
        
        if results:
            for i, result in enumerate(results, 1):
                print(f"   {i}. {result['patient_id']}")
        else:
            print("   No patients found")
        
        # Check for specific patient
        print("\n4. Checking for patient 10006...")
        query = "MATCH (p:Patient {subject_id: '10006'}) RETURN p"
        results = await db.execute_read(query)
        
        if results:
            print("✅ Patient 10006 exists")
            patient = results[0]['p']
            for key, value in patient.items():
                print(f"   {key}: {value}")
        else:
            print("❌ Patient 10006 not found")
        
        # Check relationships
        print("\n5. Checking relationships...")
        query = """
        MATCH (p:Patient)-[r]->(a)
        RETURN type(r) as relationship, labels(a) as target_labels, count(*) as count
        LIMIT 10
        """
        results = await db.execute_read(query)
        
        if results:
            print("   Found relationships:")
            for result in results:
                print(f"   - {result['relationship']} -> {result['target_labels']}: {result['count']}")
        else:
            print("   No relationships found")
            
    finally:
        await db.close()

async def main():
    """Main function."""
    try:
        await check_database()
    except Exception as e:
        print(f"\n❌ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="demo/serve_demo.py">
#!/usr/bin/env python3
"""
Simple HTTP server to serve the demo HTML files.
This avoids CORS issues by serving the HTML from the same origin as the MCP server.
"""

import http.server
import socketserver
import os
from pathlib import Path

# Change to demo directory
demo_dir = Path(__file__).parent
os.chdir(demo_dir)

PORT = 8000

class MyHTTPRequestHandler(http.server.SimpleHTTPRequestHandler):
    def end_headers(self):
        # Add CORS headers
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type, mcp-session-id')
        super().end_headers()

    def do_OPTIONS(self):
        # Handle preflight requests
        self.send_response(200)
        self.end_headers()

def main():
    print(f"\n🌐 Starting demo web server on http://localhost:{PORT}")
    print("This serves the HTML demo files to avoid CORS issues.")
    print(f"Demo will be available at: http://localhost:{PORT}/index.html")
    print("Press Ctrl+C to stop\n")
    
    with socketserver.TCPServer(("", PORT), MyHTTPRequestHandler) as httpd:
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nStopping demo server...")

if __name__ == "__main__":
    main()
</file>

<file path="demo/styles.css">
/* Neo4j MCP Server Demo Styles */

:root {
    --primary-color: #018bff;
    --secondary-color: #4b5563;
    --success-color: #10b981;
    --error-color: #ef4444;
    --warning-color: #f59e0b;
    --info-color: #3b82f6;
    --background-color: #f9fafb;
    --card-background: #ffffff;
    --text-primary: #111827;
    --text-secondary: #6b7280;
    --border-color: #e5e7eb;
    --shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
}

* {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    background-color: var(--background-color);
    color: var(--text-primary);
    line-height: 1.6;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 20px;
}

/* Header */
header {
    background-color: var(--card-background);
    padding: 20px;
    border-radius: 8px;
    box-shadow: var(--shadow);
    margin-bottom: 20px;
}

header h1 {
    font-size: 24px;
    margin-bottom: 15px;
    color: var(--text-primary);
}

.connection-status {
    display: flex;
    align-items: center;
    gap: 10px;
}

.status-indicator {
    width: 12px;
    height: 12px;
    border-radius: 50%;
    background-color: var(--error-color);
    transition: background-color 0.3s;
}

.status-indicator.connected {
    background-color: var(--success-color);
}

#status-text {
    font-size: 14px;
    color: var(--text-secondary);
    margin-right: 10px;
}

#server-url {
    flex: 1;
    padding: 8px 12px;
    border: 1px solid var(--border-color);
    border-radius: 4px;
    font-size: 14px;
}

#connect-btn {
    padding: 8px 16px;
    background-color: var(--primary-color);
    color: white;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    font-size: 14px;
    transition: background-color 0.3s;
}

#connect-btn:hover {
    background-color: #0170d9;
}

/* Main Content */
main {
    background-color: var(--card-background);
    padding: 20px;
    border-radius: 8px;
    box-shadow: var(--shadow);
}

/* Tabs */
.tabs {
    display: flex;
    gap: 5px;
    margin-bottom: 20px;
    border-bottom: 2px solid var(--border-color);
    overflow-x: auto;
}

.tab-button {
    padding: 10px 20px;
    background: none;
    border: none;
    border-bottom: 2px solid transparent;
    cursor: pointer;
    font-size: 14px;
    color: var(--text-secondary);
    transition: all 0.3s;
    white-space: nowrap;
}

.tab-button:hover {
    color: var(--text-primary);
}

.tab-button.active {
    color: var(--primary-color);
    border-bottom-color: var(--primary-color);
}

.tab-content {
    display: none;
}

.tab-content.active {
    display: block;
}

/* Tool Sections */
.tool-section {
    background-color: var(--background-color);
    padding: 20px;
    border-radius: 8px;
    margin-bottom: 20px;
}

.input-group {
    margin-bottom: 15px;
}

.input-group label {
    display: block;
    margin-bottom: 5px;
    font-weight: 500;
    color: var(--text-primary);
    font-size: 14px;
}

.input-group input[type="text"],
.input-group input[type="number"],
.input-group select,
.input-group textarea {
    width: 100%;
    padding: 8px 12px;
    border: 1px solid var(--border-color);
    border-radius: 4px;
    font-size: 14px;
    transition: border-color 0.3s;
}

.input-group input:focus,
.input-group select:focus,
.input-group textarea:focus {
    outline: none;
    border-color: var(--primary-color);
}

.input-group textarea {
    resize: vertical;
    min-height: 80px;
}

.checkbox-group {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
    gap: 10px;
}

.checkbox-group label {
    display: flex;
    align-items: center;
    font-weight: normal;
    cursor: pointer;
}

.checkbox-group input[type="checkbox"] {
    margin-right: 5px;
}

/* Buttons */
.primary-btn {
    padding: 10px 20px;
    background-color: var(--primary-color);
    color: white;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    font-size: 14px;
    font-weight: 500;
    transition: background-color 0.3s;
}

.primary-btn:hover {
    background-color: #0170d9;
}

.secondary-btn {
    padding: 8px 16px;
    background-color: var(--secondary-color);
    color: white;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    font-size: 14px;
    transition: background-color 0.3s;
}

.secondary-btn:hover {
    background-color: #374151;
}

/* Results Section */
.results-section {
    margin-top: 30px;
    border-top: 2px solid var(--border-color);
    padding-top: 20px;
}

.results-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 15px;
}

.results-header h3 {
    font-size: 18px;
    color: var(--text-primary);
}

#results-info {
    font-size: 14px;
    color: var(--text-secondary);
}

.results {
    background-color: var(--background-color);
    padding: 20px;
    border-radius: 8px;
    min-height: 100px;
    max-height: 600px;
    overflow-y: auto;
}

.no-results {
    text-align: center;
    color: var(--text-secondary);
    padding: 40px;
}

/* Loading */
.loading {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 10px;
    padding: 40px;
}

.spinner {
    width: 20px;
    height: 20px;
    border: 2px solid var(--border-color);
    border-top-color: var(--primary-color);
    border-radius: 50%;
    animation: spin 1s linear infinite;
}

@keyframes spin {
    to { transform: rotate(360deg); }
}

/* Result Formats */
.json-results {
    background-color: #1e293b;
    color: #e2e8f0;
    padding: 15px;
    border-radius: 4px;
    overflow-x: auto;
    font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
    font-size: 13px;
    line-height: 1.5;
}

.text-results {
    background-color: var(--card-background);
    padding: 15px;
    border-radius: 4px;
    overflow-x: auto;
    font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
    font-size: 13px;
    line-height: 1.5;
}

.markdown-results {
    padding: 15px;
}

.markdown-results h1,
.markdown-results h2,
.markdown-results h3 {
    margin-top: 20px;
    margin-bottom: 10px;
}

.markdown-results h1:first-child,
.markdown-results h2:first-child,
.markdown-results h3:first-child {
    margin-top: 0;
}

.markdown-results ul {
    margin-left: 20px;
    margin-bottom: 10px;
}

.markdown-results table {
    width: 100%;
    border-collapse: collapse;
    margin: 15px 0;
}

.markdown-results th,
.markdown-results td {
    padding: 8px 12px;
    text-align: left;
    border: 1px solid var(--border-color);
}

.markdown-results th {
    background-color: var(--background-color);
    font-weight: 600;
}

/* Messages */
.message {
    position: fixed;
    top: 20px;
    right: 20px;
    padding: 12px 20px;
    border-radius: 4px;
    color: white;
    font-size: 14px;
    box-shadow: var(--shadow);
    animation: slideIn 0.3s ease-out;
    z-index: 1000;
}

.message.success {
    background-color: var(--success-color);
}

.message.error {
    background-color: var(--error-color);
}

.message.info {
    background-color: var(--info-color);
}

.message.warning {
    background-color: var(--warning-color);
}

@keyframes slideIn {
    from {
        transform: translateX(100%);
        opacity: 0;
    }
    to {
        transform: translateX(0);
        opacity: 1;
    }
}

/* Notes */
.note {
    font-size: 13px;
    color: var(--text-secondary);
    font-style: italic;
    margin-top: 10px;
}

/* Footer */
footer {
    text-align: center;
    padding: 20px;
    color: var(--text-secondary);
    font-size: 14px;
}

footer p {
    margin-bottom: 5px;
}

/* Responsive */
@media (max-width: 768px) {
    .container {
        padding: 10px;
    }

    .tabs {
        flex-wrap: wrap;
    }

    .tab-button {
        padding: 8px 15px;
        font-size: 13px;
    }

    .checkbox-group {
        grid-template-columns: 1fr;
    }

    .connection-status {
        flex-wrap: wrap;
    }

    #server-url {
        width: 100%;
        margin-bottom: 10px;
    }
}
</file>

<file path="demo/test_demo.py">
#!/usr/bin/env python3
"""
Test script to verify the demo works with the hosted Neo4j database.
This script will start the server and run some basic tests.
"""

import asyncio
import aiohttp
import json
import sys
import os
from pathlib import Path

# Add parent directory to path
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

# Server URL
SERVER_URL = "http://localhost:8080"

async def test_server_connection():
    """Test if we can connect to the MCP server."""
    print("Testing server connection...")
    async with aiohttp.ClientSession() as session:
        try:
            payload = {
                "jsonrpc": "2.0",
                "method": "initialize",
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {}
                },
                "id": 1
            }
            
            async with session.post(SERVER_URL, json=payload) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    print("✅ Server connection successful")
                    return True
                else:
                    print(f"❌ Server returned status: {resp.status}")
                    return False
        except Exception as e:
            print(f"❌ Connection failed: {e}")
            return False

async def test_get_schema():
    """Test getting the database schema."""
    print("\nTesting get schema...")
    async with aiohttp.ClientSession() as session:
        try:
            payload = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": "ehr_get_schema",
                    "arguments": {
                        "format": "json"
                    }
                },
                "id": 2
            }
            
            async with session.post(SERVER_URL, json=payload) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if "result" in data:
                        print("✅ Schema retrieved successfully")
                        # Parse the JSON content
                        content = data["result"]["content"][0]["text"]
                        schema = json.loads(content)
                        print(f"   Found {len(schema['nodes'])} node types")
                        return True
                    else:
                        print(f"❌ Error: {data.get('error', 'Unknown error')}")
                        return False
        except Exception as e:
            print(f"❌ Schema test failed: {e}")
            return False

async def test_patient_lookup():
    """Test looking up a patient."""
    print("\nTesting patient lookup...")
    async with aiohttp.ClientSession() as session:
        try:
            # Test with a common patient ID
            payload = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": "ehr_patient",
                    "arguments": {
                        "subject_id": "10461137",
                        "include": ["demographics"],
                        "format": "json"
                    }
                },
                "id": 3
            }
            
            async with session.post(SERVER_URL, json=payload) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if "result" in data:
                        content = data["result"]["content"][0]["text"]
                        patient_data = json.loads(content)
                        if patient_data:
                            print("✅ Patient data retrieved successfully")
                            print(f"   Patient ID: {patient_data.get('subject_id', 'N/A')}")
                            print(f"   Gender: {patient_data.get('gender', 'N/A')}")
                            return True
                        else:
                            print("⚠️  No patient found with ID 10461137")
                            print("   This might be expected if the database doesn't have this patient")
                            return True  # Not a failure, just no data
                    else:
                        print(f"❌ Error: {data.get('error', {}).get('message', 'Unknown error')}")
                        return False
        except Exception as e:
            print(f"❌ Patient lookup failed: {e}")
            return False

async def test_list_patients():
    """Test listing some patients to find valid IDs."""
    print("\nTesting list patients...")
    async with aiohttp.ClientSession() as session:
        try:
            # Use natural query to find some patients
            payload = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": "ehr_natural_query",
                    "arguments": {
                        "query": "Show me 5 patient IDs",
                        "limit": 5,
                        "format": "json"
                    }
                },
                "id": 4
            }
            
            async with session.post(SERVER_URL, json=payload) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if "result" in data:
                        print("✅ Natural query executed successfully")
                        content = data["result"]["content"][0]["text"]
                        result_data = json.loads(content)
                        if result_data.get("results"):
                            print(f"   Found {len(result_data['results'])} results")
                            # Show first few patient IDs if available
                            for i, result in enumerate(result_data["results"][:3]):
                                print(f"   Result {i+1}: {result}")
                        return True
                    else:
                        error_msg = data.get('error', {}).get('message', 'Unknown error')
                        if 'OPENAI_API_KEY' in error_msg:
                            print("⚠️  Natural query requires OpenAI API key")
                            print("   This is expected if OPENAI_API_KEY is not set")
                            return True  # Not a failure
                        else:
                            print(f"❌ Error: {error_msg}")
                            return False
        except Exception as e:
            print(f"❌ Natural query test failed: {e}")
            return False

async def test_search_notes():
    """Test searching clinical notes."""
    print("\nTesting note search...")
    async with aiohttp.ClientSession() as session:
        try:
            payload = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": "ehr_search_notes",
                    "arguments": {
                        "query": "pain",
                        "search_type": "text",
                        "limit": 5,
                        "format": "json"
                    }
                },
                "id": 5
            }
            
            async with session.post(SERVER_URL, json=payload) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if "result" in data:
                        content = data["result"]["content"][0]["text"]
                        results = json.loads(content)
                        if results:
                            print("✅ Note search completed successfully")
                            print(f"   Found {len(results)} notes")
                        else:
                            print("⚠️  No notes found containing 'pain'")
                            print("   This might be expected if the database is empty")
                        return True
                    else:
                        print(f"❌ Error: {data.get('error', {}).get('message', 'Unknown error')}")
                        return False
        except Exception as e:
            print(f"❌ Note search failed: {e}")
            return False

async def run_all_tests():
    """Run all tests."""
    print("🧪 Neo4j MCP Server Demo Test Suite")
    print("=" * 50)
    print(f"Server URL: {SERVER_URL}")
    print("=" * 50)
    
    # Wait a moment for server to be ready
    await asyncio.sleep(2)
    
    tests = [
        test_server_connection,
        test_get_schema,
        test_patient_lookup,
        test_list_patients,
        test_search_notes
    ]
    
    results = []
    for test in tests:
        result = await test()
        results.append(result)
    
    print("\n" + "=" * 50)
    print("Test Summary:")
    passed = sum(results)
    total = len(results)
    print(f"Passed: {passed}/{total}")
    
    if passed == total:
        print("\n✅ All tests passed!")
        print("\nThe demo is working correctly. You can now:")
        print("1. Open demo/index.html in your browser")
        print("2. Click 'Connect' to connect to the server")
        print("3. Start exploring the data!")
    else:
        print("\n⚠️  Some tests did not pass")
        print("This might be expected if:")
        print("- The database doesn't have MIMIC data loaded")
        print("- OpenAI API key is not configured")
        print("- The server is still starting up")
    
    return passed == total

async def main():
    """Main function."""
    # Check if server is supposed to be running
    print("⚠️  Make sure the MCP server is running!")
    print("In another terminal, run:")
    print("  cd demo")
    print("  python run_http_server.py")
    print("\nPress Enter when the server is running...")
    input()
    
    try:
        success = await run_all_tests()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nTests interrupted by user")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="demo/test_stdio_client.py">
#!/usr/bin/env python3
"""
Simple STDIO client to test the Neo4j EHR MCP Server.
This communicates directly with the server via STDIO, avoiding HTTP/CORS issues.
"""

import json
import subprocess
import sys
import time
from pathlib import Path

class MCPStdioClient:
    def __init__(self, server_command):
        """Initialize the STDIO client with the server command."""
        self.server_command = server_command
        self.process = None
        self.request_id = 0
        
    def start_server(self):
        """Start the MCP server process."""
        print(f"🚀 Starting MCP server: {' '.join(self.server_command)}")
        self.process = subprocess.Popen(
            self.server_command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=0
        )
        time.sleep(2)  # Give server time to start
        print("✅ Server started")
        
    def send_request(self, method, params=None):
        """Send a JSON-RPC request to the server."""
        if not self.process:
            raise RuntimeError("Server not started")
            
        self.request_id += 1
        request = {
            "jsonrpc": "2.0",
            "method": method,
            "params": params or {},
            "id": self.request_id
        }
        
        request_json = json.dumps(request)
        print(f"\n📤 Sending: {method}")
        print(f"   Request: {request_json}")
        
        # Send request
        self.process.stdin.write(request_json + "\n")
        self.process.stdin.flush()
        
        # Read response
        response_line = self.process.stdout.readline()
        if not response_line:
            stderr_output = self.process.stderr.read()
            raise RuntimeError(f"No response from server. Stderr: {stderr_output}")
            
        try:
            response = json.loads(response_line)
            print(f"📥 Response: {json.dumps(response, indent=2)}")
            return response
        except json.JSONDecodeError as e:
            print(f"❌ Invalid JSON response: {response_line}")
            print(f"   Error: {e}")
            return None
            
    def stop_server(self):
        """Stop the MCP server process."""
        if self.process:
            self.process.terminate()
            self.process.wait()
            print("🛑 Server stopped")

def test_all_tools():
    """Test all EHR tools systematically."""
    
    # Server command - using STDIO transport (default)
    server_cmd = [
        "uv", "run", "mcp-server-neo4j-ehr",
        "--neo4j-password", "0d5lUsufRUO0FNUt2FEm7gVagPP2ovThFq6n0GRXH08"
    ]
    
    client = MCPStdioClient(server_cmd)
    
    try:
        # Start server
        client.start_server()
        
        # Test 1: Initialize connection
        print("\n" + "="*60)
        print("TEST 1: Initialize Connection")
        print("="*60)
        
        init_response = client.send_request("initialize", {
            "protocolVersion": "2024-11-05",
            "capabilities": {},
            "clientInfo": {
                "name": "test-client",
                "version": "1.0"
            }
        })
        
        if init_response and not init_response.get("error"):
            print("✅ Initialization successful")
        else:
            print("❌ Initialization failed:", init_response.get("error"))
            return
            
        # Test 2: Get Schema
        print("\n" + "="*60)
        print("TEST 2: Get Database Schema")
        print("="*60)
        
        schema_response = client.send_request("tools/call", {
            "name": "ehr_get_schema",
            "arguments": {
                "format": "json"
            }
        })
        
        if schema_response and not schema_response.get("error"):
            print("✅ Schema retrieval successful")
        else:
            print("❌ Schema retrieval failed:", schema_response.get("error"))
            
        # Test 3: Get Patient Info
        print("\n" + "="*60)
        print("TEST 3: Get Patient Information")
        print("="*60)
        
        patient_response = client.send_request("tools/call", {
            "name": "ehr_patient",
            "arguments": {
                "subject_id": "10000032",
                "include_admissions": True,
                "format": "json"
            }
        })
        
        if patient_response and not patient_response.get("error"):
            print("✅ Patient lookup successful")
        else:
            print("❌ Patient lookup failed:", patient_response.get("error"))
            
        # Test 4: Search Notes
        print("\n" + "="*60)
        print("TEST 4: Search Clinical Notes")
        print("="*60)
        
        notes_response = client.send_request("tools/call", {
            "name": "ehr_search_notes",
            "arguments": {
                "query": "chest pain",
                "limit": 3,
                "format": "json"
            }
        })
        
        if notes_response and not notes_response.get("error"):
            print("✅ Notes search successful")
        else:
            print("❌ Notes search failed:", notes_response.get("error"))
            
        # Test 5: List Diagnoses
        print("\n" + "="*60)
        print("TEST 5: List Diagnoses")
        print("="*60)
        
        diagnoses_response = client.send_request("tools/call", {
            "name": "ehr_list_diagnoses",
            "arguments": {
                "limit": 5,
                "format": "json"
            }
        })
        
        if diagnoses_response and not diagnoses_response.get("error"):
            print("✅ Diagnoses list successful")
        else:
            print("❌ Diagnoses list failed:", diagnoses_response.get("error"))
            
        # Test 6: Natural Language Query (if OpenAI key available)
        print("\n" + "="*60)
        print("TEST 6: Natural Language Query")
        print("="*60)
        
        natural_response = client.send_request("tools/call", {
            "name": "ehr_natural_query",
            "arguments": {
                "query": "How many patients are in the database?",
                "format": "markdown"
            }
        })
        
        if natural_response and not natural_response.get("error"):
            print("✅ Natural query successful")
        else:
            print("❌ Natural query failed:", natural_response.get("error"))
            if "OpenAI API key" in str(natural_response.get("error", "")):
                print("   (This is expected if OpenAI API key is not configured)")
            
        print("\n" + "="*60)
        print("🏁 ALL TESTS COMPLETED")
        print("="*60)
        
    except Exception as e:
        print(f"❌ Test failed with error: {e}")
        
    finally:
        client.stop_server()

def interactive_mode():
    """Interactive mode for manual testing."""
    print("🎮 Interactive Mode - Send custom requests")
    print("Available tools: ehr_patient, ehr_search_notes, ehr_list_diagnoses,")
    print("  ehr_list_medications, ehr_list_procedures, ehr_list_lab_events,")
    print("  ehr_natural_query, ehr_get_schema")
    print("Type 'quit' to exit")
    
    server_cmd = [
        "uv", "run", "mcp-server-neo4j-ehr", 
        "--neo4j-password", "0d5lUsufRUO0FNUt2FEm7gVagPP2ovThFq6n0GRXH08"
    ]
    
    client = MCPStdioClient(server_cmd)
    client.start_server()
    
    # Initialize
    client.send_request("initialize", {
        "protocolVersion": "2024-11-05",
        "capabilities": {},
        "clientInfo": {"name": "interactive-client", "version": "1.0"}
    })
    
    try:
        while True:
            print("\n" + "-"*40)
            tool_name = input("Enter tool name (or 'quit'): ").strip()
            if tool_name.lower() == 'quit':
                break
                
            print("Enter arguments as JSON (or press Enter for empty):")
            args_input = input().strip()
            
            if args_input:
                try:
                    arguments = json.loads(args_input)
                except json.JSONDecodeError:
                    print("❌ Invalid JSON format")
                    continue
            else:
                arguments = {}
                
            client.send_request("tools/call", {
                "name": tool_name,
                "arguments": arguments
            })
            
    except KeyboardInterrupt:
        print("\n👋 Exiting interactive mode")
    finally:
        client.stop_server()

def main():
    """Main function."""
    print("🧪 Neo4j EHR MCP Server STDIO Test Client")
    print("="*50)
    
    if len(sys.argv) > 1 and sys.argv[1] == "interactive":
        interactive_mode()
    else:
        print("Running automated tests...")
        print("(Use 'python test_stdio_client.py interactive' for manual testing)")
        test_all_tools()

if __name__ == "__main__":
    main()
</file>

<file path="demo/validate_demo.py">
#!/usr/bin/env python3
"""
Validation script for the Neo4j MCP Server Demo
Checks the implementation for common issues without requiring a running server.
"""

import os
import json
import re
from pathlib import Path
import sys

def check_file_exists(filepath):
    """Check if a file exists and is readable."""
    path = Path(filepath)
    if not path.exists():
        return False, f"File not found: {filepath}"
    if not path.is_file():
        return False, f"Not a file: {filepath}"
    if not os.access(path, os.R_OK):
        return False, f"File not readable: {filepath}"
    return True, "OK"

def validate_html():
    """Validate the HTML file structure and content."""
    html_path = Path(__file__).parent / "index.html"
    exists, msg = check_file_exists(html_path)
    if not exists:
        return False, msg
    
    with open(html_path, 'r') as f:
        content = f.read()
    
    # Check for required elements
    required_elements = [
        '<script src="mcp-client.js"',
        '<link rel="stylesheet" href="styles.css"',
        'id="connect-btn"',
        'id="server-url"',
        'id="results"',
        'onclick="getPatientInfo()"',
        'onclick="searchNotes()"',
        'onclick="listDiagnoses()"',
        'onclick="naturalQuery()"'
    ]
    
    missing = []
    for element in required_elements:
        if element not in content:
            missing.append(element)
    
    if missing:
        return False, f"Missing HTML elements: {', '.join(missing)}"
    
    # Check for all 8 tabs
    tabs = ['patient', 'search-notes', 'diagnoses', 'medications', 
            'procedures', 'lab-events', 'natural-query', 'schema']
    for tab in tabs:
        if f'id="{tab}-tab"' not in content:
            return False, f"Missing tab: {tab}"
    
    return True, "HTML structure looks good"

def validate_javascript():
    """Validate the JavaScript file."""
    js_path = Path(__file__).parent / "mcp-client.js"
    exists, msg = check_file_exists(js_path)
    if not exists:
        return False, msg
    
    with open(js_path, 'r') as f:
        content = f.read()
    
    # Check for required functions
    required_functions = [
        'class MCPClient',
        'async connect()',
        'async callTool(',
        'async getPatientInfo()',
        'async searchNotes()',
        'async listDiagnoses()',
        'async naturalQuery()',
        'displayResults(',
        'showTab('
    ]
    
    missing = []
    for func in required_functions:
        if func not in content:
            missing.append(func)
    
    if missing:
        return False, f"Missing JavaScript functions: {', '.join(missing)}"
    
    # Check for all tool implementations
    tools = ['ehr_patient', 'ehr_search_notes', 'ehr_list_diagnoses', 
             'ehr_list_medications', 'ehr_list_procedures', 'ehr_list_lab_events',
             'ehr_natural_query', 'ehr_get_schema']
    
    for tool in tools:
        if f"'{tool}'" not in content and f'"{tool}"' not in content:
            return False, f"Missing tool implementation: {tool}"
    
    return True, "JavaScript implementation looks complete"

def validate_css():
    """Validate the CSS file."""
    css_path = Path(__file__).parent / "styles.css"
    exists, msg = check_file_exists(css_path)
    if not exists:
        return False, msg
    
    with open(css_path, 'r') as f:
        content = f.read()
    
    # Check for key styles
    required_styles = [
        '.container',
        '.tab-button',
        '.tab-content',
        '.results',
        '.loading',
        '.status-indicator',
        '.primary-btn'
    ]
    
    missing = []
    for style in required_styles:
        if style not in content:
            missing.append(style)
    
    if missing:
        return False, f"Missing CSS styles: {', '.join(missing)}"
    
    return True, "CSS styles look complete"

def validate_server_script():
    """Validate the HTTP server script."""
    server_path = Path(__file__).parent / "run_http_server.py"
    exists, msg = check_file_exists(server_path)
    if not exists:
        return False, msg
    
    with open(server_path, 'r') as f:
        content = f.read()
    
    # Check for required imports and functionality
    required_elements = [
        'from mcp',
        'from src.mcp_server_neo4j_ehr import create_server',
        'http_server',
        'cors_headers',
        'Access-Control-Allow-Origin',
        'port = 8080'
    ]
    
    missing = []
    for element in required_elements:
        if element not in content:
            missing.append(element)
    
    if missing:
        return False, f"Missing server elements: {', '.join(missing)}"
    
    # Check if executable
    if not os.access(server_path, os.X_OK):
        return False, "Server script is not executable (run: chmod +x run_http_server.py)"
    
    return True, "Server script looks good"

def validate_readme():
    """Validate the README file."""
    readme_path = Path(__file__).parent / "README.md"
    exists, msg = check_file_exists(readme_path)
    if not exists:
        return False, msg
    
    with open(readme_path, 'r') as f:
        content = f.read()
    
    # Check for required sections
    required_sections = [
        '## Overview',
        '## Prerequisites',
        '## Quick Start',
        '## Using the Demo',
        '## Troubleshooting'
    ]
    
    missing = []
    for section in required_sections:
        if section not in content:
            missing.append(section)
    
    if missing:
        return False, f"Missing README sections: {', '.join(missing)}"
    
    return True, "README documentation looks complete"

def check_javascript_syntax():
    """Basic JavaScript syntax validation."""
    js_path = Path(__file__).parent / "mcp-client.js"
    with open(js_path, 'r') as f:
        content = f.read()
    
    # Count braces and brackets
    open_braces = content.count('{')
    close_braces = content.count('}')
    open_brackets = content.count('[')
    close_brackets = content.count(']')
    open_parens = content.count('(')
    close_parens = content.count(')')
    
    issues = []
    if open_braces != close_braces:
        issues.append(f"Brace mismatch: {open_braces} open, {close_braces} close")
    if open_brackets != close_brackets:
        issues.append(f"Bracket mismatch: {open_brackets} open, {close_brackets} close")
    if open_parens != close_parens:
        issues.append(f"Parenthesis mismatch: {open_parens} open, {close_parens} close")
    
    if issues:
        return False, f"Syntax issues: {'; '.join(issues)}"
    
    return True, "Basic syntax checks passed"

def main():
    """Run all validation checks."""
    print("🔍 Validating Neo4j MCP Server Demo Implementation\n")
    
    checks = [
        ("HTML File", validate_html),
        ("JavaScript File", validate_javascript),
        ("CSS File", validate_css),
        ("Server Script", validate_server_script),
        ("README File", validate_readme),
        ("JavaScript Syntax", check_javascript_syntax)
    ]
    
    all_passed = True
    results = []
    
    for name, check_func in checks:
        try:
            passed, message = check_func()
            results.append((name, passed, message))
            if not passed:
                all_passed = False
        except Exception as e:
            results.append((name, False, f"Error: {str(e)}"))
            all_passed = False
    
    # Display results
    print("Validation Results:")
    print("-" * 50)
    
    for name, passed, message in results:
        status = "✅ PASS" if passed else "❌ FAIL"
        print(f"{status} {name}: {message}")
    
    print("-" * 50)
    
    if all_passed:
        print("\n✅ All validation checks passed!")
        print("\nNext steps:")
        print("1. Set up your .env file with Neo4j credentials")
        print("2. Run: cd demo && python run_http_server.py")
        print("3. Open demo/index.html in your browser")
        print("4. Click Connect and start testing!")
    else:
        print("\n❌ Some validation checks failed.")
        print("Please fix the issues above before running the demo.")
        sys.exit(1)

if __name__ == "__main__":
    main()
</file>

<file path="examples/test_connection.py">
#!/usr/bin/env python3
"""Test connection to Neo4j database and basic functionality.

Run with: uv run python examples/test_connection.py
"""

import asyncio
import os
import sys
from pathlib import Path

# Add the src directory to the Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
from src.mcp_server_neo4j_ehr.modules.db_connection import create_neo4j_driver, Neo4jConnection

# Load environment variables
load_dotenv()


async def test_connection():
    """Test basic database connection and queries."""
    
    # Get connection parameters
    uri = os.getenv("NEO4J_URI", "bolt://localhost:7687")
    username = os.getenv("NEO4J_USERNAME", "neo4j")
    password = os.getenv("NEO4J_PASSWORD", "password")
    database = os.getenv("NEO4J_DATABASE", "neo4j")
    
    print(f"Connecting to Neo4j at {uri}...")
    
    # Create driver and connection
    driver = create_neo4j_driver(uri, username, password)
    db = Neo4jConnection(driver, database)
    
    try:
        # Test connection
        if await db.test_connection():
            print("✓ Connection successful!")
        else:
            print("✗ Connection failed!")
            return
        
        # Get schema info
        print("\nFetching database schema...")
        schema = await db.get_schema()
        
        print(f"\nFound {len(schema['nodes'])} node types:")
        for node in schema['nodes']:
            print(f"  - {node.get('label', 'Unknown')}")
        
        print(f"\nFound {len(schema['relationships'])} relationship types:")
        for rel in schema['relationships']:
            print(f"  - {rel.get('relationshipType', 'Unknown')}")
        
        # Test a simple query
        print("\nTesting patient count query...")
        result = await db.execute_read("MATCH (p:Patient) RETURN count(p) as count")
        if result:
            print(f"✓ Found {result[0]['count']} patients in the database")
        
    except Exception as e:
        print(f"✗ Error: {e}")
    finally:
        await driver.close()
        print("\nConnection closed.")


if __name__ == "__main__":
    asyncio.run(test_connection())
</file>

<file path="specs/fix-for-natural-query.md">
## Fix issue with natural query function
Neo4j return DateTime objects that cant be directly serialized to JSON.

Given fix from copilot:
import json
from datetime import datetime
from neo4j.time import DateTime

// ...existing code...

def serialize_neo4j_data(obj):
    """Convert Neo4j objects to JSON-serializable format."""
    if isinstance(obj, DateTime):
        # Convert Neo4j DateTime to ISO format string
        return obj.iso_format()
    elif isinstance(obj, datetime):
        # Convert Python datetime to ISO format string
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {key: serialize_neo4j_data(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [serialize_neo4j_data(item) for item in obj]
    else:
        return obj

// ...existing code...

async def natural_query(
    db_connection: Neo4jConnection,
    query: str,
    limit: int,
    format: OutputFormat,
    openai_api_key: str
) -> str:
    // ...existing code until the results processing...
    
    if format == OUTPUT_FORMAT_JSON:
        # Serialize the results to handle DateTime objects
        serialized_results = serialize_neo4j_data(results)
        return json.dumps({"results": serialized_results}, indent=2)
    elif format == OUTPUT_FORMAT_MARKDOWN:
        # Process results for markdown (likely already handling this correctly)
        // ...existing markdown processing...
    else:
        # Handle other formats


This issue likely affects other functions too, so you should apply the same fix to any other tools that return JSON with datetime fields (like patient.py, list_*.py functions, etc.).
</file>

<file path="specs/mcp-server-testing-plan.md">
# Neo4j MCP Server Testing Plan

## Overview

This document outlines comprehensive testing approaches for the Neo4j MCP (Model Context Protocol) server, including the creation of an HTML demo interface for easy interaction and testing.

## Testing Methods

### 1. Direct MCP Protocol Testing

#### Using MCP Inspector
```bash
npx @modelcontextprotocol/inspector python -m mcp_server_neo4j_ehr
```

#### Using MCP CLI
```bash
# Install MCP CLI
npm install -g @modelcontextprotocol/cli

# Connect to server
mcp connect stdio python -m mcp_server_neo4j_ehr
```

### 2. HTTP Mode Testing

The server supports HTTP mode for easier testing with web interfaces:

```python
# run_http_server.py
import asyncio
from mcp_server_neo4j_ehr import create_server

async def main():
    server = await create_server()
    # Configure for HTTP mode with CORS
    await server.run_http(host="localhost", port=8080, cors_origins=["*"])

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. HTML Demo Interface

Create an interactive web interface for testing all MCP tools.

## Demo Interface Specifications

### File Structure
```
demo/
├── index.html          # Main demo interface
├── mcp-client.js      # JavaScript MCP client
├── styles.css         # Styling
└── README.md          # Demo setup instructions
```

### HTML Interface Components

#### 1. Connection Status
- Server URL input
- Connect/Disconnect button
- Connection status indicator
- Available tools display

#### 2. Tool Interfaces

##### Patient Information Tool
```html
<div class="tool-section" id="patient-tool">
    <h3>Patient Information</h3>
    <input type="text" id="patient-id" placeholder="Patient ID (e.g., 10006)">
    <select id="include-options" multiple>
        <option value="demographics">Demographics</option>
        <option value="admissions">Admissions</option>
        <option value="diagnoses">Diagnoses</option>
        <option value="medications">Medications</option>
        <option value="procedures">Procedures</option>
        <option value="lab_events">Lab Events</option>
        <option value="notes">Clinical Notes</option>
    </select>
    <button onclick="getPatientInfo()">Get Patient Info</button>
</div>
```

##### Search Notes Tool
```html
<div class="tool-section" id="search-notes-tool">
    <h3>Search Clinical Notes</h3>
    <input type="text" id="search-query" placeholder="Search term">
    <select id="search-type">
        <option value="text">Text Search</option>
        <option value="semantic">Semantic Search</option>
    </select>
    <input type="number" id="search-limit" placeholder="Limit" value="10">
    <button onclick="searchNotes()">Search</button>
</div>
```

##### Natural Query Tool
```html
<div class="tool-section" id="natural-query-tool">
    <h3>Natural Language Query</h3>
    <textarea id="natural-query" placeholder="Ask a question about the data..."></textarea>
    <button onclick="naturalQuery()">Ask</button>
</div>
```

### JavaScript Client Implementation

```javascript
// mcp-client.js
class MCPClient {
    constructor(serverUrl) {
        this.serverUrl = serverUrl;
        this.requestId = 0;
    }

    async callTool(toolName, args) {
        const response = await fetch(this.serverUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                jsonrpc: '2.0',
                method: 'tools/call',
                params: {
                    name: toolName,
                    arguments: args
                },
                id: ++this.requestId
            })
        });
        return response.json();
    }

    async getPatientInfo(patientId, includeOptions) {
        return this.callTool('ehr_patient', {
            subject_id: patientId,
            include: includeOptions,
            format: 'json'
        });
    }

    async searchNotes(query, searchType, limit) {
        return this.callTool('ehr_search_notes', {
            query: query,
            search_type: searchType,
            limit: limit,
            format: 'json'
        });
    }

    async naturalQuery(query, limit = 10) {
        return this.callTool('ehr_natural_query', {
            query: query,
            limit: limit,
            format: 'json'
        });
    }
}
```

## Server Configuration for Testing

### Environment Variables
```bash
# .env.test
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
NEO4J_DATABASE=neo4j
OPENAI_API_KEY=your_openai_key  # Required for natural_query tool
EMBEDDING_MODEL=text-embedding-3-small  # For semantic search
```

### Test Data Requirements
- MIMIC-III or MIMIC-IV data loaded into Neo4j
- Vector embeddings created for semantic search (if using)
- Sample patient IDs for testing:
  - 10006 (patient with multiple admissions)
  - 10013 (patient with diverse medical history)
  - 10019 (patient with lab events)

## Test Scenarios

### 1. Basic Patient Lookup
```javascript
// Test: Get patient demographics
await client.getPatientInfo('10006', ['demographics']);

// Expected: Patient name, DOB, gender, etc.
```

### 2. Comprehensive Patient Data
```javascript
// Test: Get all patient data
await client.getPatientInfo('10006', [
    'demographics', 'admissions', 'diagnoses', 
    'medications', 'procedures', 'lab_events'
]);

// Expected: Complete patient record
```

### 3. Text Search
```javascript
// Test: Search for specific terms
await client.searchNotes('chest pain', 'text', 5);

// Expected: Notes containing "chest pain"
```

### 4. Semantic Search
```javascript
// Test: Semantic similarity search
await client.searchNotes('respiratory distress', 'semantic', 5);

// Expected: Notes semantically related to breathing problems
```

### 5. Natural Language Queries
```javascript
// Test: Complex natural language questions
await client.naturalQuery(
    'Which patients had both diabetes and hypertension?',
    10
);

// Expected: Cypher query generated and results returned
```

## Implementation Steps

1. **Set up Neo4j Database**
   - Install Neo4j
   - Load MIMIC data
   - Create indexes and constraints

2. **Configure MCP Server**
   - Install dependencies: `pip install mcp-server-neo4j-ehr`
   - Set environment variables
   - Test server startup

3. **Create Demo Interface**
   - Create HTML file with tool interfaces
   - Implement JavaScript client
   - Add CSS styling
   - Test CORS configuration

4. **Run Tests**
   - Start server in HTTP mode
   - Open HTML interface
   - Test each tool with sample data
   - Verify error handling

## Error Handling

### Common Issues
1. **Connection Errors**
   - Check Neo4j is running
   - Verify credentials
   - Ensure correct URI format

2. **CORS Issues**
   - Enable CORS in server configuration
   - Check allowed origins

3. **Missing API Key**
   - Natural query requires OpenAI API key
   - Set OPENAI_API_KEY environment variable

4. **Empty Results**
   - Verify data is loaded in Neo4j
   - Check patient IDs exist
   - Review query parameters

## Performance Testing

### Load Testing
```javascript
// Test concurrent requests
async function loadTest() {
    const promises = [];
    for (let i = 0; i < 10; i++) {
        promises.push(client.getPatientInfo('10006', ['demographics']));
    }
    const results = await Promise.all(promises);
    console.log(`Completed ${results.length} requests`);
}
```

### Response Time Monitoring
- Log request/response times
- Monitor Neo4j query performance
- Track LLM response times for natural queries

## Security Considerations

1. **Authentication**
   - Implement API key authentication
   - Use HTTPS in production
   - Secure Neo4j credentials

2. **Input Validation**
   - Sanitize user inputs
   - Validate patient IDs
   - Limit query complexity

3. **Rate Limiting**
   - Implement request throttling
   - Monitor usage patterns
   - Prevent abuse

## Next Steps

1. Implement the HTML demo interface
2. Create automated test suite
3. Add performance benchmarks
4. Document API endpoints
5. Create user guide for non-technical users

## Resources

- [MCP Documentation](https://modelcontextprotocol.io/docs)
- [Neo4j Python Driver](https://neo4j.com/docs/python-manual/current/)
- [MIMIC Database](https://mimic.mit.edu/)
- [OpenAI API Reference](https://platform.openai.com/docs)
</file>

<file path="specs/neo4j-mcp-v1.md">
# Neo4j server to connect to EHR graphRAG 

With this Model Context Protocol (MCP) server we can now query our Neo4j database in natural language. This specific server is to query a medical electronic health record (EHR) database that uses data from the MIMI-IV EHR datatbase (discharge notes, radiology reports, patient admission structured data).


## NEO4j Database Structure

### Node Types

#### Patient (10 nodes)
- **Properties**: `subject_id` (unique, indexed), `gender` (indexed), `anchor_age`, `anchor_year`, `anchor_year_group`, `dod`
- **Relationships**: HAS_ADMISSION → Admission

#### Admission (28 nodes)  
- **Properties**: `hadm_id` (unique, indexed), `admission_type` (indexed), `admittime`, `dischtime`, `deathtime`, `admission_location`, `discharge_location`, `insurance`, `language`, `marital_status`, `race`, `edregtime`, `edouttime`, `hospital_expire_flag`, `admit_provider_id`
- **Relationships**: 
  - ← HAS_ADMISSION from Patient
  - INCLUDES_DISCHARGE_NOTE → DischargeNote
  - INCLUDES_RADIOLOGY_REPORT → RadiologyReport  
  - INCLUDES_LAB_EVENT → LabEvent
  - HAS_PROCEDURE → Procedure
  - HAS_MEDICATION → Medication
  - HAS_DIAGNOSIS → Diagnosis

#### DischargeNote (25 nodes)
- **Properties**: `note_id` (unique, indexed), `hadm_id` (indexed), `subject_id` (indexed), `note_type` (indexed), `text` (indexed), `note_seq`, `charttime`, `storetime`, `embedding`, `embedding_model`, `embedding_created`
- **Relationships**: ← INCLUDES_DISCHARGE_NOTE from Admission

#### RadiologyReport (64 nodes)
- **Properties**: `note_id` (unique, indexed), `hadm_id` (indexed), `subject_id` (indexed), `note_type` (indexed), `text` (indexed), `note_seq`, `charttime`, `storetime`, `embedding`, `embedding_model`, `embedding_created`  
- **Relationships**: ← INCLUDES_RADIOLOGY_REPORT from Admission

#### LabEvent (4,346 nodes)
- **Properties**: `lab_event_id` (unique, indexed), `subject_id` (indexed), `hadm_id` (indexed), `charttime` (indexed), `label` (indexed), `itemid` (indexed), `category` (indexed), `flag` (indexed), `value` (indexed), `comments` (indexed), `ref_range_upper`, `ref_range_lower`, `fluid`, `priority`, `storetime`
- **Relationships**: ← INCLUDES_LAB_EVENT from Admission

#### Medication (1,051 nodes)
- **Properties**: `medication` (indexed), `route` (indexed), `hadm_id`, `subject_id`, `frequency`, `verifiedtime`
- **Relationships**: ← HAS_MEDICATION from Admission

#### Diagnosis (420 nodes)
- **Properties**: `icd_code` (indexed), `long_title` (indexed), `synonyms` (indexed), `hadm_id`, `subject_id`, `seq_num`, `icd_version`
- **Relationships**: ← HAS_DIAGNOSIS from Admission

#### Procedure (29 nodes)
- **Properties**: `icd_code` (indexed), `long_title` (indexed), `hadm_id`, `seq_num`, `chartdate`, `icd_version`
- **Relationships**: ← HAS_PROCEDURE from Admission

### Key Features
- **Vector Embeddings**: DischargeNote and RadiologyReport nodes include embeddings for semantic search
- **Temporal Data**: Comprehensive timestamps across all clinical events
- **Rich Laboratory Data**: Extensive lab results with reference ranges and flags
- **Clinical Coding**: ICD codes for diagnoses and procedures with full titles

## Implementation Notes
- Use the official `neo4j` Python driver for database connections.
- Connection parameters will be managed via environment variables: `NEO4J_URI`, `NEO4J_USERNAME`, `NEO4J_PASSWORD`, `NEO4J_DATABASE`.
- Use `python-dotenv` to load environment variables.
- Use OpenAI's API for generating embeddings for natural language queries.
- All API responses should be structured and predictable, preferably using Pydantic models.
- Required libraries:
  - `click`
  - `mcp`
  - `pydantic`
  - `neo4j`
  - `python-dotenv`
  - `openai`
  - `pytest` (dev dependency)
- Use `uv add <package>` to add libraries.
- Use `uv` for project and dependency management.
- Add `mcp-server-neo4j-ehr = "mcp_server_neo4j_ehr:main"` to the `project.scripts` section in `pyproject.toml`.

## API

```
ehr patient <subject_id> \
    --include-admissions: bool = True \
    --include-diagnoses: bool = False \
    --include-procedures: bool = False \
    --include-medications: bool = False \
    --include-lab-events: bool = False \
    --format: json | table = json

ehr search-notes <query> \
    --note-type: discharge | radiology | all = all \
    --limit: int = 5 \
    --semantic: bool = False \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --format: json | text | table = json

ehr list-diagnoses \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

ehr list-lab-events \
    --patient-id: str (required) \
    --admission-id: str (optional) \
    --abnormal-only: bool = False \
    --category: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

ehr list-medications \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --medication: str (optional) \
    --route: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

ehr list-procedures \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

ehr natural-query <query> \
    --limit: int = 10 \
    --format: json | markdown | table = markdown

ehr get-schema \
    --format: json | markdown = markdown
```

### Example API Calls
```
# Get patient information with all admissions
ehr patient "10000032" --include-admissions=True

# Search discharge notes semantically for a specific patient
ehr search-notes "congestive heart failure" --note-type=discharge --semantic=True --limit=3 --patient-id="10000032"

# List all diagnoses for a specific admission in a table
ehr list-diagnoses --admission-id="22595853" --format=table

# Find abnormal lab results for a patient
ehr list-lab-events --patient-id="10000032" --abnormal-only=True --format=table

# Natural language query to generate a Cypher statement and execute it
ehr natural-query "Show me patients with pneumonia who also had kidney issues"

# Get the database schema to help construct queries
ehr get-schema
```

## Project Structure
- `src/`
  - `mcp_server_neo4j_ehr/`
    - `__init__.py`
    - `__main__.py`
    - `server.py`
      - `serve(neo4j_uri: str, neo4j_user: str, neo4j_pass: str, neo4j_db: str) -> None`
    - `modules/`
      - `__init__.py`
      - `db_connection.py`
      - `data_types.py`
      - `constants.py`
      - `query_builder.py`
      - `functionality/`
        - `patient.py`
        - `search_notes.py`
        - `list_diagnoses.py`
        - `list_lab_events.py`
        - `list_medications.py`
        - `list_procedures.py`
        - `natural_query.py`
        - `get_schema.py`
- `tests/`
  - `__init__.py`
  - `test_db_connection.py`
  - `functionality/`
    - `test_patient.py`
    - `test_search_notes.py`
    - `test_list_diagnoses.py`
    - `test_list_lab_events.py`
    - `test_list_medications.py`
    - `test_list_procedures.py`
    - `test_natural_query.py`
    - `test_get_schema.py`

## Cypher Query Examples

### Patient Query
```cypher
MATCH (p:Patient {subject_id: $subject_id})
OPTIONAL MATCH (p)-[:HAS_ADMISSION]->(a:Admission)
RETURN p, collect(a) as admissions
```

### Semantic Note Search
```cypher
// 1. Generate embedding for the $query_text using OpenAI
// 2. Pass the embedding as $query_embedding to the query
MATCH (note)
WHERE note:DischargeNote OR note:RadiologyReport
CALL db.index.vector.queryNodes('note_embeddings', $limit, $query_embedding) YIELD node, score
RETURN node.text, score
ORDER BY score DESC
```

### Get Schema Query
```cypher
// This procedure returns a description of the graph schema.
// The server will format this output for the user.
CALL db.schema.visualization()
```

### Natural Language to Cypher
The `natural-query` command will use an LLM to translate the natural language input into a Cypher query. This is a multi-step process:
1. The LLM is prompted to first call the `ehr get-schema` tool to understand the graph's structure (nodes, properties, relationships).
2. With the schema as context, the LLM generates a Cypher query that accurately reflects the user's question.
3. The server executes the generated Cypher query and returns the results.

**Example:** "Find discharge notes mentioning allergic reactions to antibiotics"
**Generated Cypher (after consulting schema):**
```cypher
MATCH (p:Patient)-[:HAS_ADMISSION]->(a:Admission)-[:INCLUDES_DISCHARGE_NOTE]->(d:DischargeNote)
WHERE toLower(d.text) CONTAINS 'allergic reaction' AND toLower(d.text) CONTAINS 'antibiotic'
RETURN p.subject_id, a.hadm_id, d.note_id, d.text
LIMIT 10
```

## Validation
- Use `uv run pytest` to validate the functionality against a test Neo4j database instance.
- Use `uv run mcp-server-neo4j-ehr --help` to validate the MCP server CLI.
- Manually test a suite of queries to ensure accuracy and performance.
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/get_clinical_notes.py">
"""Get clinical notes functionality."""

import json
import logging
from typing import Optional, List
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import NoteSearchResult, OutputFormat, NoteType
from ..constants import (
    OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE, OUTPUT_FORMAT_TEXT,
    NOTE_TYPE_DISCHARGE, NOTE_TYPE_RADIOLOGY, NOTE_TYPE_ALL
)

logger = logging.getLogger(__name__)


async def get_clinical_notes(
    db: Neo4jConnection,
    note_type: NoteType = NOTE_TYPE_ALL,
    limit: int = 10,
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """Retrieve clinical notes by type and patient/admission."""
    
    # Build WHERE conditions
    where_conditions = []
    
    # Note type filter
    if note_type == NOTE_TYPE_DISCHARGE:
        where_conditions.append("note:DischargeNote")
    elif note_type == NOTE_TYPE_RADIOLOGY:
        where_conditions.append("note:RadiologyReport")
    else:
        where_conditions.append("(note:DischargeNote OR note:RadiologyReport)")
    
    # Patient filter
    if patient_id:
        where_conditions.append("note.subject_id = $patient_id")
    
    # Admission filter
    if admission_id:
        where_conditions.append("note.hadm_id = $admission_id")
    
    # Build query
    cypher_query = f"""
    MATCH (note)
    WHERE {' AND '.join(where_conditions) if where_conditions else 'true'}
    RETURN note.note_id as note_id,
           note.note_type as note_type,
           note.subject_id as subject_id,
           note.hadm_id as hadm_id,
           note.charttime as charttime,
           note.text as text
    ORDER BY note.charttime DESC
    LIMIT $limit
    """
    
    params = {
        "patient_id": patient_id,
        "admission_id": admission_id,
        "limit": limit
    }
    
    results = await db.execute_read(cypher_query, params)
    
    # Convert Neo4j DateTime objects to Python datetime
    converted_results = []
    for r in results:
        if 'charttime' in r and hasattr(r['charttime'], 'to_native'):
            r['charttime'] = r['charttime'].to_native()
        converted_results.append(NoteSearchResult(**r))
    
    # Format output
    if format == OUTPUT_FORMAT_TABLE:
        return format_notes_as_table(converted_results)
    elif format == OUTPUT_FORMAT_TEXT:
        return format_notes_as_text(converted_results)
    else:
        return json.dumps([r.model_dump(exclude_none=True) for r in converted_results])


def format_notes_as_table(results: List[NoteSearchResult]) -> str:
    """Format notes as a table."""
    if not results:
        return "No notes found."
    
    table_data = []
    for note in results:
        table_data.append([
            note.note_id,
            note.note_type,
            note.subject_id or "N/A",
            note.hadm_id or "N/A",
            str(note.charttime) if note.charttime else "N/A",
            note.text[:100] + "..." if len(note.text) > 100 else note.text
        ])
    
    headers = ["Note ID", "Type", "Patient ID", "Admission ID", "Chart Time", "Text Preview"]
    return tabulate(table_data, headers=headers, tablefmt="grid")


def format_notes_as_text(results: List[NoteSearchResult]) -> str:
    """Format notes as plain text."""
    if not results:
        return "No notes found."
    
    output = []
    for i, note in enumerate(results, 1):
        output.append(f"\n{'='*80}")
        output.append(f"Note {i}/{len(results)} - ID: {note.note_id}")
        output.append(f"Type: {note.note_type}")
        output.append(f"Patient: {note.subject_id or 'N/A'}, Admission: {note.hadm_id or 'N/A'}")
        if note.charttime:
            output.append(f"Chart Time: {note.charttime}")
        output.append(f"\n{note.text}")
    
    return "\n".join(output)
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/get_schema.py">
"""Get database schema functionality."""

import json
from datetime import datetime
from typing import Dict, Any

from ..db_connection import Neo4jConnection
from ..data_types import OutputFormat
from ..constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_MARKDOWN


def convert_neo4j_types(obj):
    """Convert Neo4j types to JSON-serializable types."""
    if isinstance(obj, dict):
        return {k: convert_neo4j_types(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_neo4j_types(item) for item in obj]
    elif hasattr(obj, 'isoformat'):  # Handles neo4j.time.DateTime and python datetime
        return obj.isoformat()
    elif hasattr(obj, '__dict__'):  # Handle Neo4j objects
        return convert_neo4j_types(obj.__dict__)
    return obj


async def get_schema(
    db: Neo4jConnection,
    format: OutputFormat = OUTPUT_FORMAT_MARKDOWN
) -> str:
    """Get the database schema."""
    
    # Get schema from database
    schema = await db.get_schema()
    
    # Add our known relationship structure
    schema["known_relationships"] = [
        {
            "from": "Patient",
            "to": "Admission",
            "type": "HAS_ADMISSION",
            "description": "Patient has hospital admissions"
        },
        {
            "from": "Admission",
            "to": "DischargeNote",
            "type": "INCLUDES_DISCHARGE_NOTE",
            "description": "Admission includes discharge summary notes"
        },
        {
            "from": "Admission",
            "to": "RadiologyReport",
            "type": "INCLUDES_RADIOLOGY_REPORT",
            "description": "Admission includes radiology reports"
        },
        {
            "from": "Admission",
            "to": "LabEvent",
            "type": "INCLUDES_LAB_EVENT",
            "description": "Admission includes laboratory test results"
        },
        {
            "from": "Admission",
            "to": "Diagnosis",
            "type": "HAS_DIAGNOSIS",
            "description": "Admission has associated diagnoses"
        },
        {
            "from": "Admission",
            "to": "Procedure",
            "type": "HAS_PROCEDURE",
            "description": "Admission has associated procedures"
        },
        {
            "from": "Admission",
            "to": "Medication",
            "type": "HAS_MEDICATION",
            "description": "Admission has associated medications"
        }
    ]
    
    # Format output
    if format == OUTPUT_FORMAT_MARKDOWN:
        return format_schema_as_markdown(schema)
    else:
        # Convert Neo4j types to JSON-serializable types
        schema_serializable = convert_neo4j_types(schema)
        return json.dumps(schema_serializable, indent=2)


def format_schema_as_markdown(schema: Dict[str, Any]) -> str:
    """Format schema as markdown."""
    lines = []
    
    lines.append("# Neo4j EHR Database Schema\n")
    
    # Node types
    lines.append("## Node Types\n")
    for node in schema.get("nodes", []):
        label = node.get("label", "Unknown")
        properties = node.get("properties", [])
        lines.append(f"### {label}")
        lines.append(f"**Properties:** {', '.join(properties)}\n")
    
    # Relationships
    lines.append("## Relationships\n")
    for rel in schema.get("known_relationships", []):
        lines.append(f"### {rel['type']}")
        lines.append(f"- **From:** {rel['from']}")
        lines.append(f"- **To:** {rel['to']}")
        lines.append(f"- **Description:** {rel['description']}\n")
    
    # Indexes
    if schema.get("indexes"):
        lines.append("## Indexes\n")
        for idx in schema["indexes"]:
            name = idx.get("name", "Unknown")
            state = idx.get("state", "Unknown")
            lines.append(f"- {name} (State: {state})")
    
    # Constraints
    if schema.get("constraints"):
        lines.append("\n## Constraints\n")
        for constraint in schema["constraints"]:
            name = constraint.get("name", "Unknown")
            lines.append(f"- {name}")
    
    # Usage examples
    lines.append("\n## Example Queries\n")
    lines.append("### Get patient with all admissions")
    lines.append("```cypher")
    lines.append("MATCH (p:Patient {subject_id: '10000032'})-[:HAS_ADMISSION]->(a:Admission)")
    lines.append("RETURN p, collect(a) as admissions")
    lines.append("```\n")
    
    lines.append("### Find discharge notes mentioning a condition")
    lines.append("```cypher")
    lines.append("MATCH (d:DischargeNote)")
    lines.append("WHERE toLower(d.text) CONTAINS 'heart failure'")
    lines.append("RETURN d.note_id, d.subject_id, d.hadm_id")
    lines.append("LIMIT 10")
    lines.append("```\n")
    
    lines.append("### Get abnormal lab results for a patient")
    lines.append("```cypher")
    lines.append("MATCH (l:LabEvent)")
    lines.append("WHERE l.subject_id = '10000032' AND l.flag IS NOT NULL AND l.flag <> 'normal'")
    lines.append("RETURN l.label, l.value, l.flag, l.charttime")
    lines.append("ORDER BY l.charttime DESC")
    lines.append("```")
    
    return "\n".join(lines)
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/list_diagnoses.py">
"""List diagnoses functionality."""

import json
from typing import Optional
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import Diagnosis, OutputFormat
from ..constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


async def list_diagnoses(
    db: Neo4jConnection,
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    limit: int = 20,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List diagnoses for a patient or admission."""
    
    # Build query based on filters
    if admission_id:
        query = """
        MATCH (a:Admission {hadm_id: $admission_id})-[:HAS_DIAGNOSIS]->(d:Diagnosis)
        RETURN d
        ORDER BY d.seq_num
        LIMIT $limit
        """
        params = {"admission_id": admission_id, "limit": limit}
    elif patient_id:
        query = """
        MATCH (p:Patient {subject_id: $patient_id})-[:HAS_ADMISSION]->(a:Admission)-[:HAS_DIAGNOSIS]->(d:Diagnosis)
        RETURN d, a.hadm_id as hadm_id
        ORDER BY a.admittime DESC, d.seq_num
        LIMIT $limit
        """
        params = {"patient_id": patient_id, "limit": limit}
    else:
        return json.dumps({"error": "Either patient_id or admission_id must be provided"})
    
    results = await db.execute_read(query, params)
    
    if not results:
        return json.dumps({"diagnoses": [], "message": "No diagnoses found"})
    
    # Process results
    diagnoses = []
    for result in results:
        diagnosis_data = result['d']
        diagnosis = Diagnosis(**diagnosis_data)
        
        # Add admission ID if querying by patient
        if patient_id and 'hadm_id' in result:
            diagnosis.hadm_id = result['hadm_id']
        
        diagnoses.append(diagnosis)
    
    # Format output
    if format == OUTPUT_FORMAT_TABLE:
        return format_diagnoses_as_table(diagnoses)
    else:
        return json.dumps({
            "diagnoses": [d.model_dump(exclude_none=True) for d in diagnoses],
            "count": len(diagnoses)
        })


def format_diagnoses_as_table(diagnoses: list[Diagnosis]) -> str:
    """Format diagnoses as a table."""
    if not diagnoses:
        return "No diagnoses found."
    
    table_data = []
    for diag in diagnoses:
        table_data.append([
            diag.icd_code,
            diag.long_title or "N/A",
            diag.hadm_id or "N/A",
            diag.seq_num or "N/A",
            f"ICD-{diag.icd_version}" if diag.icd_version else "N/A"
        ])
    
    headers = ["ICD Code", "Description", "Admission ID", "Sequence", "Version"]
    return tabulate(table_data, headers=headers, tablefmt="grid")
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/list_lab_events.py">
"""List lab events functionality."""

import json
from typing import Optional
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import LabEvent, OutputFormat
from ..constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


async def list_lab_events(
    db: Neo4jConnection,
    patient_id: str,
    admission_id: Optional[str] = None,
    abnormal_only: bool = False,
    category: Optional[str] = None,
    limit: int = 20,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List lab events for a patient."""
    
    # Build WHERE conditions
    where_conditions = ["l.subject_id = $patient_id"]
    
    if admission_id:
        where_conditions.append("l.hadm_id = $admission_id")
    
    if abnormal_only:
        where_conditions.append("l.flag IS NOT NULL AND l.flag <> 'normal'")
    
    if category:
        where_conditions.append("toLower(l.category) = toLower($category)")
    
    # Build query
    query = f"""
    MATCH (l:LabEvent)
    WHERE {' AND '.join(where_conditions)}
    RETURN l
    ORDER BY l.charttime DESC
    LIMIT $limit
    """
    
    params = {
        "patient_id": patient_id,
        "admission_id": admission_id,
        "category": category,
        "limit": limit
    }
    
    results = await db.execute_read(query, params)
    
    if not results:
        return json.dumps({"lab_events": [], "message": "No lab events found"})
    
    # Process results - convert Neo4j DateTime objects to Python datetime
    lab_events = []
    for result in results:
        r = result['l']
        # Convert Neo4j DateTime to Python datetime for datetime fields
        if 'charttime' in r and hasattr(r['charttime'], 'to_native'):
            r['charttime'] = r['charttime'].to_native()
        if 'storetime' in r and hasattr(r['storetime'], 'to_native'):
            r['storetime'] = r['storetime'].to_native()
        lab_events.append(LabEvent(**r))
    
    # Format output
    if format == OUTPUT_FORMAT_TABLE:
        return format_lab_events_as_table(lab_events)
    else:
        return json.dumps({
            "lab_events": [l.model_dump(exclude_none=True) for l in lab_events],
            "count": len(lab_events)
        })


def format_lab_events_as_table(lab_events: list[LabEvent]) -> str:
    """Format lab events as a table."""
    if not lab_events:
        return "No lab events found."
    
    table_data = []
    for lab in lab_events:
        # Format value with reference range
        value_str = str(lab.value) if lab.value else "N/A"
        if lab.ref_range_lower is not None or lab.ref_range_upper is not None:
            ref_range = f"({lab.ref_range_lower or ''}-{lab.ref_range_upper or ''})"
            value_str = f"{value_str} {ref_range}"
        
        table_data.append([
            lab.label,
            value_str,
            lab.flag or "normal",
            lab.category or "N/A",
            str(lab.charttime) if lab.charttime else "N/A",
            lab.hadm_id or "N/A"
        ])
    
    headers = ["Test Name", "Value (Range)", "Flag", "Category", "Chart Time", "Admission ID"]
    return tabulate(table_data, headers=headers, tablefmt="grid")
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/list_medications.py">
"""List medications functionality."""

import json
from typing import Optional
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import Medication, OutputFormat
from ..constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


async def list_medications(
    db: Neo4jConnection,
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    medication: Optional[str] = None,
    route: Optional[str] = None,
    limit: int = 20,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List medications for a patient or admission."""
    
    # Build query based on filters
    where_conditions = []
    
    if admission_id:
        where_conditions.append("m.hadm_id = $admission_id")
    elif patient_id:
        where_conditions.append("m.subject_id = $patient_id")
    else:
        return json.dumps({"error": "Either patient_id or admission_id must be provided"})
    
    if medication:
        where_conditions.append("toLower(m.medication) CONTAINS toLower($medication)")
    
    if route:
        where_conditions.append("toLower(m.route) = toLower($route)")
    
    # Build query
    query = f"""
    MATCH (m:Medication)
    WHERE {' AND '.join(where_conditions)}
    RETURN m
    ORDER BY m.verifiedtime DESC
    LIMIT $limit
    """
    
    params = {
        "patient_id": patient_id,
        "admission_id": admission_id,
        "medication": medication,
        "route": route,
        "limit": limit
    }
    
    results = await db.execute_read(query, params)
    
    if not results:
        return json.dumps({"medications": [], "message": "No medications found"})
    
    # Process results - convert Neo4j DateTime objects to Python datetime
    medications = []
    for result in results:
        r = result['m']
        # Convert Neo4j DateTime to Python datetime for datetime fields
        if 'verifiedtime' in r and hasattr(r['verifiedtime'], 'to_native'):
            r['verifiedtime'] = r['verifiedtime'].to_native()
        medications.append(Medication(**r))
    
    # Format output
    if format == OUTPUT_FORMAT_TABLE:
        return format_medications_as_table(medications)
    else:
        return json.dumps({
            "medications": [m.model_dump(exclude_none=True) for m in medications],
            "count": len(medications)
        })


def format_medications_as_table(medications: list[Medication]) -> str:
    """Format medications as a table."""
    if not medications:
        return "No medications found."
    
    table_data = []
    for med in medications:
        table_data.append([
            med.medication,
            med.route or "N/A",
            med.frequency or "N/A",
            med.hadm_id or "N/A",
            str(med.verifiedtime) if med.verifiedtime else "N/A"
        ])
    
    headers = ["Medication", "Route", "Frequency", "Admission ID", "Verified Time"]
    return tabulate(table_data, headers=headers, tablefmt="grid")
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/list_procedures.py">
"""List procedures functionality."""

import json
from typing import Optional
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import Procedure, OutputFormat
from ..constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


async def list_procedures(
    db: Neo4jConnection,
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    limit: int = 20,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List procedures for a patient or admission."""
    
    # Build query based on filters
    if admission_id:
        query = """
        MATCH (a:Admission {hadm_id: $admission_id})-[:HAS_PROCEDURE]->(p:Procedure)
        RETURN p
        ORDER BY p.seq_num
        LIMIT $limit
        """
        params = {"admission_id": admission_id, "limit": limit}
    elif patient_id:
        query = """
        MATCH (pat:Patient {subject_id: $patient_id})-[:HAS_ADMISSION]->(a:Admission)-[:HAS_PROCEDURE]->(p:Procedure)
        RETURN p, a.hadm_id as hadm_id
        ORDER BY p.chartdate DESC, p.seq_num
        LIMIT $limit
        """
        params = {"patient_id": patient_id, "limit": limit}
    else:
        return json.dumps({"error": "Either patient_id or admission_id must be provided"})
    
    results = await db.execute_read(query, params)
    
    if not results:
        return json.dumps({"procedures": [], "message": "No procedures found"})
    
    # Process results
    procedures = []
    for result in results:
        procedure_data = result['p']
        procedure = Procedure(**procedure_data)
        
        # Add admission ID if querying by patient
        if patient_id and 'hadm_id' in result:
            procedure.hadm_id = result['hadm_id']
        
        procedures.append(procedure)
    
    # Format output
    if format == OUTPUT_FORMAT_TABLE:
        return format_procedures_as_table(procedures)
    else:
        return json.dumps({
            "procedures": [p.model_dump(exclude_none=True) for p in procedures],
            "count": len(procedures)
        })


def format_procedures_as_table(procedures: list[Procedure]) -> str:
    """Format procedures as a table."""
    if not procedures:
        return "No procedures found."
    
    table_data = []
    for proc in procedures:
        table_data.append([
            proc.icd_code,
            proc.long_title or "N/A",
            proc.hadm_id or "N/A",
            str(proc.chartdate) if proc.chartdate else "N/A",
            proc.seq_num or "N/A",
            f"ICD-{proc.icd_version}" if proc.icd_version else "N/A"
        ])
    
    headers = ["ICD Code", "Description", "Admission ID", "Chart Date", "Sequence", "Version"]
    return tabulate(table_data, headers=headers, tablefmt="grid")
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/patient.py">
"""Patient query functionality."""

import json
from typing import Optional
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import Patient, Admission, Diagnosis, Procedure, Medication, LabEvent, PatientResponse, OutputFormat
from ..constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


async def get_patient(
    db: Neo4jConnection,
    subject_id: str,
    include_admissions: bool = True,
    include_diagnoses: bool = False,
    include_procedures: bool = False,
    include_medications: bool = False,
    include_lab_events: bool = False,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """Get comprehensive patient information."""
    
    # Build the main query
    query_parts = ["MATCH (p:Patient {subject_id: $subject_id})"]
    
    if include_admissions:
        query_parts.append("OPTIONAL MATCH (p)-[:HAS_ADMISSION]->(a:Admission)")
    
    if include_diagnoses:
        query_parts.append("OPTIONAL MATCH (a)-[:HAS_DIAGNOSIS]->(d:Diagnosis)")
    
    if include_procedures:
        query_parts.append("OPTIONAL MATCH (a)-[:HAS_PROCEDURE]->(proc:Procedure)")
    
    if include_medications:
        query_parts.append("OPTIONAL MATCH (a)-[:HAS_MEDICATION]->(m:Medication)")
    
    if include_lab_events:
        query_parts.append("OPTIONAL MATCH (a)-[:INCLUDES_LAB_EVENT]->(l:LabEvent)")
    
    # Build return statement
    return_parts = ["p"]
    if include_admissions:
        return_parts.append("COLLECT(DISTINCT a) as admissions")
    if include_diagnoses:
        return_parts.append("COLLECT(DISTINCT d) as diagnoses")
    if include_procedures:
        return_parts.append("COLLECT(DISTINCT proc) as procedures")
    if include_medications:
        return_parts.append("COLLECT(DISTINCT m) as medications")
    if include_lab_events:
        return_parts.append("COLLECT(DISTINCT l) as lab_events")
    
    query = "\n".join(query_parts) + f"\nRETURN {', '.join(return_parts)}"
    
    # Execute query
    results = await db.execute_read(query, {"subject_id": subject_id})
    
    if not results:
        return json.dumps({"error": f"Patient {subject_id} not found"})
    
    result = results[0]
    
    # Build response
    patient_data = result['p']
    # Convert Neo4j DateTime to Python datetime for patient datetime fields
    if 'dod' in patient_data and hasattr(patient_data['dod'], 'to_native'):
        patient_data['dod'] = patient_data['dod'].to_native()
    patient = Patient(**patient_data)
    
    response = PatientResponse(patient=patient)
    
    if include_admissions and 'admissions' in result:
        admissions = []
        for a in result['admissions']:
            if a:
                # Convert Neo4j DateTime to Python datetime for datetime fields
                if 'admittime' in a and hasattr(a['admittime'], 'to_native'):
                    a['admittime'] = a['admittime'].to_native()
                if 'dischtime' in a and hasattr(a['dischtime'], 'to_native'):
                    a['dischtime'] = a['dischtime'].to_native()
                if 'deathtime' in a and hasattr(a['deathtime'], 'to_native'):
                    a['deathtime'] = a['deathtime'].to_native()
                if 'edregtime' in a and hasattr(a['edregtime'], 'to_native'):
                    a['edregtime'] = a['edregtime'].to_native()
                if 'edouttime' in a and hasattr(a['edouttime'], 'to_native'):
                    a['edouttime'] = a['edouttime'].to_native()
                admissions.append(Admission(**a))
        response.admissions = admissions
    
    if include_diagnoses and 'diagnoses' in result and result['diagnoses'] is not None:
        response.diagnoses = [Diagnosis(**d) for d in result['diagnoses'] if d]
    
    if include_procedures and 'procedures' in result and result['procedures'] is not None:
        procedures = []
        for p in result['procedures']:
            if p:
                # Convert Neo4j DateTime to Python datetime for datetime fields
                if 'chartdate' in p and hasattr(p['chartdate'], 'to_native'):
                    p['chartdate'] = p['chartdate'].to_native()
                procedures.append(Procedure(**p))
        response.procedures = procedures
    
    if include_medications and 'medications' in result and result['medications'] is not None:
        medications = []
        for m in result['medications']:
            if m:
                # Convert Neo4j DateTime to Python datetime for datetime fields
                if 'verifiedtime' in m and hasattr(m['verifiedtime'], 'to_native'):
                    m['verifiedtime'] = m['verifiedtime'].to_native()
                medications.append(Medication(**m))
        response.medications = medications
    
    if include_lab_events and 'lab_events' in result and result['lab_events'] is not None:
        lab_events = []
        for l in result['lab_events']:
            if l:
                # Convert Neo4j DateTime to Python datetime for datetime fields
                if 'charttime' in l and hasattr(l['charttime'], 'to_native'):
                    l['charttime'] = l['charttime'].to_native()
                if 'storetime' in l and hasattr(l['storetime'], 'to_native'):
                    l['storetime'] = l['storetime'].to_native()
                lab_events.append(LabEvent(**l))
        response.lab_events = lab_events
    
    # Format output
    if format == OUTPUT_FORMAT_TABLE:
        return format_patient_as_table(response)
    else:
        return response.model_dump_json(exclude_none=True)


def format_patient_as_table(response: PatientResponse) -> str:
    """Format patient response as a table."""
    output = []
    
    # Patient info
    patient_info = [
        ["Subject ID", response.patient.subject_id],
        ["Gender", response.patient.gender or "N/A"],
        ["Anchor Age", response.patient.anchor_age or "N/A"],
        ["Date of Death", response.patient.dod or "N/A"]
    ]
    output.append("PATIENT INFORMATION")
    output.append(tabulate(patient_info, headers=["Field", "Value"], tablefmt="grid"))
    
    # Admissions
    if response.admissions:
        output.append("\nADMISSIONS")
        admission_data = []
        for adm in response.admissions:
            admission_data.append([
                adm.hadm_id,
                adm.admission_type,
                str(adm.admittime) if adm.admittime else "N/A",
                str(adm.dischtime) if adm.dischtime else "N/A"
            ])
        output.append(tabulate(admission_data, 
                             headers=["Admission ID", "Type", "Admit Time", "Discharge Time"],
                             tablefmt="grid"))
    
    # Similar formatting for other sections...
    
    return "\n".join(output)
</file>

<file path="src/mcp_server_neo4j_ehr/modules/data_types.py">
"""Data types and models for the Neo4j EHR MCP Server."""

from datetime import datetime
from typing import Optional, List, Dict, Any, Literal
from pydantic import BaseModel, Field, ConfigDict, field_serializer


# Base class for all models with JSON serialization support
class BaseNodeModel(BaseModel):
    """Base model with datetime serialization support."""
    
    @field_serializer('*', mode='wrap')
    def serialize_datetime(self, value, serializer):
        """Serialize datetime fields to ISO format."""
        if isinstance(value, datetime):
            return value.isoformat() if value else None
        return serializer(value)


# Node Models
class Patient(BaseNodeModel):
    """Patient node model."""
    subject_id: str
    gender: Optional[str] = None
    anchor_age: Optional[int] = None
    anchor_year: Optional[int] = None
    anchor_year_group: Optional[str] = None
    dod: Optional[datetime] = None


class Admission(BaseNodeModel):
    """Admission node model."""
    hadm_id: str
    admission_type: Optional[str] = None
    admittime: Optional[datetime] = None
    dischtime: Optional[datetime] = None
    deathtime: Optional[datetime] = None
    admission_location: Optional[str] = None
    discharge_location: Optional[str] = None
    insurance: Optional[str] = None
    language: Optional[str] = None
    marital_status: Optional[str] = None
    race: Optional[str] = None
    edregtime: Optional[datetime] = None
    edouttime: Optional[datetime] = None
    hospital_expire_flag: Optional[int] = None
    admit_provider_id: Optional[str] = None


class DischargeNote(BaseNodeModel):
    """Discharge note node model."""
    note_id: str
    hadm_id: Optional[str] = None
    subject_id: Optional[str] = None
    note_type: str
    text: str
    note_seq: Optional[int] = None
    charttime: Optional[datetime] = None
    storetime: Optional[datetime] = None
    embedding: Optional[List[float]] = None
    embedding_model: Optional[str] = None
    embedding_created: Optional[datetime] = None


class RadiologyReport(BaseNodeModel):
    """Radiology report node model."""
    note_id: str
    hadm_id: Optional[str] = None
    subject_id: Optional[str] = None
    note_type: str
    text: str
    note_seq: Optional[int] = None
    charttime: Optional[datetime] = None
    storetime: Optional[datetime] = None
    embedding: Optional[List[float]] = None
    embedding_model: Optional[str] = None
    embedding_created: Optional[datetime] = None


class LabEvent(BaseNodeModel):
    """Lab event node model."""
    lab_event_id: str
    subject_id: str
    hadm_id: Optional[str] = None
    charttime: datetime
    label: str
    itemid: Optional[str] = None
    category: Optional[str] = None
    flag: Optional[str] = None
    value: Optional[str] = None
    comments: Optional[str] = None
    ref_range_upper: Optional[float] = None
    ref_range_lower: Optional[float] = None
    fluid: Optional[str] = None
    priority: Optional[str] = None
    storetime: Optional[datetime] = None


class Medication(BaseNodeModel):
    """Medication node model."""
    medication: str
    route: Optional[str] = None
    hadm_id: Optional[str] = None
    subject_id: Optional[str] = None
    frequency: Optional[str] = None
    verifiedtime: Optional[datetime] = None


class Diagnosis(BaseNodeModel):
    """Diagnosis node model."""
    icd_code: str
    long_title: Optional[str] = None
    synonyms: Optional[List[str]] = None
    hadm_id: Optional[str] = None
    subject_id: Optional[str] = None
    seq_num: Optional[int] = None
    icd_version: Optional[int] = None


class Procedure(BaseNodeModel):
    """Procedure node model."""
    icd_code: str
    long_title: Optional[str] = None
    hadm_id: Optional[str] = None
    seq_num: Optional[int] = None
    chartdate: Optional[datetime] = None
    icd_version: Optional[int] = None


# Response Models
class PatientResponse(BaseNodeModel):
    """Response model for patient queries."""
    patient: Patient
    admissions: Optional[List[Admission]] = None
    diagnoses: Optional[List[Diagnosis]] = None
    procedures: Optional[List[Procedure]] = None
    medications: Optional[List[Medication]] = None
    lab_events: Optional[List[LabEvent]] = None


class NoteSearchResult(BaseNodeModel):
    """Result model for note searches."""
    note_id: str
    note_type: str
    subject_id: Optional[str] = None
    hadm_id: Optional[str] = None
    charttime: Optional[datetime] = None
    text: str
    score: Optional[float] = None  # For semantic search


class SchemaInfo(BaseNodeModel):
    """Schema information model."""
    nodes: List[Dict[str, Any]]
    relationships: List[Dict[str, Any]]
    constraints: List[Dict[str, Any]]
    indexes: List[Dict[str, Any]]


# Request parameter types
OutputFormat = Literal["json", "table", "text", "markdown"]
NoteType = Literal["discharge", "radiology", "all"]


# Tool response model
class ToolResponse(BaseNodeModel):
    """Standard response for MCP tools."""
    success: bool
    data: Optional[Any] = None
    error: Optional[str] = None
    format: OutputFormat = "json"
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_get_clinical_notes.py">
"""Tests for get clinical notes functionality."""

import json
import pytest
from unittest.mock import AsyncMock, MagicMock

from ...modules.functionality.get_clinical_notes import get_clinical_notes
from ...modules.constants import (
    OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE, OUTPUT_FORMAT_TEXT,
    NOTE_TYPE_DISCHARGE, NOTE_TYPE_RADIOLOGY, NOTE_TYPE_ALL
)


class TestGetClinicalNotesFunctionality:
    """Test suite for get clinical notes functionality."""
    
    @pytest.mark.asyncio
    async def test_get_all_notes(self, mock_db_connection, sample_discharge_note):
        """Test getting all notes without filters."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'note_id': sample_discharge_note.note_id,
            'note_type': sample_discharge_note.note_type,
            'subject_id': sample_discharge_note.subject_id,
            'hadm_id': sample_discharge_note.hadm_id,
            'charttime': sample_discharge_note.charttime,
            'text': sample_discharge_note.text
        }]
        
        # Call function
        result = await get_clinical_notes(
            mock_db_connection,
            note_type=NOTE_TYPE_ALL,
            limit=5,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert isinstance(data, list)
        assert len(data) == 1
        assert data[0]['note_id'] == sample_discharge_note.note_id
        assert data[0]['text'] == sample_discharge_note.text
    
    @pytest.mark.asyncio
    async def test_get_discharge_notes_by_admission(self, mock_db_connection, sample_discharge_note):
        """Test getting discharge notes for specific admission."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'note_id': sample_discharge_note.note_id,
            'note_type': sample_discharge_note.note_type,
            'subject_id': sample_discharge_note.subject_id,
            'hadm_id': sample_discharge_note.hadm_id,
            'charttime': sample_discharge_note.charttime,
            'text': sample_discharge_note.text
        }]
        
        # Call function
        result = await get_clinical_notes(
            mock_db_connection,
            note_type=NOTE_TYPE_DISCHARGE,
            admission_id=sample_discharge_note.hadm_id,
            limit=10,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert isinstance(data, list)
        assert len(data) == 1
        assert data[0]['hadm_id'] == sample_discharge_note.hadm_id
        
        # Check the query was built correctly
        call_args = mock_db_connection.execute_read.call_args
        query = call_args[0][0]
        params = call_args[0][1]
        
        assert "note:DischargeNote" in query
        assert "note.hadm_id = $admission_id" in query
        assert params['admission_id'] == sample_discharge_note.hadm_id
    
    @pytest.mark.asyncio
    async def test_get_radiology_notes_by_patient(self, mock_db_connection):
        """Test getting radiology reports for specific patient."""
        # Mock radiology report data
        mock_radiology_data = {
            'note_id': 'RR-123',
            'note_type': 'RR',
            'subject_id': '10461137',
            'hadm_id': '25236814',
            'charttime': None,
            'text': 'CT SCAN: Pulmonary fibrosis noted...'
        }
        
        # Mock database response
        mock_db_connection.execute_read.return_value = [mock_radiology_data]
        
        # Call function
        result = await get_clinical_notes(
            mock_db_connection,
            note_type=NOTE_TYPE_RADIOLOGY,
            patient_id=mock_radiology_data['subject_id'],
            limit=10,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert isinstance(data, list)
        assert len(data) == 1
        assert data[0]['subject_id'] == mock_radiology_data['subject_id']
        
        # Check the query was built correctly
        call_args = mock_db_connection.execute_read.call_args
        query = call_args[0][0]
        params = call_args[0][1]
        
        assert "note:RadiologyReport" in query
        assert "note.subject_id = $patient_id" in query
        assert params['patient_id'] == mock_radiology_data['subject_id']
    
    @pytest.mark.asyncio
    async def test_empty_results(self, mock_db_connection):
        """Test when no notes are found."""
        # Mock empty response
        mock_db_connection.execute_read.return_value = []
        
        # Call function
        result = await get_clinical_notes(
            mock_db_connection,
            note_type=NOTE_TYPE_ALL,
            patient_id="non_existent",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert isinstance(data, list)
        assert len(data) == 0
    
    @pytest.mark.asyncio
    async def test_table_format_output(self, mock_db_connection, sample_discharge_note):
        """Test table format output."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'note_id': sample_discharge_note.note_id,
            'note_type': sample_discharge_note.note_type,
            'subject_id': sample_discharge_note.subject_id,
            'hadm_id': sample_discharge_note.hadm_id,
            'charttime': sample_discharge_note.charttime,
            'text': sample_discharge_note.text
        }]
        
        # Call function
        result = await get_clinical_notes(
            mock_db_connection,
            note_type=NOTE_TYPE_ALL,
            limit=5,
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Assertions
        assert isinstance(result, str)
        assert "Note ID" in result
        assert "Type" in result
        assert "Patient ID" in result
        assert sample_discharge_note.note_id in result
    
    @pytest.mark.asyncio
    async def test_text_format_output(self, mock_db_connection, sample_discharge_note):
        """Test text format output."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'note_id': sample_discharge_note.note_id,
            'note_type': sample_discharge_note.note_type,
            'subject_id': sample_discharge_note.subject_id,
            'hadm_id': sample_discharge_note.hadm_id,
            'charttime': sample_discharge_note.charttime,
            'text': sample_discharge_note.text
        }]
        
        # Call function
        result = await get_clinical_notes(
            mock_db_connection,
            note_type=NOTE_TYPE_ALL,
            limit=5,
            format=OUTPUT_FORMAT_TEXT
        )
        
        # Assertions
        assert isinstance(result, str)
        assert f"Note 1/1" in result
        assert f"ID: {sample_discharge_note.note_id}" in result
        assert sample_discharge_note.text in result
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_get_schema.py">
"""Tests for get schema functionality."""

import json
import pytest

from ...modules.functionality.get_schema import get_schema, format_schema_as_markdown
from ...modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_MARKDOWN


class TestGetSchemaFunctionality:
    """Test suite for get schema functionality."""
    
    @pytest.mark.asyncio
    async def test_get_schema_json_format(self, mock_db_connection):
        """Test getting schema in JSON format."""
        # Mock schema response
        mock_schema = {
            "nodes": [
                {"label": "Patient", "properties": ["subject_id", "gender", "anchor_age"]},
                {"label": "Admission", "properties": ["hadm_id", "admission_type", "admittime"]},
                {"label": "Diagnosis", "properties": ["icd_code", "long_title"]}
            ],
            "relationships": [
                {"relationshipType": "HAS_ADMISSION"},
                {"relationshipType": "HAS_DIAGNOSIS"}
            ],
            "constraints": [
                {"name": "patient_subject_id_unique", "type": "UNIQUE"},
            ],
            "indexes": [
                {"name": "patient_subject_id_index", "state": "ONLINE"},
            ]
        }
        mock_db_connection.get_schema.return_value = mock_schema
        
        # Call function
        result = await get_schema(mock_db_connection, format=OUTPUT_FORMAT_JSON)
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'nodes' in data
        assert 'relationships' in data
        assert 'known_relationships' in data
        assert len(data['nodes']) == 3
        assert len(data['relationships']) == 2
        
        # Check known relationships were added
        assert len(data['known_relationships']) == 7  # All predefined relationships
        known_rel = data['known_relationships'][0]
        assert 'from' in known_rel
        assert 'to' in known_rel
        assert 'type' in known_rel
        assert 'description' in known_rel
    
    @pytest.mark.asyncio
    async def test_get_schema_markdown_format(self, mock_db_connection):
        """Test getting schema in markdown format."""
        # Mock schema response
        mock_schema = {
            "nodes": [
                {"label": "Patient", "properties": ["subject_id", "gender"]},
                {"label": "Admission", "properties": ["hadm_id", "admission_type"]}
            ],
            "relationships": [
                {"relationshipType": "HAS_ADMISSION"}
            ],
            "constraints": [
                {"name": "constraint_1"}
            ],
            "indexes": [
                {"name": "index_1", "state": "ONLINE"}
            ]
        }
        mock_db_connection.get_schema.return_value = mock_schema
        
        # Call function
        result = await get_schema(mock_db_connection, format=OUTPUT_FORMAT_MARKDOWN)
        
        # Assertions for markdown content
        assert "# Neo4j EHR Database Schema" in result
        assert "## Node Types" in result
        assert "### Patient" in result
        assert "**Properties:** subject_id, gender" in result
        assert "### Admission" in result
        assert "## Relationships" in result
        assert "### HAS_ADMISSION" in result
        assert "- **From:** Patient" in result
        assert "- **To:** Admission" in result
        assert "## Indexes" in result
        assert "- index_1 (State: ONLINE)" in result
        assert "## Constraints" in result
        assert "- constraint_1" in result
        assert "## Example Queries" in result
    
    @pytest.mark.asyncio
    async def test_get_schema_empty_collections(self, mock_db_connection):
        """Test handling of empty schema collections."""
        # Mock minimal schema
        mock_schema = {
            "nodes": [],
            "relationships": [],
            "constraints": [],
            "indexes": []
        }
        mock_db_connection.get_schema.return_value = mock_schema
        
        # Call function
        result = await get_schema(mock_db_connection, format=OUTPUT_FORMAT_JSON)
        
        # Parse result
        data = json.loads(result)
        
        # Should still have known relationships
        assert data['nodes'] == []
        assert data['relationships'] == []
        assert len(data['known_relationships']) == 7
    
    def test_format_schema_as_markdown_complete(self):
        """Test markdown formatting with complete schema."""
        schema = {
            "nodes": [
                {"label": "Patient", "properties": ["subject_id", "gender", "anchor_age"]},
                {"label": "Admission", "properties": ["hadm_id", "admission_type"]},
                {"label": "DischargeNote", "properties": ["note_id", "text", "charttime"]}
            ],
            "relationships": [
                {"relationshipType": "HAS_ADMISSION"},
                {"relationshipType": "INCLUDES_DISCHARGE_NOTE"}
            ],
            "known_relationships": [
                {
                    "from": "Patient",
                    "to": "Admission",
                    "type": "HAS_ADMISSION",
                    "description": "Patient has hospital admissions"
                },
                {
                    "from": "Admission",
                    "to": "DischargeNote",
                    "type": "INCLUDES_DISCHARGE_NOTE",
                    "description": "Admission includes discharge summary notes"
                }
            ],
            "indexes": [
                {"name": "patient_subject_id_idx", "state": "ONLINE"},
                {"name": "note_embeddings", "state": "ONLINE"}
            ],
            "constraints": [
                {"name": "patient_subject_id_unique"},
                {"name": "admission_hadm_id_unique"}
            ]
        }
        
        result = format_schema_as_markdown(schema)
        
        # Verify all sections are present
        assert "# Neo4j EHR Database Schema" in result
        assert "## Node Types" in result
        assert "### Patient" in result
        assert "### Admission" in result
        assert "### DischargeNote" in result
        assert "## Relationships" in result
        assert "### HAS_ADMISSION" in result
        assert "### INCLUDES_DISCHARGE_NOTE" in result
        assert "## Indexes" in result
        assert "patient_subject_id_idx" in result
        assert "## Constraints" in result
        assert "patient_subject_id_unique" in result
        assert "## Example Queries" in result
        
        # Verify example queries are included
        assert "Get patient with all admissions" in result
        assert "Find discharge notes mentioning a condition" in result
        assert "Get abnormal lab results for a patient" in result
    
    def test_format_schema_as_markdown_minimal(self):
        """Test markdown formatting with minimal schema."""
        schema = {
            "nodes": [{"label": "TestNode", "properties": ["id"]}],
            "relationships": [],
            "known_relationships": [],
            "indexes": [],
            "constraints": []
        }
        
        result = format_schema_as_markdown(schema)
        
        # Should still have all sections, even if empty
        assert "## Node Types" in result
        assert "### TestNode" in result
        assert "## Relationships" in result
        assert "## Example Queries" in result
    
    @pytest.mark.asyncio
    async def test_get_schema_preserves_original(self, mock_db_connection):
        """Test that getting schema preserves original database schema data."""
        # Mock schema with extra fields
        mock_schema = {
            "nodes": [{"label": "Patient", "properties": ["subject_id"], "extra": "data"}],
            "relationships": [{"relationshipType": "HAS_ADMISSION", "count": 100}],
            "constraints": [],
            "indexes": [],
            "custom_field": "should be preserved"
        }
        mock_db_connection.get_schema.return_value = mock_schema
        
        # Call function
        result = await get_schema(mock_db_connection, format=OUTPUT_FORMAT_JSON)
        
        # Parse result
        data = json.loads(result)
        
        # Original fields should be preserved
        assert data['nodes'][0].get('extra') == "data"
        assert data['relationships'][0].get('count') == 100
        assert data.get('custom_field') == "should be preserved"


@pytest.mark.integration
class TestGetSchemaIntegration:
    """Integration tests with real Neo4j database."""
    
    @pytest.mark.asyncio
    async def test_get_real_schema(self, real_db_connection):
        """Test getting real schema from the database."""
        # Get schema in JSON format
        result = await get_schema(real_db_connection, format=OUTPUT_FORMAT_JSON)
        data = json.loads(result)
        
        # Basic assertions
        assert 'nodes' in data
        assert 'relationships' in data
        assert 'known_relationships' in data
        
        # Should have at least Patient node
        patient_nodes = [n for n in data['nodes'] if n['label'] == 'Patient']
        assert len(patient_nodes) > 0
        
        # Get schema in markdown format
        result_md = await get_schema(real_db_connection, format=OUTPUT_FORMAT_MARKDOWN)
        
        # Should be valid markdown
        assert isinstance(result_md, str)
        assert "# Neo4j EHR Database Schema" in result_md
        assert "Patient" in result_md
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_list_diagnoses.py">
"""Tests for list diagnoses functionality."""

import json
import pytest

from ...modules.functionality.list_diagnoses import list_diagnoses
from ...modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


class TestListDiagnosesFunctionality:
    """Test suite for list diagnoses functionality."""
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_by_admission(self, mock_db_connection, sample_diagnosis):
        """Test listing diagnoses for a specific admission."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'd': sample_diagnosis.model_dump()
        }]
        
        # Call function
        result = await list_diagnoses(
            mock_db_connection,
            admission_id="22595853",
            limit=20,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'diagnoses' in data
        assert 'count' in data
        assert data['count'] == 1
        assert data['diagnoses'][0]['icd_code'] == "I50.9"
        assert data['diagnoses'][0]['long_title'] == "Heart failure, unspecified"
        
        # Verify query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "MATCH (a:Admission {hadm_id: $admission_id})" in query
        assert "-[:HAS_DIAGNOSIS]->" in query
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_by_patient(self, mock_db_connection, sample_diagnosis):
        """Test listing diagnoses for a specific patient."""
        # Mock database response with admission ID
        diagnosis_data = sample_diagnosis.model_dump()
        mock_db_connection.execute_read.return_value = [{
            'd': diagnosis_data,
            'hadm_id': "22595853"
        }]
        
        # Call function
        result = await list_diagnoses(
            mock_db_connection,
            patient_id="10000032",
            limit=20,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert data['count'] == 1
        assert data['diagnoses'][0]['hadm_id'] == "22595853"
        
        # Verify query includes patient join
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "MATCH (p:Patient {subject_id: $patient_id})" in query
        assert "-[:HAS_ADMISSION]->" in query
        assert "-[:HAS_DIAGNOSIS]->" in query
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_no_params_error(self, mock_db_connection):
        """Test error when neither patient_id nor admission_id provided."""
        result = await list_diagnoses(
            mock_db_connection,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert 'error' in data
        assert "Either patient_id or admission_id must be provided" in data['error']
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_empty_results(self, mock_db_connection):
        """Test handling of empty results."""
        mock_db_connection.execute_read.return_value = []
        
        result = await list_diagnoses(
            mock_db_connection,
            admission_id="99999999",
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert data['diagnoses'] == []
        assert data['message'] == "No diagnoses found"
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_table_format(self, mock_db_connection, sample_diagnosis):
        """Test table format output."""
        mock_db_connection.execute_read.return_value = [{
            'd': sample_diagnosis.model_dump()
        }]
        
        result = await list_diagnoses(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Assertions
        assert isinstance(result, str)
        assert "ICD Code" in result
        assert "Description" in result
        assert "I50.9" in result
        assert "Heart failure, unspecified" in result
        assert "ICD-10" in result
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_limit(self, mock_db_connection, sample_diagnosis):
        """Test limit parameter."""
        # Mock multiple diagnoses
        diagnoses = []
        for i in range(5):
            diag = sample_diagnosis.model_dump()
            diag['seq_num'] = i + 1
            diag['icd_code'] = f"I50.{i}"
            diagnoses.append({'d': diag})
        
        mock_db_connection.execute_read.return_value = diagnoses[:3]  # Limited to 3
        
        result = await list_diagnoses(
            mock_db_connection,
            admission_id="22595853",
            limit=3,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert len(data['diagnoses']) == 3
        
        # Verify limit in query
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['limit'] == 3
    
    @pytest.mark.asyncio
    async def test_list_diagnoses_ordering(self, mock_db_connection):
        """Test correct ordering of results."""
        # For admission query
        await list_diagnoses(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_JSON
        )
        
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "ORDER BY d.seq_num" in query
        
        # For patient query
        await list_diagnoses(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_JSON
        )
        
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "ORDER BY a.admittime DESC, d.seq_num" in query


@pytest.mark.integration
class TestListDiagnosesIntegration:
    """Integration tests with real Neo4j database."""
    
    @pytest.mark.asyncio
    async def test_list_real_diagnoses_by_patient(self, real_db_connection):
        """Test listing real diagnoses from the database."""
        result = await list_diagnoses(
            real_db_connection,
            patient_id="10461137",  # Adjust based on test data
            limit=5,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        
        # Basic assertions
        assert 'diagnoses' in data
        assert 'count' in data
        assert isinstance(data['diagnoses'], list)
        
        # If diagnoses found, verify structure
        if data['diagnoses']:
            diagnosis = data['diagnoses'][0]
            assert 'icd_code' in diagnosis
            assert 'hadm_id' in diagnosis
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_list_lab_events.py">
"""Tests for list lab events functionality."""

import json
import pytest

from ...modules.functionality.list_lab_events import list_lab_events
from ...modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


class TestListLabEventsFunctionality:
    """Test suite for list lab events functionality."""
    
    @pytest.mark.asyncio
    async def test_list_lab_events_basic(self, mock_db_connection, sample_lab_event):
        """Test basic lab event listing for a patient."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'l': sample_lab_event.model_dump()
        }]
        
        # Call function
        result = await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'lab_events' in data
        assert 'count' in data
        assert data['count'] == 1
        assert data['lab_events'][0]['label'] == "Sodium"
        assert data['lab_events'][0]['value'] == "130"
        assert data['lab_events'][0]['flag'] == "abnormal"
        
        # Verify query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "l.subject_id = $patient_id" in query
        assert "ORDER BY l.charttime DESC" in query
    
    @pytest.mark.asyncio
    async def test_list_lab_events_with_admission(self, mock_db_connection, sample_lab_event):
        """Test listing lab events for specific admission."""
        mock_db_connection.execute_read.return_value = [{
            'l': sample_lab_event.model_dump()
        }]
        
        # Call function
        result = await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            admission_id="22595853",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify both filters in query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "l.subject_id = $patient_id" in query
        assert "l.hadm_id = $admission_id" in query
    
    @pytest.mark.asyncio
    async def test_list_lab_events_abnormal_only(self, mock_db_connection, sample_lab_event):
        """Test filtering for abnormal lab results only."""
        mock_db_connection.execute_read.return_value = [{
            'l': sample_lab_event.model_dump()
        }]
        
        # Call function
        result = await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            abnormal_only=True,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify abnormal filter in query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "l.flag IS NOT NULL" in query
        assert "l.flag <> 'normal'" in query
    
    @pytest.mark.asyncio
    async def test_list_lab_events_by_category(self, mock_db_connection, sample_lab_event):
        """Test filtering by category."""
        mock_db_connection.execute_read.return_value = [{
            'l': sample_lab_event.model_dump()
        }]
        
        # Call function
        result = await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            category="CHEMISTRY",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify category filter
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "toLower(l.category) = toLower($category)" in query
        
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['category'] == "CHEMISTRY"
    
    @pytest.mark.asyncio
    async def test_list_lab_events_empty_results(self, mock_db_connection):
        """Test handling of empty results."""
        mock_db_connection.execute_read.return_value = []
        
        result = await list_lab_events(
            mock_db_connection,
            patient_id="99999999",
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert data['lab_events'] == []
        assert data['message'] == "No lab events found"
    
    @pytest.mark.asyncio
    async def test_list_lab_events_table_format(self, mock_db_connection, sample_lab_event):
        """Test table format output."""
        mock_db_connection.execute_read.return_value = [{
            'l': sample_lab_event.model_dump()
        }]
        
        result = await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Assertions
        assert isinstance(result, str)
        assert "Test Name" in result
        assert "Value (Range)" in result
        assert "Sodium" in result
        assert "130 (136.0-145.0)" in result  # Value with reference range
        assert "abnormal" in result
        assert "CHEMISTRY" in result
    
    @pytest.mark.asyncio
    async def test_list_lab_events_table_format_no_ref_range(self, mock_db_connection):
        """Test table format when reference range is missing."""
        lab_event = {
            'lab_event_id': '123',
            'subject_id': '10000032',
            'hadm_id': '22595853',
            'charttime': '2124-08-08T06:00:00',
            'label': 'Custom Test',
            'value': 'Positive',
            'flag': 'normal',
            'category': 'OTHER',
            'ref_range_lower': None,
            'ref_range_upper': None
        }
        
        mock_db_connection.execute_read.return_value = [{'l': lab_event}]
        
        result = await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Should show value without range
        assert "Positive" in result
        assert "(--)" not in result  # No empty range shown
    
    @pytest.mark.asyncio
    async def test_list_lab_events_all_filters(self, mock_db_connection):
        """Test using all available filters together."""
        mock_db_connection.execute_read.return_value = []
        
        await list_lab_events(
            mock_db_connection,
            patient_id="10000032",
            admission_id="22595853",
            abnormal_only=True,
            category="CHEMISTRY",
            limit=10,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify all conditions in query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "l.subject_id = $patient_id" in query
        assert "l.hadm_id = $admission_id" in query
        assert "l.flag IS NOT NULL" in query
        assert "l.flag <> 'normal'" in query
        assert "toLower(l.category) = toLower($category)" in query
        
        # Verify all parameters
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['patient_id'] == "10000032"
        assert params['admission_id'] == "22595853"
        assert params['category'] == "CHEMISTRY"
        assert params['limit'] == 10


@pytest.mark.integration
class TestListLabEventsIntegration:
    """Integration tests with real Neo4j database."""
    
    @pytest.mark.asyncio
    async def test_list_real_lab_events(self, real_db_connection):
        """Test listing real lab events from the database."""
        result = await list_lab_events(
            real_db_connection,
            patient_id="10461137",  # Adjust based on test data
            limit=5,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        
        # Basic assertions
        assert 'lab_events' in data
        assert 'count' in data
        assert isinstance(data['lab_events'], list)
        
        # If lab events found, verify structure
        if data['lab_events']:
            lab_event = data['lab_events'][0]
            assert 'label' in lab_event
            assert 'value' in lab_event
            assert 'charttime' in lab_event
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_list_medications.py">
"""Tests for list medications functionality."""

import json
import pytest

from ...modules.functionality.list_medications import list_medications
from ...modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


class TestListMedicationsFunctionality:
    """Test suite for list medications functionality."""
    
    @pytest.mark.asyncio
    async def test_list_medications_by_admission(self, mock_db_connection, sample_medication):
        """Test listing medications for a specific admission."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'm': sample_medication.model_dump()
        }]
        
        # Call function
        result = await list_medications(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'medications' in data
        assert 'count' in data
        assert data['count'] == 1
        assert data['medications'][0]['medication'] == "Furosemide"
        assert data['medications'][0]['route'] == "PO"
        assert data['medications'][0]['frequency'] == "BID"
        
        # Verify query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "m.hadm_id = $admission_id" in query
        assert "ORDER BY m.verifiedtime DESC" in query
    
    @pytest.mark.asyncio
    async def test_list_medications_by_patient(self, mock_db_connection, sample_medication):
        """Test listing medications for a specific patient."""
        mock_db_connection.execute_read.return_value = [{
            'm': sample_medication.model_dump()
        }]
        
        # Call function
        result = await list_medications(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify query uses patient_id
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "m.subject_id = $patient_id" in query
    
    @pytest.mark.asyncio
    async def test_list_medications_by_name(self, mock_db_connection, sample_medication):
        """Test filtering medications by name."""
        mock_db_connection.execute_read.return_value = [{
            'm': sample_medication.model_dump()
        }]
        
        # Call function
        result = await list_medications(
            mock_db_connection,
            patient_id="10000032",
            medication="furosemide",  # Test case-insensitive search
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify medication filter
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "toLower(m.medication) CONTAINS toLower($medication)" in query
        
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['medication'] == "furosemide"
    
    @pytest.mark.asyncio
    async def test_list_medications_by_route(self, mock_db_connection, sample_medication):
        """Test filtering medications by route."""
        mock_db_connection.execute_read.return_value = [{
            'm': sample_medication.model_dump()
        }]
        
        # Call function
        result = await list_medications(
            mock_db_connection,
            admission_id="22595853",
            route="po",  # Test case-insensitive
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify route filter
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "toLower(m.route) = toLower($route)" in query
        
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['route'] == "po"
    
    @pytest.mark.asyncio
    async def test_list_medications_no_params_error(self, mock_db_connection):
        """Test error when neither patient_id nor admission_id provided."""
        result = await list_medications(
            mock_db_connection,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert 'error' in data
        assert "Either patient_id or admission_id must be provided" in data['error']
    
    @pytest.mark.asyncio
    async def test_list_medications_empty_results(self, mock_db_connection):
        """Test handling of empty results."""
        mock_db_connection.execute_read.return_value = []
        
        result = await list_medications(
            mock_db_connection,
            patient_id="99999999",
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert data['medications'] == []
        assert data['message'] == "No medications found"
    
    @pytest.mark.asyncio
    async def test_list_medications_table_format(self, mock_db_connection, sample_medication):
        """Test table format output."""
        # Add verifiedtime to sample
        med_data = sample_medication.model_dump()
        med_data['verifiedtime'] = '2124-08-08T10:00:00'
        
        mock_db_connection.execute_read.return_value = [{'m': med_data}]
        
        result = await list_medications(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Assertions
        assert isinstance(result, str)
        assert "Medication" in result
        assert "Route" in result
        assert "Frequency" in result
        assert "Furosemide" in result
        assert "PO" in result
        assert "BID" in result
        assert "2124-08-08" in result
    
    @pytest.mark.asyncio
    async def test_list_medications_missing_fields(self, mock_db_connection):
        """Test handling medications with missing optional fields."""
        # Medication with minimal fields
        minimal_med = {
            'medication': 'Aspirin',
            'hadm_id': '22595853',
            'subject_id': '10000032',
            'route': None,
            'frequency': None,
            'verifiedtime': None
        }
        
        mock_db_connection.execute_read.return_value = [{'m': minimal_med}]
        
        result = await list_medications(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Should show N/A for missing fields
        assert "Aspirin" in result
        assert "N/A" in result  # For missing fields
    
    @pytest.mark.asyncio
    async def test_list_medications_combined_filters(self, mock_db_connection):
        """Test using multiple filters together."""
        mock_db_connection.execute_read.return_value = []
        
        await list_medications(
            mock_db_connection,
            patient_id="10000032",
            medication="metformin",
            route="PO",
            limit=5,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Verify all conditions in query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "m.subject_id = $patient_id" in query
        assert "toLower(m.medication) CONTAINS toLower($medication)" in query
        assert "toLower(m.route) = toLower($route)" in query
        
        # Verify all parameters
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['patient_id'] == "10000032"
        assert params['medication'] == "metformin"
        assert params['route'] == "PO"
        assert params['limit'] == 5


@pytest.mark.integration
class TestListMedicationsIntegration:
    """Integration tests with real Neo4j database."""
    
    @pytest.mark.asyncio
    async def test_list_real_medications_by_patient(self, real_db_connection):
        """Test listing real medications from the database."""
        result = await list_medications(
            real_db_connection,
            patient_id="10461137",  # Adjust based on test data
            limit=5,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        
        # Basic assertions
        assert 'medications' in data
        assert 'count' in data
        assert isinstance(data['medications'], list)
        
        # If medications found, verify structure
        if data['medications']:
            medication = data['medications'][0]
            assert 'medication' in medication
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_list_procedures.py">
"""Tests for list procedures functionality."""

import json
import pytest

from ...modules.functionality.list_procedures import list_procedures
from ...modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


class TestListProceduresFunctionality:
    """Test suite for list procedures functionality."""
    
    @pytest.mark.asyncio
    async def test_list_procedures_by_admission(self, mock_db_connection, sample_procedure):
        """Test listing procedures for a specific admission."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'p': sample_procedure.model_dump()
        }]
        
        # Call function
        result = await list_procedures(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'procedures' in data
        assert 'count' in data
        assert data['count'] == 1
        assert data['procedures'][0]['icd_code'] == "99.04"
        assert data['procedures'][0]['long_title'] == "Transfusion of packed cells"
        assert data['procedures'][0]['icd_version'] == 9
        
        # Verify query
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "MATCH (a:Admission {hadm_id: $admission_id})" in query
        assert "-[:HAS_PROCEDURE]->" in query
        assert "ORDER BY p.seq_num" in query
    
    @pytest.mark.asyncio
    async def test_list_procedures_by_patient(self, mock_db_connection, sample_procedure):
        """Test listing procedures for a specific patient."""
        # Mock database response with admission ID
        procedure_data = sample_procedure.model_dump()
        mock_db_connection.execute_read.return_value = [{
            'p': procedure_data,
            'hadm_id': "22595853"
        }]
        
        # Call function
        result = await list_procedures(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert data['count'] == 1
        assert data['procedures'][0]['hadm_id'] == "22595853"
        
        # Verify query includes patient join
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "MATCH (pat:Patient {subject_id: $patient_id})" in query
        assert "-[:HAS_ADMISSION]->" in query
        assert "-[:HAS_PROCEDURE]->" in query
        assert "ORDER BY p.chartdate DESC, p.seq_num" in query
    
    @pytest.mark.asyncio
    async def test_list_procedures_no_params_error(self, mock_db_connection):
        """Test error when neither patient_id nor admission_id provided."""
        result = await list_procedures(
            mock_db_connection,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert 'error' in data
        assert "Either patient_id or admission_id must be provided" in data['error']
    
    @pytest.mark.asyncio
    async def test_list_procedures_empty_results(self, mock_db_connection):
        """Test handling of empty results."""
        mock_db_connection.execute_read.return_value = []
        
        result = await list_procedures(
            mock_db_connection,
            admission_id="99999999",
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert data['procedures'] == []
        assert data['message'] == "No procedures found"
    
    @pytest.mark.asyncio
    async def test_list_procedures_table_format(self, mock_db_connection, sample_procedure):
        """Test table format output."""
        mock_db_connection.execute_read.return_value = [{
            'p': sample_procedure.model_dump()
        }]
        
        result = await list_procedures(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Assertions
        assert isinstance(result, str)
        assert "ICD Code" in result
        assert "Description" in result
        assert "Chart Date" in result
        assert "99.04" in result
        assert "Transfusion of packed cells" in result
        assert "2124-08-08" in result
        assert "ICD-9" in result
    
    @pytest.mark.asyncio
    async def test_list_procedures_limit(self, mock_db_connection, sample_procedure):
        """Test limit parameter."""
        # Mock multiple procedures
        procedures = []
        for i in range(5):
            proc = sample_procedure.model_dump()
            proc['seq_num'] = i + 1
            proc['icd_code'] = f"99.0{i}"
            procedures.append({'p': proc})
        
        mock_db_connection.execute_read.return_value = procedures[:3]  # Limited to 3
        
        result = await list_procedures(
            mock_db_connection,
            admission_id="22595853",
            limit=3,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        assert len(data['procedures']) == 3
        
        # Verify limit in query
        params = mock_db_connection.execute_read.call_args[0][1]
        assert params['limit'] == 3
    
    @pytest.mark.asyncio
    async def test_list_procedures_missing_fields(self, mock_db_connection):
        """Test handling procedures with missing optional fields."""
        # Procedure with minimal fields
        minimal_proc = {
            'icd_code': '99.99',
            'long_title': None,
            'hadm_id': '22595853',
            'seq_num': None,
            'chartdate': None,
            'icd_version': None
        }
        
        mock_db_connection.execute_read.return_value = [{'p': minimal_proc}]
        
        result = await list_procedures(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Should show N/A for missing fields
        assert "99.99" in result
        assert "N/A" in result  # For missing fields
    
    @pytest.mark.asyncio
    async def test_list_procedures_ordering(self, mock_db_connection):
        """Test correct ordering of results."""
        # Multiple procedures with different dates and sequences
        procedures = [
            {
                'p': {
                    'icd_code': '99.01',
                    'long_title': 'Procedure 1',
                    'seq_num': 2,
                    'chartdate': '2124-08-08'
                }
            },
            {
                'p': {
                    'icd_code': '99.02',
                    'long_title': 'Procedure 2',
                    'seq_num': 1,
                    'chartdate': '2124-08-08'
                }
            }
        ]
        
        mock_db_connection.execute_read.return_value = procedures
        
        # For admission query - should order by seq_num
        result = await list_procedures(
            mock_db_connection,
            admission_id="22595853",
            format=OUTPUT_FORMAT_JSON
        )
        
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "ORDER BY p.seq_num" in query
        
        # For patient query - should order by chartdate DESC, then seq_num
        result = await list_procedures(
            mock_db_connection,
            patient_id="10000032",
            format=OUTPUT_FORMAT_JSON
        )
        
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "ORDER BY p.chartdate DESC, p.seq_num" in query


@pytest.mark.integration
class TestListProceduresIntegration:
    """Integration tests with real Neo4j database."""
    
    @pytest.mark.asyncio
    async def test_list_real_procedures_by_patient(self, real_db_connection):
        """Test listing real procedures from the database."""
        result = await list_procedures(
            real_db_connection,
            patient_id="10461137",  # Adjust based on test data
            limit=5,
            format=OUTPUT_FORMAT_JSON
        )
        
        data = json.loads(result)
        
        # Basic assertions
        assert 'procedures' in data
        assert isinstance(data['procedures'], list)
        # count is only present when procedures are found
        if data['procedures']:
            assert 'count' in data
        
        # If procedures found, verify structure
        if data['procedures']:
            procedure = data['procedures'][0]
            assert 'icd_code' in procedure
            assert 'hadm_id' in procedure
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_natural_query.py">
"""Tests for natural language query functionality."""

import json
import os
import pytest
from unittest.mock import patch, MagicMock

from ...modules.functionality.natural_query import natural_query, format_schema_for_llm
from ...modules.constants import (
    OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE, OUTPUT_FORMAT_MARKDOWN
)


class TestNaturalQueryFunctionality:
    """Test suite for natural language query functionality."""
    
    @pytest.mark.asyncio
    async def test_natural_query_success(self, mock_db_connection, mock_openai_response):
        """Test successful natural language query conversion and execution."""
        # Mock schema response
        schema = {
            "nodes": [
                {"label": "Patient", "properties": ["subject_id", "gender", "anchor_age"]},
                {"label": "Admission", "properties": ["hadm_id", "admission_type"]}
            ],
            "relationships": [
                {"relationshipType": "HAS_ADMISSION"}
            ]
        }
        mock_db_connection.get_schema.return_value = schema
        
        # Mock Cypher query execution
        mock_db_connection.execute_read.return_value = [
            {"subject_id": "10000032", "count": 3}
        ]
        
        # Mock OpenAI to return a valid Cypher query
        mock_openai_response.chat.completions.create.return_value = MagicMock(
            choices=[MagicMock(
                message=MagicMock(
                    content='MATCH (p:Patient {subject_id: "10000032"})-[:HAS_ADMISSION]->(a:Admission) RETURN p.subject_id as subject_id, count(a) as count'
                )
            )]
        )
        
        # Execute test
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_openai_response):
            result = await natural_query(
                mock_db_connection,
                query="How many admissions does patient 10000032 have?",
                limit=10,
                format=OUTPUT_FORMAT_JSON,
                openai_api_key="test-key"
            )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'question' in data
        assert 'cypher_query' in data
        assert 'results' in data
        assert 'count' in data
        assert data['count'] == 1
        assert data['results'][0]['subject_id'] == "10000032"
        assert data['results'][0]['count'] == 3
    
    @pytest.mark.asyncio
    async def test_natural_query_with_cypher_extraction(self, mock_db_connection, mock_openai_response):
        """Test extraction of Cypher from markdown code blocks."""
        # Mock schema
        mock_db_connection.get_schema.return_value = {"nodes": [], "relationships": []}
        mock_db_connection.execute_read.return_value = [{"result": "test"}]
        
        # Mock OpenAI to return Cypher in markdown
        mock_openai_response.chat.completions.create.return_value = MagicMock(
            choices=[MagicMock(
                message=MagicMock(
                    content='```cypher\nMATCH (p:Patient) RETURN p LIMIT 10\n```'
                )
            )]
        )
        
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_openai_response):
            result = await natural_query(
                mock_db_connection,
                query="Show me all patients",
                limit=10,
                format=OUTPUT_FORMAT_JSON,
                openai_api_key="test-key"
            )
        
        data = json.loads(result)
        assert data['cypher_query'] == "MATCH (p:Patient) RETURN p LIMIT 10"
    
    @pytest.mark.asyncio
    async def test_natural_query_cypher_error(self, mock_db_connection, mock_openai_response):
        """Test handling of Cypher execution errors."""
        mock_db_connection.get_schema.return_value = {"nodes": [], "relationships": []}
        
        # Mock Cypher execution error
        mock_db_connection.execute_read.side_effect = Exception("Invalid Cypher syntax")
        
        mock_openai_response.chat.completions.create.return_value = MagicMock(
            choices=[MagicMock(
                message=MagicMock(content='INVALID CYPHER QUERY')
            )]
        )
        
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_openai_response):
            result = await natural_query(
                mock_db_connection,
                query="Test query",
                format=OUTPUT_FORMAT_JSON,
                openai_api_key="test-key"
            )
        
        data = json.loads(result)
        assert 'error' in data
        assert "Failed to execute generated query" in data['error']
        assert data['query'] == "INVALID CYPHER QUERY"
    
    @pytest.mark.asyncio
    async def test_natural_query_openai_error(self, mock_db_connection):
        """Test handling of OpenAI API errors."""
        mock_db_connection.get_schema.return_value = {"nodes": [], "relationships": []}
        
        # Mock OpenAI error
        mock_client = MagicMock()
        mock_client.chat.completions.create.side_effect = Exception("API Error")
        
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_client):
            result = await natural_query(
                mock_db_connection,
                query="Test query",
                format=OUTPUT_FORMAT_JSON,
                openai_api_key="test-key"
            )
        
        data = json.loads(result)
        assert 'error' in data
        assert "Failed to process natural language query" in data['error']
    
    @pytest.mark.asyncio
    async def test_natural_query_markdown_format(self, mock_db_connection, mock_openai_response):
        """Test markdown format output."""
        mock_db_connection.get_schema.return_value = {"nodes": [], "relationships": []}
        mock_db_connection.execute_read.return_value = [
            {"patient_id": "10000032", "diagnosis": "Heart failure"},
            {"patient_id": "10000033", "diagnosis": "Pneumonia"}
        ]
        
        mock_openai_response.chat.completions.create.return_value = MagicMock(
            choices=[MagicMock(
                message=MagicMock(
                    content='MATCH (p:Patient)-[:HAS_DIAGNOSIS]->(d:Diagnosis) RETURN p.subject_id as patient_id, d.long_title as diagnosis LIMIT 2'
                )
            )]
        )
        
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_openai_response):
            result = await natural_query(
                mock_db_connection,
                query="Show me patient diagnoses",
                format=OUTPUT_FORMAT_MARKDOWN,
                openai_api_key="test-key"
            )
        
        # Assertions for markdown format
        assert "## Question" in result
        assert "## Generated Cypher Query" in result
        assert "```cypher" in result
        assert "## Results (2 rows)" in result
        assert "| patient_id | diagnosis |" in result
        assert "| 10000032 | Heart failure |" in result
    
    @pytest.mark.asyncio
    async def test_natural_query_table_format(self, mock_db_connection, mock_openai_response):
        """Test table format output."""
        mock_db_connection.get_schema.return_value = {"nodes": [], "relationships": []}
        mock_db_connection.execute_read.return_value = [
            {"name": "Test", "value": 123}
        ]
        
        mock_openai_response.chat.completions.create.return_value = MagicMock(
            choices=[MagicMock(
                message=MagicMock(content='MATCH (n) RETURN n.name as name, n.value as value LIMIT 1')
            )]
        )
        
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_openai_response):
            result = await natural_query(
                mock_db_connection,
                query="Test query",
                format=OUTPUT_FORMAT_TABLE,
                openai_api_key="test-key"
            )
        
        assert "QUESTION:" in result
        assert "CYPHER QUERY:" in result
        assert "RESULTS (1 rows):" in result
        assert "name" in result
        assert "value" in result
    
    def test_format_schema_for_llm(self):
        """Test schema formatting for LLM context."""
        schema = {
            "nodes": [
                {"label": "Patient", "properties": ["subject_id", "gender"]},
                {"label": "Admission", "properties": ["hadm_id", "admission_type"]}
            ],
            "relationships": [
                {"relationshipType": "HAS_ADMISSION"},
                {"relationshipType": "HAS_DIAGNOSIS"}
            ]
        }
        
        formatted = format_schema_for_llm(schema)
        
        # Assertions
        assert "NODES:" in formatted
        assert "- Patient: subject_id, gender" in formatted
        assert "- Admission: hadm_id, admission_type" in formatted
        assert "RELATIONSHIPS:" in formatted
        assert "- HAS_ADMISSION" in formatted
        assert "KEY RELATIONSHIPS:" in formatted
        assert "(Patient)-[:HAS_ADMISSION]->(Admission)" in formatted
    
    @pytest.mark.asyncio
    async def test_natural_query_empty_results(self, mock_db_connection, mock_openai_response):
        """Test handling of empty query results."""
        mock_db_connection.get_schema.return_value = {"nodes": [], "relationships": []}
        mock_db_connection.execute_read.return_value = []
        
        mock_openai_response.chat.completions.create.return_value = MagicMock(
            choices=[MagicMock(
                message=MagicMock(content='MATCH (n:NonExistent) RETURN n')
            )]
        )
        
        with patch('src.mcp_server_neo4j_ehr.modules.functionality.natural_query.OpenAI', return_value=mock_openai_response):
            result = await natural_query(
                mock_db_connection,
                query="Find non-existent data",
                format=OUTPUT_FORMAT_MARKDOWN,
                openai_api_key="test-key"
            )
        
        assert "No results found." in result


@pytest.mark.integration
class TestNaturalQueryIntegration:
    """Integration tests with real Neo4j database and OpenAI."""
    
    @pytest.mark.asyncio
    @pytest.mark.skipif(not os.getenv("OPENAI_API_KEY"), reason="OpenAI API key not configured")
    async def test_natural_query_real_integration(self, real_db_connection):
        """Test natural language query with real database and OpenAI."""
        openai_key = os.getenv("OPENAI_API_KEY")
        
        result = await natural_query(
            real_db_connection,
            query="How many patients are in the database?",
            limit=10,
            format=OUTPUT_FORMAT_JSON,
            openai_api_key=openai_key
        )
        
        data = json.loads(result)
        
        # Print the full response for debugging
        print("\n" + "="*80)
        print("NATURAL LANGUAGE QUERY TEST RESULTS")
        print("="*80)
        print(f"Question: {data.get('question', 'N/A')}")
        print(f"\nGenerated Cypher Query:\n{data.get('cypher_query', 'N/A')}")
        print(f"\nResult Count: {data.get('count', 0)}")
        print(f"\nResults: {json.dumps(data.get('results', []), indent=2)}")
        print("="*80 + "\n")
        
        # Basic assertions
        assert 'cypher_query' in data
        assert 'results' in data
        # Verify it generated a query about patients
        assert 'Patient' in data['cypher_query']
</file>

<file path="src/mcp_server_neo4j_ehr/tests/functionality/test_patient.py">
"""Tests for patient query functionality."""

import json
import pytest
from unittest.mock import AsyncMock

from ...modules.functionality.patient import get_patient
from ...modules.data_types import OutputFormat
from ...modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE


class TestPatientFunctionality:
    """Test suite for patient query functionality."""
    
    @pytest.mark.asyncio
    async def test_get_patient_basic(self, mock_db_connection, sample_patient):
        """Test basic patient retrieval without additional data."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'p': sample_patient.model_dump()
        }]
        
        # Call function
        result = await get_patient(
            mock_db_connection,
            subject_id="10000032",
            include_admissions=False,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'patient' in data
        assert data['patient']['subject_id'] == "10000032"
        assert data['patient']['gender'] == "M"
        assert 'admissions' not in data
        
        # Verify query was called correctly
        mock_db_connection.execute_read.assert_called_once()
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "MATCH (p:Patient {subject_id: $subject_id})" in query
        assert "HAS_ADMISSION" not in query
    
    @pytest.mark.asyncio
    async def test_get_patient_with_admissions(
        self, mock_db_connection, sample_patient, sample_admission
    ):
        """Test patient retrieval with admissions."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'p': sample_patient.model_dump(),
            'admissions': [sample_admission.model_dump()]
        }]
        
        # Call function
        result = await get_patient(
            mock_db_connection,
            subject_id="10000032",
            include_admissions=True,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'admissions' in data
        assert len(data['admissions']) == 1
        assert data['admissions'][0]['hadm_id'] == "22595853"
        
        # Verify query includes admission join
        query = mock_db_connection.execute_read.call_args[0][0]
        assert "OPTIONAL MATCH (p)-[:HAS_ADMISSION]->(a:Admission)" in query
    
    @pytest.mark.asyncio
    async def test_get_patient_with_all_data(
        self, mock_db_connection, sample_patient, sample_admission,
        sample_diagnosis, sample_procedure, sample_medication, sample_lab_event
    ):
        """Test patient retrieval with all related data."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'p': sample_patient.model_dump(),
            'admissions': [sample_admission.model_dump()],
            'diagnoses': [sample_diagnosis.model_dump()],
            'procedures': [sample_procedure.model_dump()],
            'medications': [sample_medication.model_dump()],
            'lab_events': [sample_lab_event.model_dump()]
        }]
        
        # Call function with all includes
        result = await get_patient(
            mock_db_connection,
            subject_id="10000032",
            include_admissions=True,
            include_diagnoses=True,
            include_procedures=True,
            include_medications=True,
            include_lab_events=True,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert all(key in data for key in [
            'patient', 'admissions', 'diagnoses', 
            'procedures', 'medications', 'lab_events'
        ])
        assert len(data['diagnoses']) == 1
        assert data['diagnoses'][0]['icd_code'] == "I50.9"
        assert len(data['medications']) == 1
        assert data['medications'][0]['medication'] == "Furosemide"
    
    @pytest.mark.asyncio
    async def test_patient_not_found(self, mock_db_connection):
        """Test handling when patient is not found."""
        # Mock empty response
        mock_db_connection.execute_read.return_value = []
        
        # Call function
        result = await get_patient(
            mock_db_connection,
            subject_id="99999999",
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert 'error' in data
        assert "Patient 99999999 not found" in data['error']
    
    @pytest.mark.asyncio
    async def test_get_patient_table_format(
        self, mock_db_connection, sample_patient, sample_admission
    ):
        """Test patient retrieval with table format output."""
        # Mock database response
        mock_db_connection.execute_read.return_value = [{
            'p': sample_patient.model_dump(),
            'admissions': [sample_admission.model_dump()]
        }]
        
        # Call function with table format
        result = await get_patient(
            mock_db_connection,
            subject_id="10000032",
            include_admissions=True,
            format=OUTPUT_FORMAT_TABLE
        )
        
        # Assertions
        assert isinstance(result, str)
        assert "PATIENT INFORMATION" in result
        assert "Subject ID" in result
        assert "10000032" in result
        assert "ADMISSIONS" in result
        assert "22595853" in result
    
    @pytest.mark.asyncio
    async def test_empty_collections_handling(self, mock_db_connection, sample_patient):
        """Test handling of empty collections in response."""
        # Mock response with empty collections
        mock_db_connection.execute_read.return_value = [{
            'p': sample_patient.model_dump(),
            'admissions': [],
            'diagnoses': None,  # Test None handling
            'medications': []
        }]
        
        # Call function
        result = await get_patient(
            mock_db_connection,
            subject_id="10000032",
            include_admissions=True,
            include_diagnoses=True,
            include_medications=True,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Assertions
        assert data['admissions'] == []
        assert 'diagnoses' not in data or data['diagnoses'] == []
        assert data['medications'] == []


@pytest.mark.integration
class TestPatientIntegration:
    """Integration tests with real Neo4j database."""
    
    @pytest.mark.asyncio
    async def test_get_real_patient(self, real_db_connection):
        """Test getting a real patient from the database."""
        # Use a patient ID that exists in your test database
        result = await get_patient(
            real_db_connection,
            subject_id="10461137",  # Using actual patient ID from database
            include_admissions=True,
            include_diagnoses=True,
            format=OUTPUT_FORMAT_JSON
        )
        
        # Parse result
        data = json.loads(result)
        
        # Basic assertions
        assert 'patient' in data
        assert data['patient']['subject_id'] == "10461137"
        
        # If patient has admissions, verify structure
        if 'admissions' in data and data['admissions']:
            admission = data['admissions'][0]
            assert 'hadm_id' in admission
            assert 'admission_type' in admission
</file>

<file path="src/mcp_server_neo4j_ehr/tests/conftest.py">
"""Shared test fixtures and configuration."""

import os
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock
from dotenv import load_dotenv

from ..modules.db_connection import Neo4jConnection, create_neo4j_driver
from ..modules.data_types import (
    Patient, Admission, Diagnosis, Procedure, 
    Medication, LabEvent, DischargeNote, RadiologyReport
)

# Load environment variables
load_dotenv()


@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture
def mock_db_connection():
    """Create a mock database connection for unit tests."""
    mock_connection = AsyncMock(spec=Neo4jConnection)
    return mock_connection


@pytest.fixture
async def real_db_connection():
    """Create a real database connection for integration tests."""
    # Use test database credentials from environment
    uri = os.getenv("NEO4J_TEST_URI", os.getenv("NEO4J_URI"))
    username = os.getenv("NEO4J_TEST_USERNAME", os.getenv("NEO4J_USERNAME"))
    password = os.getenv("NEO4J_TEST_PASSWORD", os.getenv("NEO4J_PASSWORD"))
    database = os.getenv("NEO4J_TEST_DATABASE", os.getenv("NEO4J_DATABASE"))
    
    if not all([uri, username, password]):
        pytest.skip("Neo4j credentials not configured for integration tests")
    
    driver = create_neo4j_driver(uri, username, password)
    connection = Neo4jConnection(driver, database)
    
    # Test the connection
    if not await connection.test_connection():
        pytest.skip("Cannot connect to Neo4j database")
    
    yield connection
    await driver.close()


@pytest.fixture
def sample_patient():
    """Sample patient data for testing."""
    return Patient(
        subject_id="10000032",
        gender="M",
        anchor_age=52,
        anchor_year=2126,
        anchor_year_group="2020 - 2025"
    )


@pytest.fixture
def sample_admission():
    """Sample admission data for testing."""
    from datetime import datetime
    return Admission(
        hadm_id="22595853",
        admission_type="URGENT",
        admittime=datetime.fromisoformat("2124-08-07T15:45:00"),
        dischtime=datetime.fromisoformat("2124-08-10T16:00:00"),
        admission_location="EMERGENCY ROOM",
        discharge_location="HOME",
        insurance="Medicare",
        language="ENGLISH",
        marital_status="MARRIED",
        race="WHITE"
    )


@pytest.fixture
def sample_diagnosis():
    """Sample diagnosis data for testing."""
    return Diagnosis(
        icd_code="I50.9",
        long_title="Heart failure, unspecified",
        hadm_id="22595853",
        subject_id="10000032",
        seq_num=1,
        icd_version=10
    )


@pytest.fixture
def sample_lab_event():
    """Sample lab event data for testing."""
    from datetime import datetime
    return LabEvent(
        lab_event_id="1234567",
        subject_id="10000032",
        hadm_id="22595853",
        charttime=datetime.fromisoformat("2124-08-08T06:00:00"),
        label="Sodium",
        itemid="50983",
        category="CHEMISTRY",
        flag="abnormal",
        value="130",
        ref_range_lower=136.0,
        ref_range_upper=145.0
    )


@pytest.fixture
def sample_medication():
    """Sample medication data for testing."""
    return Medication(
        medication="Furosemide",
        route="PO",
        hadm_id="22595853",
        subject_id="10000032",
        frequency="BID"
    )


@pytest.fixture
def sample_procedure():
    """Sample procedure data for testing."""
    from datetime import datetime
    return Procedure(
        icd_code="99.04",
        long_title="Transfusion of packed cells",
        hadm_id="22595853",
        seq_num=1,
        chartdate=datetime.fromisoformat("2124-08-08"),
        icd_version=9
    )


@pytest.fixture
def sample_discharge_note():
    """Sample discharge note for testing."""
    from datetime import datetime
    return DischargeNote(
        note_id="note_001",
        hadm_id="22595853",
        subject_id="10000032",
        note_type="Discharge summary",
        text="Patient admitted with acute heart failure exacerbation. Treated with IV diuretics.",
        charttime=datetime.fromisoformat("2124-08-10T14:00:00")
    )


@pytest.fixture
def mock_openai_response():
    """Mock OpenAI API response for testing."""
    mock = MagicMock()
    # Mock the client itself to avoid initialization issues
    mock.embeddings = MagicMock()
    mock.embeddings.create = MagicMock(return_value=MagicMock(
        data=[MagicMock(embedding=[0.1] * 1536)]
    ))
    mock.chat = MagicMock()
    mock.chat.completions = MagicMock()
    mock.chat.completions.create = MagicMock(return_value=MagicMock(
        choices=[MagicMock(message=MagicMock(content='{"tool": "test_tool", "arguments": {}}'))]
    ))
    return mock
</file>

<file path="src/mcp_server_neo4j_ehr/tests/README.md">
# Neo4j EHR MCP Server Tests

This directory contains the test suite for the Neo4j EHR MCP Server. The tests are organized to validate both individual functionality modules and the overall server integration.

## Test Structure

```
tests/
├── README.md                    # This file
├── conftest.py                 # Shared test fixtures and configuration
└── functionality/              # Tests for individual functionality modules
    ├── test_get_schema.py      # Schema retrieval tests
    ├── test_list_diagnoses.py  # Diagnosis listing tests
    ├── test_list_lab_events.py # Lab event listing tests
    ├── test_list_medications.py # Medication listing tests
    ├── test_list_procedures.py  # Procedure listing tests
    ├── test_natural_query.py    # Natural language query tests
    ├── test_patient.py         # Patient information retrieval tests
    └── test_search_notes.py    # Clinical note search tests
```

## Test Categories

### 1. Unit Tests
- Mock all external dependencies (Neo4j, OpenAI)
- Test business logic and data transformations
- Fast execution, no network calls
- Run frequently during development

### 2. Integration Tests
- Use real Neo4j database connection
- Use real OpenAI API (for natural language tests)
- Marked with `@pytest.mark.integration`
- Require environment variables to be set

## Running Tests

### Run All Tests
```bash
# Using uv (recommended)
uv run pytest

# Using standard pytest
pytest
```

### Run Only Unit Tests
```bash
# Skip integration tests that require database/API connections
uv run pytest -k "not integration"
```

### Run Only Integration Tests
```bash
# Requires Neo4j database and OpenAI API key
uv run pytest -k "integration"
```

### Run Specific Test Files
```bash
# Test a specific module
uv run pytest src/mcp_server_neo4j_ehr/tests/functionality/test_patient.py

# Test a specific test class
uv run pytest src/mcp_server_neo4j_ehr/tests/functionality/test_patient.py::TestPatientFunctionality

# Test a specific test method
uv run pytest src/mcp_server_neo4j_ehr/tests/functionality/test_patient.py::TestPatientFunctionality::test_get_patient_basic
```

### Run Tests with Output
```bash
# Show print statements and logs
uv run pytest -v -s

# Show only INFO level logs and above
uv run pytest -v -s --log-cli-level=INFO

# Show all debug logs
uv run pytest -v -s --log-cli-level=DEBUG
```

### Run Tests with Coverage
```bash
# Install coverage tool
uv pip install pytest-cov

# Run with coverage report
uv run pytest --cov=src/mcp_server_neo4j_ehr

# Generate HTML coverage report
uv run pytest --cov=src/mcp_server_neo4j_ehr --cov-report=html
```

## Environment Setup

### For Unit Tests
No special setup required - all dependencies are mocked.

### For Integration Tests
Create a `.env` file in the project root with:

```env
# Neo4j connection
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=neo4j

# OpenAI API (for natural language query tests)
OPENAI_API_KEY=sk-...
```

## Test Fixtures (conftest.py)

Common fixtures available to all tests:

- `mock_db_connection`: Mock Neo4j connection for unit tests
- `real_db_connection`: Real Neo4j connection for integration tests (skips if not configured)
- `sample_patient`: Sample patient data
- `sample_admission`: Sample admission data
- `sample_diagnosis`: Sample diagnosis data
- `sample_lab_event`: Sample lab event data
- `sample_medication`: Sample medication data
- `sample_procedure`: Sample procedure data
- `sample_discharge_note`: Sample discharge note
- `mock_openai_response`: Mock OpenAI API responses

## What Each Test Module Covers

### test_patient.py
- Retrieving patient information with various include options
- Handling missing patients
- Output formatting (JSON, table)
- Integration with real patient data

### test_search_notes.py
- Text-based search in clinical notes
- Semantic search using embeddings
- Filtering by note type and patient/admission
- Different output formats

### test_list_*.py modules
- Listing clinical data (diagnoses, lab events, medications, procedures)
- Filtering by patient, admission, and other criteria
- Pagination and limiting results
- Table formatting

### test_natural_query.py
- Converting natural language to Cypher queries
- OpenAI integration
- Error handling for invalid queries
- Different output formats

### test_get_schema.py
- Retrieving database schema information
- Formatting schema as JSON or Markdown
- Handling empty collections

## Debugging Test Failures

### View Natural Language Query Outputs
```bash
# See what Cypher queries are generated
uv run pytest "src/mcp_server_neo4j_ehr/tests/functionality/test_natural_query.py::TestNaturalQueryIntegration" -v -s --log-cli-level=INFO
```

### Use the Debug Script
```bash
# Interactive query testing
uv run python debug_natural_query.py

# Test specific query
uv run python debug_natural_query.py "How many patients are in the database?"
```

### Common Issues

1. **DateTime Serialization Errors**
   - Neo4j returns DateTime objects that need conversion
   - Fixed by converting to Python datetime before Pydantic serialization

2. **Patient Not Found in Integration Tests**
   - Integration tests use patient ID "10461137"
   - Ensure this patient exists in your test database

3. **OpenAI API Key Issues**
   - Set `OPENAI_API_KEY` environment variable
   - Check API key validity and rate limits

4. **Neo4j Connection Failures**
   - Verify Neo4j credentials in `.env`
   - Check network connectivity to Neo4j instance
   - Ensure database exists and is accessible

## Writing New Tests

### Unit Test Template
```python
@pytest.mark.asyncio
async def test_new_functionality(mock_db_connection):
    """Test description."""
    # Arrange
    mock_db_connection.execute_read.return_value = [{"result": "data"}]
    
    # Act
    result = await your_function(mock_db_connection, param="value")
    
    # Assert
    assert "expected" in result
```

### Integration Test Template
```python
@pytest.mark.asyncio
@pytest.mark.integration
async def test_real_functionality(real_db_connection):
    """Test with real database."""
    # Will skip if database not configured
    result = await your_function(real_db_connection, param="value")
    assert result is not None
```

## Best Practices

1. **Keep tests focused** - Each test should verify one specific behavior
2. **Use descriptive names** - Test names should clearly indicate what they test
3. **Mock external dependencies** - Unit tests should not require database or API access
4. **Test edge cases** - Include tests for error conditions and empty results
5. **Maintain test data** - Keep sample data in fixtures up-to-date with schema changes

## Continuous Integration

Tests are designed to run in CI/CD pipelines:
- Unit tests run on every commit (no external dependencies)
- Integration tests run on deployment branches (require secrets)
- Coverage reports help maintain code quality
</file>

<file path="tests/README.md">
# Server Tests

This directory contains high-level tests for the MCP server creation and tool registration.

## Test Files

- `test_server.py` - Tests the FastMCP server initialization and tool registration

## Running These Tests

```bash
# Run server tests
uv run pytest tests/

# Run with verbose output
uv run pytest tests/ -v
```

## What's Tested

1. **Server Creation** - Verifies the MCP server can be created with proper configuration
2. **Tool Registration** - Ensures all 8 EHR tools are properly registered:
   - `ehr_patient` - Patient information retrieval
   - `ehr_search_notes` - Clinical note search
   - `ehr_list_diagnoses` - Diagnosis listing
   - `ehr_list_lab_events` - Lab event listing
   - `ehr_list_medications` - Medication listing
   - `ehr_list_procedures` - Procedure listing
   - `ehr_natural_query` - Natural language queries
   - `ehr_get_schema` - Schema information

## Note

For detailed functionality tests, see `src/mcp_server_neo4j_ehr/tests/README.md`
</file>

<file path="tests/test_server.py">
"""Basic tests for the Neo4j EHR MCP Server."""

import pytest
import os
from unittest.mock import AsyncMock, MagicMock
from src.mcp_server_neo4j_ehr.server import create_mcp_server
from src.mcp_server_neo4j_ehr.modules.db_connection import Neo4jConnection


@pytest.fixture
def mock_neo4j_driver():
    """Create a mock Neo4j driver."""
    driver = AsyncMock()
    return driver


@pytest.fixture
def mock_db_connection(mock_neo4j_driver):
    """Create a mock database connection."""
    return Neo4jConnection(mock_neo4j_driver)


def test_create_mcp_server(mock_neo4j_driver):
    """Test that MCP server can be created."""
    server = create_mcp_server(mock_neo4j_driver, "neo4j", "test-api-key")
    assert server is not None
    assert server.name == "mcp-server-neo4j-ehr"


@pytest.mark.asyncio
async def test_patient_tool_exists(mock_neo4j_driver):
    """Test that patient tool exists in the server."""
    server = create_mcp_server(mock_neo4j_driver)
    # Check if the tool decorator created the tool
    # FastMCP tool registration happens via decorators
    tools = await server.get_tools()
    assert "ehr_patient" in tools


@pytest.mark.asyncio
async def test_all_tools_exist(mock_neo4j_driver):
    """Test that all expected tools exist."""
    server = create_mcp_server(mock_neo4j_driver)
    
    expected_tools = [
        "ehr_patient",
        "ehr_search_notes",
        "ehr_list_diagnoses",
        "ehr_list_lab_events",
        "ehr_list_medications",
        "ehr_list_procedures",
        "ehr_natural_query",
        "ehr_get_schema"
    ]
    
    # Check if tools are registered via get_tools
    tools = await server.get_tools()
    
    for expected in expected_tools:
        assert expected in tools, f"Tool {expected} not found"
</file>

<file path=".env.example">
# Neo4j connection settings
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=neo4j

# OpenAI API key for semantic search and natural language queries
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Optional: Test database settings (for integration tests)
# NEO4J_TEST_URI=neo4j+s://test-instance.databases.neo4j.io
# NEO4J_TEST_USERNAME=neo4j
# NEO4J_TEST_PASSWORD=test-password
# NEO4J_TEST_DATABASE=neo4j
</file>

<file path=".gitignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Testing
.pytest_cache/
.coverage
htmlcov/
.tox/
.nox/

# OS
.DS_Store
Thumbs.db

# Project specific
*.log
.env
.env.local
.env.*.local
</file>

<file path="AGENTIC_SEARCH_ARCHITECTURE.md">
# Agentic Search Architecture: Replacing Vector Search with Intelligence

## Table of Contents
1. [Overview](#overview)
2. [Big O Complexity: Vector vs Agentic Search](#big-o-complexity-vector-vs-agentic-search)
3. [Query Caching Implementation](#query-caching-implementation)
4. [Complete Implementation Plan](#complete-implementation-plan)
5. [Architecture Comparison](#architecture-comparison)
6. [Scalability Analysis](#scalability-analysis)
7. [Future Improvements](#future-improvements)

## Overview

This document outlines the transition from vector-based semantic search to an agentic search architecture that leverages LLM intelligence for query generation rather than embedding similarity.

### Key Insight
With intelligent agents like Claude Desktop orchestrating queries, and GPT-4 generating precise Cypher queries, we can achieve better results than vector similarity search while reducing complexity and improving scalability.

## Big O Complexity: Vector vs Agentic Search

### Vector Search: O(n) - Why It's Linear

Vector search must compare your query embedding against **every document** in the database:

```
Query: "Find notes about respiratory failure"
         ↓
    [0.23, -0.81, 0.45, ...] (1536 dimensions)
         ↓
Compare with EVERY note:
  Note 1: distance = 0.82
  Note 2: distance = 0.91  
  Note 3: distance = 0.23  ← Best match
  ...
  Note 10,000: distance = 0.95
```

**Why O(n)?**
- Must check all n documents
- Even with optimizations (like HNSW), approximate O(n) for high recall
- As you add patients: 100 → 1,000 → 10,000 patients, search time grows linearly

### Agentic Search: O(log n) - Why It's Logarithmic

Agentic search uses database indexes to find data directly:

```
Query: "Find notes about respiratory failure for patient 123"
         ↓
    GPT-4 generates: 
    MATCH (p:Patient {subject_id: '123'})-[:HAS_ADMISSION]->(a)
          -[:INCLUDES_DISCHARGE_NOTE]->(n)
    WHERE n.text CONTAINS 'respiratory failure'
         ↓
    Neo4j uses indexes:
    1. Binary search patient index: O(log n)
    2. Follow relationships: O(1) per relationship
    3. Filter on indexed property: O(log m) where m << n
```

**Why O(log n)?**
- Database indexes use B-trees or similar structures
- Finding patient 123 among 10,000 patients takes ~14 comparisons, not 10,000
- Relationships in graphs are direct pointers (O(1) traversal)

### Real-World Example

For 10,000 patients with 10 notes each (100,000 total notes):

| Operation | Vector Search | Agentic Search |
|-----------|--------------|----------------|
| Find all notes mentioning "cardiac arrest" | Check all 100,000 notes | Use text index: ~17 operations |
| Find patient 5000's notes about "diabetes" | Check all 100,000 notes | Find patient (14 ops) + scan their 10 notes |
| Complex: "Patients who developed sepsis after cardiac surgery" | Can't do this directly! | Join operations with indexes: ~50 ops total |

## Query Caching Implementation

### How Caching Would Work

```python
from functools import lru_cache
from typing import Dict, Tuple
import hashlib
import json
import time

class QueryCache:
    def __init__(self, ttl_seconds: int = 3600):
        self.cache: Dict[str, Tuple[str, float, str]] = {}
        self.ttl = ttl_seconds
    
    def _generate_key(self, query: str, limit: int) -> str:
        """Generate cache key from query parameters."""
        # Normalize query: lowercase, strip whitespace
        normalized = query.lower().strip()
        # Include limit in key
        cache_input = f"{normalized}::limit={limit}"
        # Create hash for consistent key length
        return hashlib.md5(cache_input.encode()).hexdigest()
    
    def get(self, query: str, limit: int) -> Optional[str]:
        """Get cached Cypher query if valid."""
        key = self._generate_key(query, limit)
        
        if key in self.cache:
            cypher, timestamp, original_query = self.cache[key]
            # Check if cache is still valid
            if time.time() - timestamp < self.ttl:
                return cypher
            else:
                # Expired, remove from cache
                del self.cache[key]
        
        return None
    
    def set(self, query: str, limit: int, cypher: str):
        """Cache the generated Cypher query."""
        key = self._generate_key(query, limit)
        self.cache[key] = (cypher, time.time(), query)

# Integration with natural_query function
class CachedNaturalQuery:
    def __init__(self):
        self.cache = QueryCache(ttl_seconds=3600)  # 1 hour cache
        self.stats = {"hits": 0, "misses": 0}
    
    async def query(self, db, query: str, limit: int, openai_key: str) -> str:
        # Check cache first
        cached_cypher = self.cache.get(query, limit)
        
        if cached_cypher:
            self.stats["hits"] += 1
            logger.info(f"Cache HIT for query: {query[:50]}...")
            # Execute cached Cypher directly
            results = await db.execute_read(cached_cypher)
        else:
            self.stats["misses"] += 1
            logger.info(f"Cache MISS for query: {query[:50]}...")
            # Generate new Cypher via GPT-4
            cypher = await self._generate_cypher(query, limit, openai_key)
            # Cache for next time
            self.cache.set(query, limit, cypher)
            # Execute
            results = await db.execute_read(cypher)
        
        return self._format_results(results)
```

### Cache Key Strategy

1. **Normalize queries** to increase cache hits:
   ```python
   "What medications did patient 123 take?" 
   "what medications did patient 123 take"
   "What medications did patient 123 take???"
   → All map to same cache key
   ```

2. **Include parameters** that affect the query:
   - Limit value
   - Time ranges (if added)
   - Output format

3. **Don't cache** queries with:
   - Current date/time references ("patients admitted today")
   - User-specific context
   - Queries that modify data

### TTL Considerations

| Data Type | Suggested TTL | Reasoning |
|-----------|--------------|-----------|
| Patient demographics | 24 hours | Rarely changes |
| Clinical notes | 1 hour | New notes added during admissions |
| Lab results | 30 minutes | Can change frequently for active patients |
| Aggregations/counts | 5 minutes | Most volatile |

## Complete Implementation Plan

### Phase 1: Remove Vector Search (Week 1)

```python
# 1. Remove from data_types.py
class DischargeNote(BaseNodeModel):
    note_id: str
    hadm_id: Optional[str] = None
    subject_id: Optional[str] = None
    note_type: str
    text: str
    note_seq: Optional[int] = None
    charttime: Optional[datetime] = None
    storetime: Optional[datetime] = None
    # REMOVE THESE:
    # embedding: Optional[List[float]] = None
    # embedding_model: Optional[str] = None
    # embedding_created: Optional[datetime] = None

# 2. Remove from constants.py
# DELETE: EMBEDDING_MODEL = "text-embedding-3-small"
# DELETE: EMBEDDING_DIMENSION = 1536
# DELETE: NOTE_EMBEDDINGS_INDEX = "note_embeddings"

# 3. Update database schema
async def cleanup_vectors(db):
    """Remove vector indexes and properties."""
    await db.execute_write("""
        DROP INDEX note_embeddings IF EXISTS
    """)
    
    await db.execute_write("""
        MATCH (n:DischargeNote)
        REMOVE n.embedding, n.embedding_model, n.embedding_created
    """)
```

### Phase 2: Optimize Natural Query (Week 1-2)

```python
# Enhanced natural_query.py
NATURAL_QUERY_SYSTEM_PROMPT = """
You are a Cypher query generator for a Neo4j medical database.

PERFORMANCE RULES:
1. ALWAYS use indexed properties in WHERE clauses
2. ALWAYS include LIMIT to prevent large results
3. For existence checks, use EXISTS() or LIMIT 1
4. For counts, use COUNT(*) not COLLECT()
5. Filter by patient_id or admission_id FIRST

QUERY PATTERNS FOR SCALE:
- Patient lookup: MATCH (p:Patient {subject_id: $id}) - O(log n)
- Recent notes: ORDER BY n.charttime DESC LIMIT 10 - O(n log n) but limited
- Text search: WHERE n.text CONTAINS 'term' - O(n) but on filtered set
- Relationships: Use specific paths, not variable-length

EXAMPLE EFFICIENT QUERIES:
// Get recent labs for patient
MATCH (l:LabEvent {subject_id: '123'})
WHERE l.charttime > datetime() - duration('P7D')
ORDER BY l.charttime DESC
LIMIT 20

// Count patients with condition
MATCH (d:Diagnosis)
WHERE d.long_title CONTAINS 'heart failure'
RETURN COUNT(DISTINCT d.subject_id) as patient_count
"""
```

### Phase 3: Add Performance Features (Week 2)

```python
# 1. Query Analysis Tool
@mcp.tool
async def ehr_analyze_query(
    query: str,
    format: OutputFormat = OUTPUT_FORMAT_MARKDOWN
) -> str:
    """Analyze what Cypher would be generated without executing.
    Useful for debugging and learning."""
    
    # Generate Cypher
    cypher = await generate_cypher_only(query)
    
    # Analyze complexity
    analysis = analyze_query_complexity(cypher)
    
    return format_analysis(cypher, analysis, format)

# 2. Batch Operations
@mcp.tool
async def ehr_batch_get_notes(
    patient_ids: List[str],
    note_type: NoteType = "all",
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """Efficiently retrieve notes for multiple patients."""
    
    # Use UNWIND for efficient batch processing
    cypher = """
    UNWIND $patient_ids AS pid
    MATCH (p:Patient {subject_id: pid})-[:HAS_ADMISSION]->(a)
    OPTIONAL MATCH (a)-[:INCLUDES_DISCHARGE_NOTE]->(d)
    OPTIONAL MATCH (a)-[:INCLUDES_RADIOLOGY_REPORT]->(r)
    WITH p, COLLECT(DISTINCT d) as discharge_notes, 
         COLLECT(DISTINCT r) as radiology_reports
    RETURN p.subject_id as patient_id, 
           discharge_notes, 
           radiology_reports
    """
    
    results = await db.execute_read(cypher, {"patient_ids": patient_ids})
    return format_results(results, format)

# 3. Query Performance Monitor
class QueryPerformanceMonitor:
    def __init__(self):
        self.query_times = []
    
    async def monitor(self, func, *args, **kwargs):
        start = time.time()
        try:
            result = await func(*args, **kwargs)
            duration = time.time() - start
            self.query_times.append({
                "timestamp": start,
                "duration": duration,
                "success": True
            })
            if duration > 5.0:
                logger.warning(f"Slow query detected: {duration:.2f}s")
            return result
        except Exception as e:
            duration = time.time() - start
            self.query_times.append({
                "timestamp": start,
                "duration": duration,
                "success": False,
                "error": str(e)
            })
            raise
```

## Architecture Comparison

### Vector Search Architecture
```
User Query → Embedding API → Vector DB → Similarity Search → Results
    ↓            $0.0001         ↑              O(n)
    └──────────────────────────→ Neo4j → Post-filter → Results
```

**Pros:**
- Good for "find similar" use cases
- No query generation needed
- Works with unstructured data

**Cons:**
- Can't do complex relationships
- Requires embedding maintenance
- Additional API costs
- O(n) complexity
- Storage overhead (1536 floats per document)

### Agentic Search Architecture
```
User Query → GPT-4 → Cypher Query → Neo4j → Results
    ↓         $0.01      O(1)        O(log n)
    └────────────────────────────────┘
         Cached for repeated queries
```

**Pros:**
- Complex relationship queries
- Precise, not just similar
- O(log n) with indexes
- No storage overhead
- Temporal reasoning

**Cons:**
- Requires structured data
- GPT-4 API costs (but cacheable)
- Potential for bad query generation

## Scalability Analysis

### At Different Scales

| Scale | Patients | Notes | Vector Search Time | Agentic Search Time |
|-------|----------|-------|-------------------|-------------------|
| Small | 100 | 1,000 | 50ms | 20ms |
| Medium | 1,000 | 10,000 | 500ms | 25ms |
| Large | 10,000 | 100,000 | 5,000ms | 30ms |
| Huge | 100,000 | 1,000,000 | 50,000ms | 35ms |

### Why Agentic Scales Better

1. **Index Usage**
   ```cypher
   // This uses patient index - O(log n)
   MATCH (p:Patient {subject_id: '12345'})
   
   // Then follows relationships - O(1) per relationship
   MATCH (p)-[:HAS_ADMISSION]->(a)
   ```

2. **Filtered Searches**
   ```cypher
   // Only searches notes for ONE patient, not all
   MATCH (p:Patient {subject_id: '123'})-[:HAS_ADMISSION]->(a)
         -[:INCLUDES_DISCHARGE_NOTE]->(n)
   WHERE n.text CONTAINS 'sepsis'
   ```

3. **Aggregations Without Full Scans**
   ```cypher
   // Uses diagnosis index, not full scan
   MATCH (d:Diagnosis {icd_code: 'I50'})
   RETURN COUNT(DISTINCT d.subject_id)
   ```

## Future Improvements

### 1. Query Pattern Learning
```python
class QueryPatternLearner:
    """Learn common query patterns to pre-optimize."""
    
    def __init__(self):
        self.patterns = defaultdict(int)
    
    def record_query(self, natural_language: str, cypher: str):
        # Extract pattern
        pattern = self.extract_pattern(natural_language)
        self.patterns[pattern] += 1
        
        # After 10 occurrences, create optimized template
        if self.patterns[pattern] == 10:
            self.create_template(pattern, cypher)
```

### 2. Intelligent Caching
```python
class IntelligentCache:
    """Cache that understands medical data patterns."""
    
    def should_cache(self, query: str) -> bool:
        # Don't cache time-sensitive queries
        if any(term in query.lower() for term in ['today', 'now', 'current']):
            return False
        
        # Always cache expensive aggregations
        if 'count' in query.lower() or 'average' in query.lower():
            return True
        
        # Cache patient-specific queries with longer TTL
        if re.search(r'patient \d+', query):
            return True
```

### 3. Query Optimization Hints
```python
async def optimize_natural_query(query: str) -> str:
    """Suggest query optimizations to user."""
    
    if "all patients" in query.lower():
        return (
            "Tip: This query might be slow. Consider:\n"
            "- Adding a time range (e.g., 'in the last year')\n"
            "- Filtering by condition first\n"
            "- Using a sample (e.g., 'show me 10 examples')"
        )
```

### 4. Monitoring Dashboard
```python
class MCPMonitoringDashboard:
    """Track MCP server performance."""
    
    async def get_metrics(self) -> dict:
        return {
            "cache_hit_rate": self.cache.get_hit_rate(),
            "avg_query_time": self.monitor.get_average_time(),
            "slow_queries": self.monitor.get_slow_queries(),
            "popular_queries": self.cache.get_popular_queries(),
            "error_rate": self.monitor.get_error_rate()
        }
```

### 5. Federated Queries
```python
@mcp.tool
async def ehr_federated_query(
    query: str,
    databases: List[str] = ["main"],
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """Query across multiple Neo4j databases."""
    
    # Generate Cypher for each database
    results = []
    for db_name in databases:
        db_results = await query_database(db_name, query)
        results.extend(db_results)
    
    return format_federated_results(results, format)
```

## Conclusion

The shift from vector search to agentic search represents a fundamental change in how we approach medical data retrieval:

- **From similarity to intelligence**: We're not finding "similar" notes, we're answering specific questions
- **From O(n) to O(log n)**: Scalability improves dramatically with proper indexing
- **From embeddings to relationships**: Leveraging the graph structure gives us more precise results

This architecture is not just more scalable—it's more aligned with how medical professionals actually query data: with specific questions about specific patients, not vague similarity searches.
</file>

<file path="CONTRIBUTING.md">
# Contributing to Neo4j EHR MCP Server

Thank you for your interest in contributing to the Neo4j EHR MCP Server! This document provides guidelines for contributing to the project.

## Getting Started

1. Fork the repository
2. Clone your fork:
   ```bash
   git clone https://github.com/your-username/neo4j-mcp.git
   cd neo4j-mcp
   ```
3. Install dependencies:
   ```bash
   uv pip install -e .
   ```
4. Set up your environment:
   ```bash
   cp .env.example .env
   # Edit .env with your credentials
   ```

## Development Process

### 1. Create a Feature Branch

```bash
git checkout -b feature/your-feature-name
```

### 2. Make Your Changes

- Follow the existing code style
- Add tests for new functionality
- Update documentation as needed

### 3. Run Tests

Before submitting, ensure all tests pass:

```bash
# Run unit tests
uv run pytest -k "not integration"

# Run all tests (requires database)
uv run pytest

# Check code coverage
uv run pytest --cov=src/mcp_server_neo4j_ehr
```

### 4. Test Your Changes

For natural language query changes:
```bash
uv run python debug_natural_query.py
```

### 5. Submit a Pull Request

- Write a clear description of your changes
- Reference any related issues
- Ensure CI tests pass

## Code Style Guidelines

### Python Code

- Follow PEP 8
- Use type hints where appropriate
- Keep functions focused and small
- Document complex logic with comments

### Imports

```python
# Standard library
import json
from typing import Optional, List

# Third-party
from pydantic import BaseModel
import neo4j

# Local
from ..modules.constants import *
from ..modules.data_types import Patient
```

### Error Handling

```python
try:
    results = await db.execute_read(query)
except Exception as e:
    logger.error(f"Query failed: {e}")
    return json.dumps({"error": "Query failed", "details": str(e)})
```

## Testing Guidelines

### Writing Tests

1. **Unit Tests**: Mock external dependencies
   ```python
   @pytest.mark.asyncio
   async def test_feature(mock_db_connection):
       mock_db_connection.execute_read.return_value = [{"data": "test"}]
       result = await your_function(mock_db_connection)
       assert "expected" in result
   ```

2. **Integration Tests**: Use real connections
   ```python
   @pytest.mark.asyncio
   @pytest.mark.integration
   async def test_real_feature(real_db_connection):
       result = await your_function(real_db_connection)
       assert result is not None
   ```

### Test Data

- Use fixtures from `conftest.py`
- Create minimal test data
- Clean up after tests

## Documentation

### Code Documentation

- Add docstrings to all public functions
- Include parameter descriptions
- Document return values

Example:
```python
async def get_patient(
    db: Neo4jConnection,
    subject_id: str,
    include_admissions: bool = True
) -> str:
    """Get comprehensive patient information.
    
    Args:
        db: Database connection
        subject_id: Patient identifier
        include_admissions: Whether to include admission data
        
    Returns:
        JSON string with patient data
    """
```

### Update Documentation

When adding features, update:
- README.md - for user-facing changes
- CHANGELOG.md - for all changes
- Test documentation - for new test cases

## Commit Messages

Follow conventional commits:
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation changes
- `test:` Test additions/changes
- `refactor:` Code refactoring
- `chore:` Maintenance tasks

Examples:
```
feat: add patient medication history endpoint
fix: handle Neo4j DateTime serialization
docs: update natural language query examples
test: add integration tests for lab events
```

## Questions?

- Open an issue for bugs or feature requests
- Start a discussion for questions
- Check existing issues before creating new ones

## License

By contributing, you agree that your contributions will be licensed under the MIT License.
</file>

<file path="debug_natural_query.py">
#!/usr/bin/env python3
"""
Debug script for testing natural language queries with the Neo4j EHR MCP Server.
This script shows all the outputs from the LLM and query execution.
"""

import asyncio
import json
import logging
import os
import sys
from dotenv import load_dotenv

from src.mcp_server_neo4j_ehr.modules.db_connection import create_neo4j_driver, Neo4jConnection
from src.mcp_server_neo4j_ehr.modules.functionality.natural_query import natural_query
from src.mcp_server_neo4j_ehr.modules.constants import OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_MARKDOWN

# Configure logging to show all output
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Also log debug messages from our module
logging.getLogger('src.mcp_server_neo4j_ehr').setLevel(logging.DEBUG)


async def test_query(query_text: str):
    """Test a natural language query and show all outputs."""
    
    load_dotenv()
    
    # Check for required environment variables
    neo4j_uri = os.getenv("NEO4J_URI")
    neo4j_username = os.getenv("NEO4J_USERNAME")
    neo4j_password = os.getenv("NEO4J_PASSWORD")
    neo4j_database = os.getenv("NEO4J_DATABASE", "neo4j")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
    if not all([neo4j_uri, neo4j_username, neo4j_password, openai_api_key]):
        print("Error: Required environment variables not set.")
        print("Please ensure NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, and OPENAI_API_KEY are set.")
        return
    
    # Create database connection
    driver = create_neo4j_driver(neo4j_uri, neo4j_username, neo4j_password)
    db = Neo4jConnection(driver, neo4j_database)
    
    try:
        print(f"\nTesting connection to Neo4j...")
        if await db.test_connection():
            print("✓ Connected to Neo4j successfully!")
        else:
            print("✗ Failed to connect to Neo4j")
            return
        
        print(f"\nProcessing query: '{query_text}'")
        print("-" * 80)
        
        # Execute the natural language query
        result = await natural_query(
            db,
            query=query_text,
            limit=10,
            format=OUTPUT_FORMAT_JSON,
            openai_api_key=openai_api_key
        )
        
        # Parse and display results
        data = json.loads(result)
        
        print("\n" + "="*80)
        print("QUERY RESULTS")
        print("="*80)
        
        if "error" in data:
            print(f"ERROR: {data['error']}")
            if "details" in data:
                print(f"Details: {data['details']}")
            if "query" in data:
                print(f"Failed Query: {data['query']}")
        else:
            print(f"Question: {data.get('question', 'N/A')}")
            print(f"\nGenerated Cypher Query:")
            print(f"  {data.get('cypher_query', 'N/A')}")
            print(f"\nResult Count: {data.get('count', 0)}")
            print(f"\nResults:")
            results = data.get('results', [])
            if results:
                for i, result in enumerate(results[:5]):  # Show first 5 results
                    print(f"  [{i+1}] {json.dumps(result, indent=4)}")
                if len(results) > 5:
                    print(f"  ... and {len(results) - 5} more results")
            else:
                print("  No results found")
        
        print("="*80 + "\n")
        
    except Exception as e:
        print(f"\nError: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await driver.close()


def main():
    """Main entry point for the debug script."""
    
    # Check if query was provided as command line argument
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
        asyncio.run(test_query(query))
    else:
        # Interactive mode
        print("Neo4j EHR Natural Language Query Debugger")
        print("=========================================")
        print("Enter natural language queries to test, or 'quit' to exit.")
        print()
        
        while True:
            try:
                query = input("Query> ").strip()
                if query.lower() in ['quit', 'exit', 'q']:
                    break
                if query:
                    asyncio.run(test_query(query))
            except KeyboardInterrupt:
                print("\nExiting...")
                break
            except Exception as e:
                print(f"Error: {e}")


if __name__ == "__main__":
    main()
</file>

<file path="mcp_app.md">
# Healthcare MCP Application Implementation Guide

Building a Claude Desktop-like Healthcare AI Assistant using mcp-agent framework

## Table of Contents
1. [Overview & Architecture](#overview--architecture)
2. [Quick Start Implementation](#quick-start-implementation)
3. [Advanced Healthcare Agent System](#advanced-healthcare-agent-system)
4. [Integration with Neo4j MCP Server](#integration-with-neo4j-mcp-server)
5. [Clinical Safety & Compliance](#clinical-safety--compliance)
6. [User Interface Options](#user-interface-options)
7. [Deployment Guide](#deployment-guide)
8. [Next Steps & Roadmap](#next-steps--roadmap)

## Overview & Architecture

### How mcp-agent Replicates Claude Desktop

Claude Desktop's orchestration pattern:
```
User Query → Claude Desktop → Claude LLM + MCP Tools → Response
```

Your healthcare app with mcp-agent:
```
User Query → Your App → mcp-agent (AugmentedLLM + MCP Servers) → Response
```

### Architecture Diagram
```
┌─────────────────────────────────────────────────────────┐
│                Healthcare Web App                        │
├─────────────────┬──────────────────┬───────────────────┤
│   Streamlit UI  │   FastAPI REST   │   React Frontend  │
└────────┬────────┴────────┬─────────┴────────┬──────────┘
         │                 │                   │
         ▼                 ▼                   ▼
┌─────────────────────────────────────────────────────────┐
│                 mcp-agent Framework                      │
├─────────────────┬──────────────────┬───────────────────┤
│ HealthcareAgent │  ClinicalSafety  │  ParallelWorkflow │
│   - AugmentedLLM│     Wrapper      │   - Multi-agents  │
│   - Context Mgmt│  - Safety Rules  │   - Coordination  │
└────────┬────────┴──────────┬───────┴────────┬──────────┘
         │                   │                 │
         ▼                   ▼                 ▼
┌─────────────────────────────────────────────────────────┐
│                    MCP Servers                           │
├─────────────────┬──────────────────┬───────────────────┤
│  neo4j-ehr      │  clinical-rules  │  drug-interactions│
│  (Your server)  │   (Future)       │     (Future)      │
└─────────────────┴──────────────────┴───────────────────┘
```

## Quick Start Implementation

### 1. Installation & Dependencies

```bash
# Create project directory
mkdir healthcare-mcp-client
cd healthcare-mcp-client

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install mcp-agent anthropic streamlit python-dotenv
```

### 2. Basic Healthcare Agent

Create `healthcare_agent.py`:

```python
import asyncio
import os
from dotenv import load_dotenv
from mcp_agent import Agent, AugmentedLLM
from anthropic import Anthropic

load_dotenv()

class HealthcareAssistant:
    def __init__(self):
        # Initialize Anthropic client
        self.anthropic_client = Anthropic(
            api_key=os.getenv("ANTHROPIC_API_KEY")
        )
        
        # Create healthcare-aware LLM
        self.augmented_llm = AugmentedLLM(
            llm_client=self.anthropic_client,
            system_prompt=self.get_healthcare_system_prompt()
        )
        
        # Create agent with your Neo4j MCP server
        self.agent = Agent(
            llm=self.augmented_llm,
            mcp_servers={
                "neo4j_ehr": {
                    "command": "/Users/samuelthio/projects/neo4j-mcp/.venv/bin/mcp-server-neo4j-ehr",
                    "args": [],
                    "cwd": "/Users/samuelthio/projects/neo4j-mcp",
                    "env": {
                        "NEO4J_URI": os.getenv("NEO4J_URI"),
                        "NEO4J_USERNAME": os.getenv("NEO4J_USERNAME"),
                        "NEO4J_PASSWORD": os.getenv("NEO4J_PASSWORD"),
                        "NEO4J_DATABASE": os.getenv("NEO4J_DATABASE"),
                        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY")
                    }
                }
            }
        )
    
    def get_healthcare_system_prompt(self):
        return """You are a healthcare AI assistant with access to electronic health record data.

IMPORTANT GUIDELINES:
- Always prioritize patient safety and privacy
- Provide evidence-based information when possible
- Flag critical values or urgent findings immediately
- Explain medical terminology clearly
- Include relevant context from patient history
- Never provide definitive diagnoses - support clinical decision-making
- Always recommend consulting with healthcare providers for medical decisions

AVAILABLE TOOLS:
You have access to EHR tools that can:
- Retrieve patient records and clinical notes
- Search discharge summaries and radiology reports
- List diagnoses, medications, lab results, and procedures
- Answer complex medical queries using natural language

When using tools:
1. Start with patient context if provided
2. Use the most appropriate tool for the query
3. Interpret results in clinical context
4. Highlight any concerning findings
5. Suggest next steps when appropriate"""

    async def chat(self, message: str, patient_id: str = None) -> str:
        """Main chat interface"""
        # Add patient context if provided
        if patient_id:
            context_message = f"Current patient ID: {patient_id}\n\nQuery: {message}"
        else:
            context_message = message
        
        try:
            # Agent automatically handles tool discovery and execution
            response = await self.agent.run(context_message)
            return response.content
        except Exception as e:
            return f"I encountered an error: {str(e)}. Please try rephrasing your question."

# Example usage
async def main():
    assistant = HealthcareAssistant()
    
    # Test basic functionality
    response = await assistant.chat(
        "What are the recent lab results for patient 10461137?",
        patient_id="10461137"
    )
    print("Assistant:", response)

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. Environment Configuration

Create `.env` file:

```env
# Anthropic API Key
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Neo4j Configuration (same as your existing setup)
NEO4J_URI=neo4j+s://59e8b04a.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j

# OpenAI API Key (for your neo4j server's natural language features)
OPENAI_API_KEY=secret key 
```

## Advanced Healthcare Agent System

### 1. Multi-Agent Clinical Decision Support

```python
from mcp_agent.workflows import ParallelWorkflow
from typing import List, Dict, Any

class ClinicalDecisionSystem:
    """Multi-agent system for comprehensive clinical assessment"""
    
    def __init__(self):
        # Specialized agents for different clinical domains
        self.diagnostic_agent = self.create_diagnostic_agent()
        self.medication_agent = self.create_medication_agent()
        self.lab_analyst_agent = self.create_lab_analyst_agent()
        self.synthesis_agent = self.create_synthesis_agent()
    
    def create_diagnostic_agent(self):
        """Agent focused on differential diagnosis"""
        llm = AugmentedLLM(
            llm_client=Anthropic(),
            system_prompt="""You are a diagnostic specialist AI. Focus on:
            - Analyzing symptoms and clinical findings
            - Generating differential diagnoses
            - Identifying red flags requiring immediate attention
            - Recommending diagnostic workup
            
            Use available EHR tools to gather comprehensive patient history."""
        )
        
        return Agent(
            llm=llm,
            mcp_servers={"neo4j_ehr": self.get_neo4j_config()}
        )
    
    def create_medication_agent(self):
        """Agent focused on medication review and interactions"""
        llm = AugmentedLLM(
            llm_client=Anthropic(),
            system_prompt="""You are a clinical pharmacist AI. Focus on:
            - Reviewing current medications
            - Identifying drug interactions
            - Assessing appropriateness of dosing
            - Recommending medication adjustments
            
            Always consider patient allergies and contraindications."""
        )
        
        return Agent(
            llm=llm,
            mcp_servers={"neo4j_ehr": self.get_neo4j_config()}
        )
    
    def create_lab_analyst_agent(self):
        """Agent focused on laboratory result interpretation"""
        llm = AugmentedLLM(
            llm_client=Anthropic(),
            system_prompt="""You are a laboratory medicine specialist AI. Focus on:
            - Interpreting lab results in clinical context
            - Identifying trends over time
            - Flagging critical values
            - Suggesting additional testing if needed
            
            Consider patient age, gender, and clinical condition."""
        )
        
        return Agent(
            llm=llm,
            mcp_servers={"neo4j_ehr": self.get_neo4j_config()}
        )
    
    def create_synthesis_agent(self):
        """Agent that synthesizes multiple specialist opinions"""
        llm = AugmentedLLM(
            llm_client=Anthropic(),
            system_prompt="""You are a chief medical officer AI responsible for synthesizing
            multiple specialist assessments into a cohesive clinical plan.
            
            Your role:
            - Integrate different specialist perspectives
            - Identify areas of agreement and disagreement
            - Prioritize recommendations by urgency and importance
            - Create a unified action plan
            - Highlight any safety concerns"""
        )
        
        return Agent(llm=llm, mcp_servers={})  # No direct MCP access - works with synthesized data
    
    async def comprehensive_assessment(
        self, 
        patient_id: str, 
        clinical_question: str
    ) -> Dict[str, Any]:
        """Run comprehensive multi-agent assessment"""
        
        # Prepare query for each specialist
        specialist_query = f"""
        Patient ID: {patient_id}
        Clinical Question: {clinical_question}
        
        Please provide your specialized assessment based on available EHR data.
        """
        
        # Run parallel assessments
        print("🔄 Running parallel specialist consultations...")
        workflow = ParallelWorkflow([
            self.diagnostic_agent,
            self.medication_agent,
            self.lab_analyst_agent
        ])
        
        specialist_results = await workflow.run(specialist_query)
        
        # Synthesize results
        print("🧠 Synthesizing specialist opinions...")
        synthesis_prompt = f"""
        Synthesize these specialist assessments for patient {patient_id}:
        
        DIAGNOSTIC ASSESSMENT:
        {specialist_results[0]}
        
        MEDICATION REVIEW:
        {specialist_results[1]}
        
        LABORATORY ANALYSIS:
        {specialist_results[2]}
        
        Provide a unified clinical assessment with prioritized recommendations.
        """
        
        synthesis = await self.synthesis_agent.run(synthesis_prompt)
        
        return {
            "patient_id": patient_id,
            "clinical_question": clinical_question,
            "specialist_assessments": {
                "diagnostic": specialist_results[0],
                "medication": specialist_results[1],
                "laboratory": specialist_results[2]
            },
            "unified_assessment": synthesis.content,
            "timestamp": "2024-01-01T00:00:00Z"  # Add current timestamp
        }
    
    def get_neo4j_config(self):
        """Neo4j MCP server configuration"""
        return {
            "command": "/Users/samuelthio/projects/neo4j-mcp/.venv/bin/mcp-server-neo4j-ehr",
            "args": [],
            "cwd": "/Users/samuelthio/projects/neo4j-mcp",
            "env": {
                "NEO4J_URI": os.getenv("NEO4J_URI"),
                "NEO4J_USERNAME": os.getenv("NEO4J_USERNAME"), 
                "NEO4J_PASSWORD": os.getenv("NEO4J_PASSWORD"),
                "NEO4J_DATABASE": os.getenv("NEO4J_DATABASE"),
                "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY")
            }
        }

# Example usage
async def demo_multi_agent():
    system = ClinicalDecisionSystem()
    
    result = await system.comprehensive_assessment(
        patient_id="10461137",
        clinical_question="Patient presents with shortness of breath. What's the differential diagnosis and recommended workup?"
    )
    
    print("🏥 COMPREHENSIVE CLINICAL ASSESSMENT")
    print(f"Patient: {result['patient_id']}")
    print(f"Question: {result['clinical_question']}")
    print("\n" + "="*60)
    print(result['unified_assessment'])
```

### 2. Clinical Safety Wrapper

```python
import re
import json
from typing import Dict, Any, List
from datetime import datetime

class ClinicalSafetyWrapper:
    """Wraps mcp-agent with healthcare-specific safety checks"""
    
    def __init__(self, base_agent: Agent):
        self.agent = base_agent
        self.safety_rules = self.load_clinical_safety_rules()
        self.audit_log = []
    
    def load_clinical_safety_rules(self) -> Dict[str, Any]:
        """Load clinical safety rules and contraindications"""
        return {
            "dangerous_queries": [
                r"how to.*euthan",
                r"lethal dose",
                r"suicide.*method",
                r"how to.*kill"
            ],
            "requires_physician_review": [
                r"recommend.*medication",
                r"start.*drug",
                r"discontinue.*medication",
                r"diagnosis.*is"
            ],
            "critical_values": {
                "glucose": {"low": 70, "high": 400},
                "potassium": {"low": 3.0, "high": 5.5},
                "creatinine": {"low": 0, "high": 2.0}
            }
        }
    
    async def run_with_safety(self, query: str, patient_id: str = None) -> Dict[str, Any]:
        """Execute query with clinical safety checks"""
        
        # Pre-execution safety check
        safety_check = self.check_query_safety(query)
        if not safety_check["is_safe"]:
            return {
                "content": f"⚠️ Safety Check Failed: {safety_check['reason']}",
                "safety_blocked": True,
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            # Execute the agent
            response = await self.agent.run(query)
            
            # Post-execution safety analysis
            enhanced_response = self.enhance_response_with_safety(response, patient_id)
            
            # Audit logging
            await self.log_interaction(query, enhanced_response, patient_id)
            
            return enhanced_response
            
        except Exception as e:
            error_response = {
                "content": f"An error occurred: {str(e)}",
                "error": True,
                "timestamp": datetime.now().isoformat()
            }
            await self.log_interaction(query, error_response, patient_id)
            return error_response
    
    def check_query_safety(self, query: str) -> Dict[str, Any]:
        """Pre-execution safety checks"""
        query_lower = query.lower()
        
        # Check for dangerous content
        for pattern in self.safety_rules["dangerous_queries"]:
            if re.search(pattern, query_lower):
                return {
                    "is_safe": False,
                    "reason": "Query contains potentially harmful content"
                }
        
        return {"is_safe": True}
    
    def enhance_response_with_safety(self, response, patient_id: str = None) -> Dict[str, Any]:
        """Add safety warnings and clinical context to response"""
        content = response.content
        warnings = []
        
        # Check if response contains medication recommendations
        for pattern in self.safety_rules["requires_physician_review"]:
            if re.search(pattern, content.lower()):
                warnings.append(
                    "⚠️ Medication recommendations require physician review"
                )
        
        # Check for critical values in lab results
        critical_findings = self.detect_critical_values(content)
        if critical_findings:
            warnings.append(
                f"🚨 CRITICAL VALUES DETECTED: {', '.join(critical_findings)}"
            )
        
        # Add standard clinical disclaimer
        if not warnings:
            warnings.append(
                "ℹ️ This information is for clinical decision support only. Always verify with current guidelines and patient-specific factors."
            )
        
        return {
            "content": content,
            "warnings": warnings,
            "patient_id": patient_id,
            "tool_calls": getattr(response, 'tool_calls', []),
            "timestamp": datetime.now().isoformat(),
            "safety_checked": True
        }
    
    def detect_critical_values(self, content: str) -> List[str]:
        """Detect critical lab values in response content"""
        critical_findings = []
        
        # Simple pattern matching for common critical values
        # In production, this would be more sophisticated
        patterns = {
            "glucose": r"glucose.*?(\d+(?:\.\d+)?)",
            "potassium": r"potassium.*?(\d+(?:\.\d+)?)",
            "creatinine": r"creatinine.*?(\d+(?:\.\d+)?)"
        }
        
        for test, pattern in patterns.items():
            matches = re.finditer(pattern, content.lower())
            for match in matches:
                value = float(match.group(1))
                ranges = self.safety_rules["critical_values"][test]
                
                if value < ranges["low"] or value > ranges["high"]:
                    critical_findings.append(f"{test}: {value}")
        
        return critical_findings
    
    async def log_interaction(self, query: str, response: Dict[str, Any], patient_id: str = None):
        """Audit log for clinical interactions"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "patient_id": patient_id,
            "response_length": len(response.get("content", "")),
            "tools_used": [tc.get("tool", "unknown") for tc in response.get("tool_calls", [])],
            "warnings_generated": len(response.get("warnings", [])),
            "safety_blocked": response.get("safety_blocked", False)
        }
        
        self.audit_log.append(log_entry)
        
        # In production, you'd write this to a proper audit database
        # For now, just keep in memory
```

## Integration with Neo4j MCP Server

### 1. Server Configuration for mcp-agent

```python
def get_neo4j_mcp_config():
    """Configuration for your existing Neo4j MCP server"""
    return {
        "neo4j_ehr": {
            # Use the executable from your virtual environment
            "command": "/Users/samuelthio/projects/neo4j-mcp/.venv/bin/mcp-server-neo4j-ehr",
            "args": [],
            "cwd": "/Users/samuelthio/projects/neo4j-mcp",
            "env": {
                "NEO4J_URI": os.getenv("NEO4J_URI"),
                "NEO4J_USERNAME": os.getenv("NEO4J_USERNAME"),
                "NEO4J_PASSWORD": os.getenv("NEO4J_PASSWORD"),
                "NEO4J_DATABASE": os.getenv("NEO4J_DATABASE"),
                "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY")
            }
        }
    }

def create_healthcare_agent_with_neo4j():
    """Create agent specifically configured for your Neo4j server"""
    
    llm = AugmentedLLM(
        llm_client=Anthropic(),
        system_prompt="""You are a healthcare AI with access to a Neo4j EHR database.

AVAILABLE TOOLS (from neo4j-ehr server):
- ehr_get_clinical_notes: Retrieve discharge summaries, radiology reports by patient/admission
- ehr_patient: Get comprehensive patient record with admissions, diagnoses, etc.
- ehr_list_diagnoses: List diagnoses for patient or admission
- ehr_list_lab_events: List laboratory results
- ehr_list_medications: List medications
- ehr_list_procedures: List procedures
- ehr_natural_query: Ask complex questions in natural language
- ehr_get_schema: Get database structure

TOOL USAGE STRATEGY:
1. For specific patients: Start with ehr_patient to get overview
2. For clinical notes: Use ehr_get_clinical_notes with patient_id for radiology, admission_id for discharge
3. For complex queries: Use ehr_natural_query
4. For browsing data: Use appropriate list tools

Remember: Results are ordered by charttime DESC (most recent first) when limit=1."""
    )
    
    return Agent(
        llm=llm,
        mcp_servers=get_neo4j_mcp_config()
    )
```

### 2. Tool-Specific Helpers

```python
class Neo4jEHRHelper:
    """Helper class for common Neo4j EHR operations"""
    
    def __init__(self, agent: Agent):
        self.agent = agent
    
    async def get_patient_summary(self, patient_id: str) -> Dict[str, Any]:
        """Get comprehensive patient summary"""
        query = f"""Get a comprehensive overview of patient {patient_id} including:
        - Basic demographics and current status
        - Recent admissions and diagnoses
        - Current medications
        - Recent lab results (if any abnormal values, highlight them)
        - Recent clinical notes (discharge summaries, radiology reports)"""
        
        response = await self.agent.run(query)
        return {"patient_id": patient_id, "summary": response.content}
    
    async def analyze_symptoms(self, patient_id: str, symptoms: List[str]) -> Dict[str, Any]:
        """Analyze symptoms in context of patient history"""
        symptoms_text = ", ".join(symptoms)
        query = f"""Patient {patient_id} presents with: {symptoms_text}
        
        Please:
        1. Review their medical history for relevant context
        2. Check recent lab results that might be related
        3. Look for similar past episodes
        4. Suggest differential diagnosis considerations
        5. Recommend what additional information might be helpful"""
        
        response = await self.agent.run(query)
        return {
            "patient_id": patient_id,
            "symptoms": symptoms,
            "analysis": response.content
        }
    
    async def medication_review(self, patient_id: str) -> Dict[str, Any]:
        """Comprehensive medication review"""
        query = f"""Perform a medication review for patient {patient_id}:
        
        1. List current medications
        2. Check for potential interactions
        3. Review for duplicate therapies
        4. Consider appropriateness based on diagnoses
        5. Flag any missing indicated medications based on conditions"""
        
        response = await self.agent.run(query)
        return {
            "patient_id": patient_id,
            "medication_review": response.content
        }
```

## User Interface Options

### 1. Streamlit Web App (Recommended for Quick Start)

Create `streamlit_app.py`:

```python
import streamlit as st
import asyncio
from healthcare_agent import HealthcareAssistant
from clinical_safety import ClinicalSafetyWrapper

st.set_page_config(
    page_title="Healthcare AI Assistant",
    page_icon="🏥",
    layout="wide"
)

class HealthcareStreamlitApp:
    def __init__(self):
        if 'assistant' not in st.session_state:
            st.session_state.assistant = None
        if 'messages' not in st.session_state:
            st.session_state.messages = []
    
    async def initialize_assistant(self):
        """Initialize the healthcare assistant"""
        if st.session_state.assistant is None:
            with st.spinner("🔄 Connecting to EHR systems..."):
                base_agent = HealthcareAssistant().agent
                st.session_state.assistant = ClinicalSafetyWrapper(base_agent)
    
    def run(self):
        """Main Streamlit app"""
        st.title("🏥 Healthcare AI Assistant")
        st.markdown("*Powered by mcp-agent + Neo4j EHR*")
        
        # Sidebar for patient context
        with st.sidebar:
            st.header("Patient Context")
            patient_id = st.text_input("Patient ID", placeholder="e.g., 10461137")
            
            if patient_id:
                st.success(f"Active Patient: {patient_id}")
            
            st.markdown("---")
            st.markdown("### Quick Actions")
            
            if st.button("📋 Patient Summary") and patient_id:
                st.session_state.messages.append({
                    "role": "user",
                    "content": f"Give me a comprehensive summary of patient {patient_id}"
                })
                st.rerun()
            
            if st.button("🧪 Recent Lab Results") and patient_id:
                st.session_state.messages.append({
                    "role": "user", 
                    "content": f"What are the most recent lab results for patient {patient_id}? Highlight any abnormal values."
                })
                st.rerun()
            
            if st.button("📄 Latest Discharge Summary") and patient_id:
                st.session_state.messages.append({
                    "role": "user",
                    "content": f"Show me the most recent discharge summary for patient {patient_id}"
                })
                st.rerun()
        
        # Main chat interface
        self.render_chat_interface(patient_id)
    
    def render_chat_interface(self, patient_id: str):
        """Render the main chat interface"""
        
        # Initialize assistant
        asyncio.run(self.initialize_assistant())
        
        # Display chat messages
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # Show warnings if present
                if "warnings" in message:
                    for warning in message["warnings"]:
                        st.warning(warning)
                
                # Show tools used
                if "tool_calls" in message and message["tool_calls"]:
                    with st.expander("🔧 Tools Used"):
                        for tool_call in message["tool_calls"]:
                            st.code(f"Tool: {tool_call.get('tool', 'unknown')}")
                            if tool_call.get('arguments'):
                                st.json(tool_call['arguments'])
        
        # Chat input
        if prompt := st.chat_input("Ask about patient care..."):
            # Add user message
            st.session_state.messages.append({
                "role": "user",
                "content": prompt
            })
            
            # Get assistant response
            with st.chat_message("assistant"):
                with st.spinner("🤔 Analyzing..."):
                    response = asyncio.run(
                        st.session_state.assistant.run_with_safety(
                            prompt, 
                            patient_id=patient_id
                        )
                    )
                
                st.markdown(response["content"])
                
                # Show warnings
                if response.get("warnings"):
                    for warning in response["warnings"]:
                        st.warning(warning)
                
                # Show tools used
                if response.get("tool_calls"):
                    with st.expander("🔧 Tools Used"):
                        for tool_call in response["tool_calls"]:
                            st.code(f"Tool: {tool_call.get('tool', 'unknown')}")
                
                # Add to message history
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response["content"],
                    "warnings": response.get("warnings", []),
                    "tool_calls": response.get("tool_calls", [])
                })

# Run the app
if __name__ == "__main__":
    app = HealthcareStreamlitApp()
    app.run()
```

Run with:
```bash
streamlit run streamlit_app.py
```

### 2. FastAPI REST API (for Production)

Create `api_server.py`:

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, List
import asyncio
from healthcare_agent import HealthcareAssistant
from clinical_safety import ClinicalSafetyWrapper

app = FastAPI(title="Healthcare AI API", version="1.0.0")

# Global assistant instance
assistant = None

class ChatRequest(BaseModel):
    message: str
    patient_id: Optional[str] = None

class ChatResponse(BaseModel):
    content: str
    patient_id: Optional[str] = None
    warnings: List[str] = []
    tool_calls: List[dict] = []
    timestamp: str

@app.on_event("startup")
async def startup_event():
    """Initialize the healthcare assistant on startup"""
    global assistant
    base_agent = HealthcareAssistant().agent
    assistant = ClinicalSafetyWrapper(base_agent)

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """Main chat endpoint"""
    try:
        response = await assistant.run_with_safety(
            request.message,
            patient_id=request.patient_id
        )
        
        return ChatResponse(
            content=response["content"],
            patient_id=response.get("patient_id"),
            warnings=response.get("warnings", []),
            tool_calls=response.get("tool_calls", []),
            timestamp=response["timestamp"]
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "service": "healthcare-ai-api"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## Deployment Guide

### 1. Local Development

```bash
# Clone your neo4j-mcp repository (if not already done)
git clone /path/to/neo4j-mcp
cd neo4j-mcp

# Set up the healthcare MCP client alongside it
mkdir ../healthcare-mcp-client
cd ../healthcare-mcp-client

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install mcp-agent anthropic streamlit fastapi uvicorn python-dotenv

# Copy the code files (healthcare_agent.py, clinical_safety.py, etc.)
# Set up .env file with your credentials

# Run Streamlit app
streamlit run streamlit_app.py

# Or run FastAPI server
python api_server.py
```

### 2. Docker Deployment

Create `Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Run the application
CMD ["python", "api_server.py"]
```

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  healthcare-ai:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - NEO4J_URI=${NEO4J_URI}
      - NEO4J_USERNAME=${NEO4J_USERNAME}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - NEO4J_DATABASE=${NEO4J_DATABASE}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      - healthcare-ai
    environment:
      - REACT_APP_API_URL=http://healthcare-ai:8000
```

### 3. Production Considerations

```python
# production_config.py
import os
from typing import Dict, Any

class ProductionConfig:
    """Production configuration for healthcare MCP app"""
    
    @staticmethod
    def get_config() -> Dict[str, Any]:
        return {
            "database": {
                "audit_logs": os.getenv("AUDIT_DB_URL"),
                "encryption_key": os.getenv("ENCRYPTION_KEY")
            },
            "security": {
                "jwt_secret": os.getenv("JWT_SECRET"),
                "token_expiry": 3600,  # 1 hour
                "rate_limit": "100/hour"
            },
            "monitoring": {
                "sentry_dsn": os.getenv("SENTRY_DSN"),
                "log_level": "INFO"
            },
            "healthcare": {
                "require_physician_auth": True,
                "audit_all_interactions": True,
                "hipaa_compliance": True
            }
        }
```

## Next Steps & Roadmap

### Phase 1: Core Implementation (Week 1-2)
- [ ] Set up basic healthcare agent with mcp-agent
- [ ] Integrate with your existing Neo4j MCP server  
- [ ] Implement clinical safety wrapper
- [ ] Create Streamlit prototype
- [ ] Test basic functionality

### Phase 2: Advanced Features (Week 3-4)
- [ ] Implement multi-agent clinical decision system
- [ ] Add audit logging and compliance features
- [ ] Create FastAPI REST API
- [ ] Build React frontend (optional)
- [ ] Add user authentication

### Phase 3: Production Readiness (Week 5-6)
- [ ] Implement comprehensive error handling
- [ ] Add monitoring and alerting
- [ ] Security hardening
- [ ] Performance optimization
- [ ] Documentation and training materials

### Phase 4: Integration & Scaling (Future)
- [ ] FHIR server integration
- [ ] Epic/Cerner connectors
- [ ] Clinical decision rules engine
- [ ] Mobile app development
- [ ] Multi-tenant architecture

### Immediate Next Steps

1. **Start with the basic implementation**:
   ```bash
   pip install mcp-agent anthropic streamlit
   python healthcare_agent.py  # Test basic functionality
   ```

2. **Test with your Neo4j server**:
   - Ensure your neo4j-mcp server is working
   - Test the mcp-agent integration
   - Verify tool discovery and execution

3. **Build the Streamlit prototype**:
   - Get immediate visual feedback
   - Test different query patterns
   - Validate the user experience

4. **Add safety features incrementally**:
   - Start with basic warnings
   - Add audit logging
   - Implement clinical validation rules

### Success Metrics

- **Functionality**: Can replicate Claude Desktop's capabilities
- **Safety**: All interactions logged, warnings for critical values
- **Performance**: Response time < 5 seconds for most queries
- **Usability**: Intuitive interface for healthcare professionals
- **Compliance**: Audit trail suitable for clinical use

This implementation plan gives you a production-ready healthcare AI assistant that leverages your existing Neo4j MCP server while adding the intelligent orchestration capabilities of Claude Desktop through the mcp-agent framework.
</file>

<file path="MCP_CLIENT_GUIDE.md">
# Building an MCP Client Web Application

This guide covers building a custom MCP (Model Context Protocol) client as a web application with database access, AI model integration, custom UIs, and automated testing.

## Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Technology Stack](#technology-stack)
4. [Implementation Plan](#implementation-plan)
5. [Core Components](#core-components)
6. [Web Application Setup](#web-application-setup)
7. [MCP Client Implementation](#mcp-client-implementation)
8. [Database Integration](#database-integration)
9. [AI Model Integration](#ai-model-integration)
10. [Custom UI Components](#custom-ui-components)
11. [Automated Testing](#automated-testing)
12. [Deployment](#deployment)

## Overview

An MCP client is a program that can:
- Start and manage MCP server processes
- Communicate with servers via JSON-RPC 2.0
- Discover and invoke tools provided by servers
- Handle responses and errors gracefully

### Benefits of a Web-Based MCP Client

- **Universal Access**: Use from any device with a browser
- **Multi-User Support**: Multiple users can access different MCP servers
- **Rich UI**: Build interactive dashboards and visualizations
- **API Gateway**: Expose MCP tools as REST/GraphQL APIs
- **Integration Hub**: Connect multiple AI models and services

## Architecture

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   Frontend      │     │   Backend API   │     │   MCP Servers   │
│   (React/Vue)   │────▶│   (Node/Python) │────▶│   (Multiple)    │
└─────────────────┘     └─────────────────┘     └─────────────────┘
         │                        │                        │
         │                        │                        │
         ▼                        ▼                        ▼
   ┌──────────┐           ┌──────────────┐       ┌──────────────┐
   │    UI    │           │ MCP Manager  │       │ Neo4j Server │
   │Components│           │   Service    │       │ Other Server │
   └──────────┘           └──────────────┘       └──────────────┘
```

### Key Components

1. **Frontend**: Interactive web interface
2. **Backend API**: Manages MCP connections and provides REST/WebSocket APIs
3. **MCP Manager**: Handles server lifecycle and communication
4. **Database**: Stores configurations, logs, and results
5. **AI Integration**: Connects to various AI providers

## Technology Stack

### Recommended Stack

**Frontend:**
- **Framework**: React with TypeScript (or Vue.js)
- **UI Library**: Material-UI, Ant Design, or Tailwind UI
- **State Management**: Redux Toolkit or Zustand
- **Real-time**: Socket.io client for live updates

**Backend:**
- **Runtime**: Node.js with TypeScript
- **Framework**: Express.js or Fastify
- **WebSocket**: Socket.io for real-time communication
- **Process Management**: node-pty for spawning MCP servers
- **Database**: PostgreSQL with Prisma ORM

**Testing:**
- **Unit Tests**: Jest
- **Integration Tests**: Supertest
- **E2E Tests**: Playwright or Cypress
- **MCP Mocking**: Custom mock servers

## Implementation Plan

### Phase 1: Core MCP Client (Week 1-2)

1. Set up project structure
2. Implement MCP client class
3. Handle JSON-RPC communication
4. Process management (start/stop servers)
5. Basic CLI for testing

### Phase 2: Web API Layer (Week 2-3)

1. REST API design
2. WebSocket implementation
3. Authentication & authorization
4. Server configuration management
5. API documentation (OpenAPI)

### Phase 3: Frontend Development (Week 3-4)

1. UI framework setup
2. Dashboard layout
3. Tool exploration interface
4. Real-time updates
5. Response visualization

### Phase 4: Advanced Features (Week 4-6)

1. AI model integration
2. Custom UI components for tools
3. Workflow automation
4. Advanced testing framework
5. Performance optimization

## Core Components

### MCP Client Class (TypeScript)

```typescript
// src/mcp/MCPClient.ts
import { spawn, ChildProcess } from 'child_process';
import { EventEmitter } from 'events';

interface MCPRequest {
  jsonrpc: '2.0';
  method: string;
  params?: any;
  id: number | string;
}

interface MCPResponse {
  jsonrpc: '2.0';
  result?: any;
  error?: {
    code: number;
    message: string;
    data?: any;
  };
  id: number | string;
}

export class MCPClient extends EventEmitter {
  private process: ChildProcess | null = null;
  private requestId = 0;
  private pendingRequests = new Map<number, {
    resolve: (value: any) => void;
    reject: (error: any) => void;
  }>();

  constructor(private command: string, private args: string[] = []) {
    super();
  }

  async connect(): Promise<void> {
    this.process = spawn(this.command, this.args, {
      stdio: ['pipe', 'pipe', 'pipe']
    });

    this.process.stdout?.on('data', (data) => {
      this.handleResponse(data.toString());
    });

    this.process.stderr?.on('data', (data) => {
      console.error('MCP Server Error:', data.toString());
    });

    this.process.on('exit', (code) => {
      this.emit('exit', code);
    });

    // Initialize connection
    await this.request('initialize', {
      protocolVersion: '2024-11-05',
      capabilities: {}
    });
  }

  private async request(method: string, params?: any): Promise<any> {
    const id = ++this.requestId;
    const request: MCPRequest = {
      jsonrpc: '2.0',
      method,
      params,
      id
    };

    return new Promise((resolve, reject) => {
      this.pendingRequests.set(id, { resolve, reject });
      this.process?.stdin?.write(JSON.stringify(request) + '\n');
    });
  }

  private handleResponse(data: string): void {
    try {
      const response: MCPResponse = JSON.parse(data);
      const pending = this.pendingRequests.get(response.id as number);
      
      if (pending) {
        if (response.error) {
          pending.reject(response.error);
        } else {
          pending.resolve(response.result);
        }
        this.pendingRequests.delete(response.id as number);
      }
    } catch (error) {
      console.error('Failed to parse MCP response:', error);
    }
  }

  async listTools() {
    return this.request('tools/list');
  }

  async callTool(name: string, arguments: any) {
    return this.request('tools/call', { name, arguments });
  }

  async disconnect(): Promise<void> {
    this.process?.kill();
    this.process = null;
  }
}
```

### Server Manager

```typescript
// src/mcp/ServerManager.ts
export interface ServerConfig {
  id: string;
  name: string;
  command: string;
  args?: string[];
  env?: Record<string, string>;
  autoStart?: boolean;
}

export class ServerManager {
  private servers = new Map<string, MCPClient>();
  private configs = new Map<string, ServerConfig>();

  async addServer(config: ServerConfig): Promise<void> {
    this.configs.set(config.id, config);
    
    if (config.autoStart) {
      await this.startServer(config.id);
    }
  }

  async startServer(id: string): Promise<MCPClient> {
    const config = this.configs.get(id);
    if (!config) throw new Error(`Server ${id} not found`);

    const client = new MCPClient(config.command, config.args);
    
    // Set environment variables
    if (config.env) {
      process.env = { ...process.env, ...config.env };
    }

    await client.connect();
    this.servers.set(id, client);
    
    return client;
  }

  async stopServer(id: string): Promise<void> {
    const client = this.servers.get(id);
    if (client) {
      await client.disconnect();
      this.servers.delete(id);
    }
  }

  getServer(id: string): MCPClient | undefined {
    return this.servers.get(id);
  }

  listServers(): ServerConfig[] {
    return Array.from(this.configs.values());
  }
}
```

## Web Application Setup

### Backend API Structure

```typescript
// src/api/server.ts
import express from 'express';
import { Server } from 'socket.io';
import { ServerManager } from '../mcp/ServerManager';

const app = express();
const io = new Server(server, {
  cors: {
    origin: process.env.FRONTEND_URL || 'http://localhost:3000'
  }
});

const serverManager = new ServerManager();

// REST API Routes
app.post('/api/servers', async (req, res) => {
  try {
    await serverManager.addServer(req.body);
    res.json({ success: true });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.get('/api/servers/:id/tools', async (req, res) => {
  try {
    const server = serverManager.getServer(req.params.id);
    if (!server) return res.status(404).json({ error: 'Server not found' });
    
    const tools = await server.listTools();
    res.json(tools);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.post('/api/servers/:id/tools/:toolName', async (req, res) => {
  try {
    const server = serverManager.getServer(req.params.id);
    if (!server) return res.status(404).json({ error: 'Server not found' });
    
    const result = await server.callTool(req.params.toolName, req.body);
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// WebSocket for real-time updates
io.on('connection', (socket) => {
  socket.on('subscribe-server', (serverId) => {
    socket.join(`server:${serverId}`);
  });

  socket.on('call-tool', async (data) => {
    const { serverId, toolName, arguments } = data;
    const server = serverManager.getServer(serverId);
    
    if (server) {
      try {
        const result = await server.callTool(toolName, arguments);
        socket.emit('tool-result', { toolName, result });
      } catch (error) {
        socket.emit('tool-error', { toolName, error: error.message });
      }
    }
  });
});
```

### Frontend Components

```tsx
// src/components/MCPDashboard.tsx
import React, { useState, useEffect } from 'react';
import { ServerList } from './ServerList';
import { ToolExplorer } from './ToolExplorer';
import { ResultViewer } from './ResultViewer';
import { useMCPClient } from '../hooks/useMCPClient';

export const MCPDashboard: React.FC = () => {
  const { servers, tools, results, callTool } = useMCPClient();
  const [selectedServer, setSelectedServer] = useState<string | null>(null);
  const [selectedTool, setSelectedTool] = useState<string | null>(null);

  return (
    <div className="mcp-dashboard">
      <div className="sidebar">
        <ServerList
          servers={servers}
          selectedServer={selectedServer}
          onSelectServer={setSelectedServer}
        />
      </div>
      
      <div className="main-content">
        {selectedServer && (
          <ToolExplorer
            tools={tools[selectedServer] || []}
            selectedTool={selectedTool}
            onSelectTool={setSelectedTool}
            onCallTool={(toolName, args) => 
              callTool(selectedServer, toolName, args)
            }
          />
        )}
        
        <ResultViewer results={results} />
      </div>
    </div>
  );
};
```

## Database Integration

### Schema Design

```sql
-- PostgreSQL schema for MCP client
CREATE TABLE servers (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  command VARCHAR(255) NOT NULL,
  args JSONB DEFAULT '[]',
  env JSONB DEFAULT '{}',
  auto_start BOOLEAN DEFAULT false,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE tool_calls (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  server_id UUID REFERENCES servers(id),
  tool_name VARCHAR(255) NOT NULL,
  arguments JSONB,
  result JSONB,
  error TEXT,
  duration_ms INTEGER,
  user_id UUID,
  created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE workflows (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  description TEXT,
  steps JSONB NOT NULL,
  created_by UUID,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
```

### Prisma Integration

```typescript
// prisma/schema.prisma
model Server {
  id        String   @id @default(uuid())
  name      String
  command   String
  args      Json     @default("[]")
  env       Json     @default("{}")
  autoStart Boolean  @default(false)
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
  
  toolCalls ToolCall[]
}

model ToolCall {
  id         String   @id @default(uuid())
  serverId   String
  server     Server   @relation(fields: [serverId], references: [id])
  toolName   String
  arguments  Json?
  result     Json?
  error      String?
  durationMs Int?
  userId     String?
  createdAt  DateTime @default(now())
}
```

## AI Model Integration

### Multi-Model Support

```typescript
// src/ai/AIProvider.ts
interface AIProvider {
  name: string;
  generateCompletion(prompt: string, context?: any): Promise<string>;
  generateEmbedding(text: string): Promise<number[]>;
}

class OpenAIProvider implements AIProvider {
  name = 'openai';
  
  constructor(private apiKey: string) {}
  
  async generateCompletion(prompt: string, context?: any): Promise<string> {
    // Implementation using OpenAI API
  }
  
  async generateEmbedding(text: string): Promise<number[]> {
    // Implementation using OpenAI embeddings
  }
}

class AnthropicProvider implements AIProvider {
  name = 'anthropic';
  
  constructor(private apiKey: string) {}
  
  async generateCompletion(prompt: string, context?: any): Promise<string> {
    // Implementation using Claude API
  }
  
  async generateEmbedding(text: string): Promise<number[]> {
    // Implementation using Anthropic embeddings
  }
}

// AI-enhanced MCP tool calling
class AIEnhancedMCPClient {
  constructor(
    private mcpClient: MCPClient,
    private aiProvider: AIProvider
  ) {}
  
  async intelligentToolCall(userQuery: string): Promise<any> {
    // 1. Get available tools
    const tools = await this.mcpClient.listTools();
    
    // 2. Use AI to determine which tool to call
    const toolSelectionPrompt = `
      User Query: ${userQuery}
      Available Tools: ${JSON.stringify(tools)}
      
      Which tool should be called and with what arguments?
      Respond with JSON: { "tool": "tool_name", "arguments": {} }
    `;
    
    const aiResponse = await this.aiProvider.generateCompletion(toolSelectionPrompt);
    const { tool, arguments } = JSON.parse(aiResponse);
    
    // 3. Call the selected tool
    return this.mcpClient.callTool(tool, arguments);
  }
}
```

## Custom UI Components

### Tool-Specific UIs

```tsx
// src/components/tools/PatientViewer.tsx
import React from 'react';
import { Patient, Admission } from '../types';

interface PatientViewerProps {
  data: {
    patient: Patient;
    admissions?: Admission[];
  };
}

export const PatientViewer: React.FC<PatientViewerProps> = ({ data }) => {
  return (
    <div className="patient-viewer">
      <div className="patient-header">
        <h2>Patient {data.patient.subject_id}</h2>
        <div className="patient-demographics">
          <span>Gender: {data.patient.gender}</span>
          <span>Age: {data.patient.anchor_age}</span>
        </div>
      </div>
      
      {data.admissions && (
        <div className="admissions-timeline">
          <h3>Admissions Timeline</h3>
          {data.admissions.map(admission => (
            <div key={admission.hadm_id} className="admission-card">
              <h4>Admission {admission.hadm_id}</h4>
              <p>Type: {admission.admission_type}</p>
              <p>Admitted: {admission.admittime}</p>
              <p>Discharged: {admission.dischtime}</p>
            </div>
          ))}
        </div>
      )}
    </div>
  );
};

// Tool UI Registry
export const toolUIRegistry = {
  'ehr_patient': PatientViewer,
  'ehr_search_notes': NoteSearchViewer,
  'ehr_list_diagnoses': DiagnosisListViewer,
  // ... other tool-specific components
};
```

### Dynamic Form Generation

```tsx
// src/components/DynamicToolForm.tsx
import React from 'react';
import { useForm } from 'react-hook-form';

interface ToolParameter {
  name: string;
  type: string;
  description?: string;
  required?: boolean;
  default?: any;
  enum?: string[];
}

interface DynamicToolFormProps {
  tool: {
    name: string;
    description: string;
    parameters: ToolParameter[];
  };
  onSubmit: (args: any) => void;
}

export const DynamicToolForm: React.FC<DynamicToolFormProps> = ({ 
  tool, 
  onSubmit 
}) => {
  const { register, handleSubmit } = useForm();

  const renderField = (param: ToolParameter) => {
    switch (param.type) {
      case 'string':
        if (param.enum) {
          return (
            <select {...register(param.name)} defaultValue={param.default}>
              {param.enum.map(value => (
                <option key={value} value={value}>{value}</option>
              ))}
            </select>
          );
        }
        return (
          <input
            type="text"
            {...register(param.name)}
            defaultValue={param.default}
          />
        );
      
      case 'boolean':
        return (
          <input
            type="checkbox"
            {...register(param.name)}
            defaultChecked={param.default}
          />
        );
      
      case 'number':
        return (
          <input
            type="number"
            {...register(param.name, { valueAsNumber: true })}
            defaultValue={param.default}
          />
        );
      
      default:
        return null;
    }
  };

  return (
    <form onSubmit={handleSubmit(onSubmit)}>
      <h3>{tool.name}</h3>
      <p>{tool.description}</p>
      
      {tool.parameters.map(param => (
        <div key={param.name} className="form-field">
          <label>
            {param.name}
            {param.required && <span className="required">*</span>}
          </label>
          {renderField(param)}
          {param.description && (
            <small>{param.description}</small>
          )}
        </div>
      ))}
      
      <button type="submit">Execute Tool</button>
    </form>
  );
};
```

## Automated Testing

### Testing Strategy

```typescript
// src/tests/mcp-client.test.ts
import { MCPClient } from '../mcp/MCPClient';
import { MockMCPServer } from './mocks/MockMCPServer';

describe('MCPClient', () => {
  let client: MCPClient;
  let mockServer: MockMCPServer;

  beforeEach(async () => {
    mockServer = new MockMCPServer();
    await mockServer.start();
    
    client = new MCPClient('node', [mockServer.getPath()]);
    await client.connect();
  });

  afterEach(async () => {
    await client.disconnect();
    await mockServer.stop();
  });

  test('should list tools', async () => {
    const tools = await client.listTools();
    expect(tools).toHaveProperty('tools');
    expect(Array.isArray(tools.tools)).toBe(true);
  });

  test('should call tool successfully', async () => {
    const result = await client.callTool('test_tool', { 
      param1: 'value1' 
    });
    expect(result).toHaveProperty('success', true);
  });

  test('should handle tool errors', async () => {
    await expect(
      client.callTool('error_tool', {})
    ).rejects.toThrow('Tool execution failed');
  });
});
```

### Mock MCP Server

```typescript
// src/tests/mocks/MockMCPServer.ts
export class MockMCPServer {
  private server: any;
  private port: number;

  async start(): Promise<void> {
    // Create a mock server that responds to MCP protocol
    this.server = createMockServer({
      tools: [
        {
          name: 'test_tool',
          description: 'Test tool',
          parameters: [],
          handler: async (args) => ({ success: true, data: args })
        },
        {
          name: 'error_tool',
          description: 'Tool that errors',
          parameters: [],
          handler: async () => {
            throw new Error('Tool execution failed');
          }
        }
      ]
    });
    
    await this.server.listen(this.port);
  }

  getPath(): string {
    return path.join(__dirname, 'mock-mcp-server.js');
  }

  async stop(): Promise<void> {
    await this.server.close();
  }
}
```

### E2E Testing

```typescript
// src/tests/e2e/dashboard.test.ts
import { test, expect } from '@playwright/test';

test.describe('MCP Dashboard', () => {
  test('should add and connect to a server', async ({ page }) => {
    await page.goto('http://localhost:3000');
    
    // Add server
    await page.click('[data-testid="add-server-button"]');
    await page.fill('[name="name"]', 'Test Server');
    await page.fill('[name="command"]', 'mock-mcp-server');
    await page.click('[type="submit"]');
    
    // Verify server appears in list
    await expect(page.locator('[data-testid="server-list"]'))
      .toContainText('Test Server');
    
    // Connect to server
    await page.click('[data-testid="connect-button"]');
    await expect(page.locator('[data-testid="status"]'))
      .toContainText('Connected');
  });

  test('should execute a tool', async ({ page }) => {
    // ... setup server connection ...
    
    // Select tool
    await page.click('[data-testid="tool-ehr_patient"]');
    
    // Fill form
    await page.fill('[name="subject_id"]', '10000032');
    await page.check('[name="include_diagnoses"]');
    
    // Execute
    await page.click('[data-testid="execute-tool"]');
    
    // Verify results
    await expect(page.locator('[data-testid="results"]'))
      .toContainText('Patient 10000032');
  });
});
```

## Deployment

### Docker Configuration

```dockerfile
# Dockerfile
FROM node:18-alpine

# Install Python for MCP servers that need it
RUN apk add --no-cache python3 py3-pip

WORKDIR /app

# Copy package files
COPY package*.json ./
RUN npm ci --only=production

# Copy application
COPY . .

# Build frontend
RUN npm run build

EXPOSE 3000

CMD ["node", "dist/server.js"]
```

### Docker Compose

```yaml
# docker-compose.yml
version: '3.8'

services:
  mcp-client:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/mcp
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    volumes:
      - ./mcp-servers:/app/mcp-servers
  
  postgres:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=mcp
    volumes:
      - postgres-data:/var/lib/postgresql/data
  
  redis:
    image: redis:7
    volumes:
      - redis-data:/data

volumes:
  postgres-data:
  redis-data:
```

### Production Considerations

1. **Security**:
   - Implement proper authentication (JWT, OAuth)
   - Sanitize tool inputs
   - Use environment-specific configurations
   - Enable HTTPS

2. **Scalability**:
   - Use Redis for session management
   - Implement horizontal scaling for API servers
   - Use message queues for long-running tools

3. **Monitoring**:
   - Add application metrics (Prometheus)
   - Log aggregation (ELK stack)
   - Error tracking (Sentry)

4. **Performance**:
   - Cache tool responses
   - Implement rate limiting
   - Use connection pooling

## Next Steps

1. **Start with the core MCP client implementation**
2. **Build a simple REST API**
3. **Create basic UI components**
4. **Add one AI provider integration**
5. **Implement automated tests**
6. **Deploy a minimal version**
7. **Iterate based on user feedback**

## Resources

- [MCP Specification](https://github.com/anthropics/mcp)
- [JSON-RPC 2.0 Specification](https://www.jsonrpc.org/specification)
- [Socket.io Documentation](https://socket.io/docs/)
- [Playwright Testing](https://playwright.dev/)

This guide provides a foundation for building a production-ready MCP client web application. Start with the core components and gradually add features based on your specific needs.
</file>

<file path="mcp_inspector_test.md">
MCP Inspector Setup Guide for Neo4j MCP Server

  Prerequisites Confirmed

  - ✅ Node.js v24.4.1 installed (exceeds required v22.7.5)
  - ✅ Neo4j credentials configured in .env file
  - ✅ OpenAI API key configured for natural language queries
  - ✅ Project uses uv for package management

  Quick Start Commands

  1. Basic Launch

  npx @modelcontextprotocol/inspector uv run mcp-server-neo4j-ehr

  2. With Explicit Environment Variables

  npx @modelcontextprotocol/inspector \
    -e NEO4J_URI=neo4j+s://59e8b04a.databases.neo4j.io \
    -e NEO4J_USERNAME=neo4j \
    -e NEO4J_PASSWORD=password \
    -e NEO4J_DATABASE=neo4j \
    -e
  OPENAI_API_KEY=secret key \
    uv run mcp-server-neo4j-ehr

  3. Using Python Module Directly

  npx @modelcontextprotocol/inspector uv run python -m mcp_server_neo4j_ehr

  What to Expect

  1. MCP Inspector starts on http://localhost:6274
  2. Session token displayed in terminal
  3. Browser opens automatically with token pre-filled
  4. UI shows 8 available Neo4j tools

  Available Tools to Test

  - ehr_get_schema - View database structure
  - ehr_patient - Get patient records (example: subject_id "10000032")
  - ehr_search_notes - Search clinical notes
  - ehr_list_diagnoses - List patient diagnoses
  - ehr_list_lab_events - List lab results
  - ehr_list_medications - List medications
  - ehr_list_procedures - List medical procedures
  - ehr_natural_query - Natural language queries

  Troubleshooting

  - Ensure you're in /Users/samuelthio/projects/neo4j-mcp directory
  - The .env file is automatically loaded by python-dotenv
  - Verify Neo4j instance is accessible
  - Default transport mode is stdio (standard input/output)

  CLI Mode Testing

  For automated testing without UI:
  # List all tools
  npx @modelcontextprotocol/inspector --cli uv run mcp-server-neo4j-ehr --method tools/list

  # Get database schema
  npx @modelcontextprotocol/inspector --cli uv run mcp-server-neo4j-ehr --method tools/call --tool-name ehr_get_schema

  # Query a patient
  npx @modelcontextprotocol/inspector --cli uv run mcp-server-neo4j-ehr --method tools/call --tool-name ehr_patient --tool-arg subject_id=10000032
</file>

<file path="pytest.ini">
[pytest]
testpaths = tests src/mcp_server_neo4j_ehr/tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = auto
markers =
    integration: marks tests as integration tests (deselect with '-m "not integration"')
    unit: marks tests as unit tests
addopts = -v --tb=short
</file>

<file path="requirements.txt">
click>=8.1.7
fastmcp>=2.0.0
pydantic>=2.0.0
neo4j>=5.0.0
python-dotenv>=1.0.0
openai>=1.0.0
tabulate>=0.9.0
</file>

<file path="setup.sh">
#!/bin/bash
# Setup script for Neo4j MCP Server

echo "Setting up Neo4j MCP Server..."

# Install the package in editable mode with all dependencies
echo "Installing dependencies..."
uv pip install -e .

# Install test dependencies
echo "Installing test dependencies..."
uv pip install pytest pytest-asyncio

echo "Setup complete!"
echo ""
echo "To test your connection, run:"
echo "  uv run python examples/test_connection.py"
echo ""
echo "To start the server, run:"
echo "  uv run mcp-server-neo4j-ehr"
</file>

<file path="TOOL_REFACTORING.md">
# Clinical Notes Tool Refactoring

## Overview
We've refactored the clinical notes functionality to provide clearer separation between simple retrieval and complex queries.

## Changes Made

### 1. Renamed Tool
- **Old**: `ehr_search_notes`
- **New**: `ehr_get_clinical_notes`

### 2. Simplified Functionality
Removed:
- `query` parameter (no more text search)
- `semantic` parameter (no more AI-powered search)
- All OpenAI dependencies

The tool now simply retrieves notes by:
- Note type (discharge, radiology, or all)
- Patient ID
- Admission ID

### 3. Clear Usage Patterns

#### Get all radiology reports for a patient:
```python
ehr_get_clinical_notes(
    note_type="radiology",
    patient_id="10461137"
)
```

#### Get discharge summary for specific admission:
```python
ehr_get_clinical_notes(
    note_type="discharge", 
    admission_id="25236814"
)
```

#### Get all notes for a patient:
```python
ehr_get_clinical_notes(
    note_type="all",
    patient_id="10461137"
)
```

## Benefits

1. **Predictable**: No more confusion about whether to use patient_id or admission_id
2. **Fast**: No API calls or text searching overhead
3. **Simple**: Claude can easily understand when to use this tool
4. **Cost-effective**: No OpenAI API usage for basic retrieval

## Complex Queries

For complex searches like "find notes mentioning pulmonary fibrosis", use:
```
ehr_natural_query("Show me all notes for patient 10461137 that mention pulmonary fibrosis")
```

This separation makes the tools more intuitive and reduces the number of retry attempts Claude needs to make.

## Before vs After Examples

### Getting Radiology Reports

**Before (often failed):**
```
ehr_search_notes(query="radiology", note_type="radiology", patient_id="10461137")
# → No results (notes don't contain word "radiology")

ehr_search_notes(query="imaging", note_type="radiology", patient_id="10461137") 
# → No results (notes don't contain word "imaging")

ehr_search_notes(query="CT scan", note_type="radiology", patient_id="10461137")
# → Finally works if notes contain "CT scan"
```

**After (always works):**
```
ehr_get_clinical_notes(note_type="radiology", patient_id="10461137")
# → Returns all radiology reports for patient, guaranteed
```

### Getting Most Recent Discharge Summary

**Before (confusing):**
```
ehr_search_notes(query="", note_type="discharge", admission_id="25236814")
# → Unclear why query is empty, required admission_id
```

**After (intuitive):**
```
ehr_get_clinical_notes(note_type="discharge", patient_id="10461137", limit=1)
# → Gets most recent discharge summary, sorted by charttime DESC
```

## Performance Comparison

| Operation | Old Tool | New Tool |
|-----------|----------|----------|
| Get all radiology reports | 3 API attempts | 1 direct query |
| Get discharge summary | Required admission_id lookup | Works with patient_id |
| Response time | 2-5 seconds (with retries) | <1 second |
| Cost | Multiple OpenAI calls | No API calls |

## Common Usage Patterns

### 1. Medical Review Workflow
```python
# Get patient overview
patient = ehr_patient("10461137", include_admissions=True)

# Get latest discharge summary
discharge = ehr_get_clinical_notes(
    note_type="discharge", 
    patient_id="10461137", 
    limit=1
)

# Get all imaging reports
imaging = ehr_get_clinical_notes(
    note_type="radiology", 
    patient_id="10461137"
)

# Ask specific questions about findings
findings = ehr_natural_query(
    "What were the key findings in the CT scan for patient 10461137?"
)
```

### 2. Research Query Workflow
```python
# Find patients with specific conditions
patients = ehr_natural_query(
    "Find patients diagnosed with pulmonary fibrosis"
)

# For each patient, get their clinical notes
for patient_id in patient_ids:
    notes = ehr_get_clinical_notes(
        note_type="all",
        patient_id=patient_id,
        limit=10
    )
```

## Troubleshooting

### No Results Returned
**Problem**: `ehr_get_clinical_notes` returns empty array
**Solutions**:
- Check if patient_id exists in database
- Try `note_type="all"` instead of specific type
- Use `ehr_natural_query` to verify patient has notes

### Wrong Admission
**Problem**: Got discharge summary from wrong admission
**Solutions**:
- Use `admission_id` instead of `patient_id` for specific admission
- Use `limit=1` to get most recent only
- Check `charttime` field to verify date

### Performance Issues
**Problem**: Queries are slow
**Solutions**:
- `ehr_get_clinical_notes` should be fast (<1s)
- Use appropriate indexes on `subject_id`, `hadm_id`, `charttime`
- Use `limit` parameter to reduce result size

## Migration Guide

If you have existing code using `ehr_search_notes`:

```python
# Old code
result = ehr_search_notes(
    query="",  # Remove this
    note_type="discharge",
    semantic=False,  # Remove this
    patient_id="123",
    format="json"
)

# New code
result = ehr_get_clinical_notes(
    note_type="discharge",
    patient_id="123", 
    format="json"
)
```

For content searches, use natural language:
```python
# Old code
result = ehr_search_notes(
    query="pulmonary fibrosis",
    note_type="all",
    patient_id="123"
)

# New code
result = ehr_natural_query(
    "Find notes mentioning pulmonary fibrosis for patient 123"
)
```
</file>

<file path="ai_docs/pocket-pick-v1.md">
# Pocket Pick - Your Personal Knowledge Base

As engineers we end up reusing ideas, patterns and code snippets all the time but keeping track of these snippets can be hard and remembering where you stored them can be even harder. What if the exact snippet or idea you were looking for was one prompt away?

With Anthropics new MCP (model context protocol) and a minimal portable database layer - we can solve this problem. Pocket Pick is your personal engineering knowledge base that lets you quickly store ideas, patterns and code snippets and gives you a DEAD SIMPLE text or tag based searching to quickly find them in the future.

To implement this we'll...
1. Build the key sqlite functionality
2. Test the functionality with pytest
3. Expose the functionality via MCP server.

## SQLITE Database Structure

```
CREATE TABLE if not exists POCKET_PICK {
    id: str,
    created: datetime,
    text: str,
    tags: str[],
}
```

## Implementation Notes
- DEFAULT_SQLITE_DATABASE_PATH = Path.home() / ".pocket_pick.db" - place in constants.py
- always force (auto update) tags to be lowercase, trim whitespace, and use dash instead of spaces or underscores.
- mcp comands will return whatever the command returns.
- mirror ai_docs/mcp-server-git-repomix-output.xml structure to understand how to setup the mcp server
- use ai_docs/paic-pkb-repomix-output.xml to get a rough understanding of what we're building.
- libraries should be
  - click
  - mcp
  - pydantic
  - pytest (dev dependency)
  - sqlite3 (standard library)
- use `uv add <package>` to add libraries.
- we're using uv to manage the project.
- add mcp-server-pocket-pick = "mcp_server_pocket_pick:main" to the project.scripts section in pyproject.toml

## API

```
pocket add <text> \
    --tags, t: str[] (optional)
    --db: str = DEFAULT_SQLITE_DATABASE_PATH

pocket find <text> \
    --mode: substr | fts | glob | regex | exact (optional) \
    --limit, -l: number = 5 \
    --info, -i: bool (show with metadata like id) \
    --tags, -t: str[] (optional) \
    --db: str = DEFAULT_SQLITE_DATABASE_PATH

pocket list \
    --tags, -t: str[] (optional) \
    --limit, -l: number = 100 \
    --db: str = DEFAULT_SQLITE_DATABASE_PATH

pocket list-tags \
    --limit, -l: number = 1000 \
    --db: str = DEFAULT_SQLITE_DATABASE_PATH

pocket remove \
    --id, -i: str \
    --db: str = DEFAULT_SQLITE_DATABASE_PATH

pocket get \
    --id, -i: str \
    --db: str = DEFAULT_SQLITE_DATABASE_PATH

pocket backup <backup_absolute_path> \
    --db: str = DEFAULT_SQLITE_DATABASE_PATH
```

### Example API Calls (for find modes)
```
# basic sqlite substring search
pocket find "test" --mode substr

# full text search
pocket find "test" --mode fts

# glob search
pocket find "test*" --mode glob

# regex search
pocket find "^start.*test.*$" --mode regex

# exact search
pocket find "match exactly test" --mode exact
```

## Project Structure
- src/
  - mcp_server_pocket_pick/
    - __init__.py - MIRROR ai_docs/mcp-server-git-repomix-output.xml
    - __main__.py - MIRROR ai_docs/mcp-server-git-repomix-output.xml
    - server.py - MIRROR but use our functionality
      - serve(sqlite_database: Path | None) -> None
      - pass sqlite_database to every tool call (--db arg)
    - modules/
      - __init__.py
      - init_db.py
      - data_types.py
        - class AddCommand(BaseModel) {text: str, tags: list[str] = [], db_path: Path = DEFAULT_SQLITE_DATABASE_PATH}
        - ...
      - constants.py
        - DEFAULT_SQLITE_DATABASE_PATH: Path = Path.home() / ".pocket_pick.db"
      - functionality/
        - add.py
        - find.py
        - list.py
        - list_tags.py
        - remove.py
        - get.py
        - backup.py
    - tests/
      - __init__.py
      - test_init_db.py
      - functionality/
        - test_add.py
        - test_find.py
        - test_list.py
        - test_list_tags.py
        - test_remove.py
        - test_get.py
        - test_backup.py
    

## Validation (close the loop)
- use `uv run pytest` to validate the tests pass.
- use `uv run mcp-server-pocket-pick --help` to validate the mcp server works.
</file>

<file path="demo/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neo4j MCP Server Demo</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Neo4j EHR MCP Server Demo</h1>
            <div class="connection-status">
                <div class="status-indicator" id="status-indicator"></div>
                <span id="status-text">Disconnected</span>
                <input type="text" id="server-url" placeholder="Server URL" value="http://localhost:8080/mcp/">
                <button id="connect-btn" onclick="toggleConnection()">Connect</button>
            </div>
        </header>

        <main>
            <div class="tabs">
                <button class="tab-button active" onclick="showTab('patient')">Patient Info</button>
                <button class="tab-button" onclick="showTab('search-notes')">Search Notes</button>
                <button class="tab-button" onclick="showTab('diagnoses')">Diagnoses</button>
                <button class="tab-button" onclick="showTab('medications')">Medications</button>
                <button class="tab-button" onclick="showTab('procedures')">Procedures</button>
                <button class="tab-button" onclick="showTab('lab-events')">Lab Events</button>
                <button class="tab-button" onclick="showTab('natural-query')">Natural Query</button>
                <button class="tab-button" onclick="showTab('schema')">Schema</button>
            </div>

            <!-- Patient Information Tool -->
            <div id="patient-tab" class="tab-content active">
                <h2>Patient Information</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="patient-id">Patient ID:</label>
                        <input type="text" id="patient-id" placeholder="e.g., 10461137" value="10461137">
                    </div>
                    <div class="input-group">
                        <label>Include:</label>
                        <div class="checkbox-group">
                            <label><input type="checkbox" name="include" value="demographics" checked> Demographics</label>
                            <label><input type="checkbox" name="include" value="admissions"> Admissions</label>
                            <label><input type="checkbox" name="include" value="diagnoses"> Diagnoses</label>
                            <label><input type="checkbox" name="include" value="medications"> Medications</label>
                            <label><input type="checkbox" name="include" value="procedures"> Procedures</label>
                            <label><input type="checkbox" name="include" value="lab_events"> Lab Events</label>
                            <label><input type="checkbox" name="include" value="notes"> Clinical Notes</label>
                        </div>
                    </div>
                    <div class="input-group">
                        <label for="patient-format">Format:</label>
                        <select id="patient-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="getPatientInfo()">Get Patient Info</button>
                </div>
            </div>

            <!-- Search Notes Tool -->
            <div id="search-notes-tab" class="tab-content">
                <h2>Search Clinical Notes</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="search-query">Search Query:</label>
                        <input type="text" id="search-query" placeholder="e.g., chest pain" value="chest pain">
                    </div>
                    <div class="input-group">
                        <label for="search-type">Search Type:</label>
                        <select id="search-type">
                            <option value="text">Text Search</option>
                            <option value="semantic">Semantic Search</option>
                        </select>
                    </div>
                    <div class="input-group">
                        <label for="search-patient-id">Patient ID (optional):</label>
                        <input type="text" id="search-patient-id" placeholder="Leave empty for all patients">
                    </div>
                    <div class="input-group">
                        <label for="search-admission-id">Admission ID (optional):</label>
                        <input type="text" id="search-admission-id" placeholder="Leave empty for all admissions">
                    </div>
                    <div class="input-group">
                        <label for="search-limit">Limit:</label>
                        <input type="number" id="search-limit" value="10" min="1" max="100">
                    </div>
                    <div class="input-group">
                        <label for="search-format">Format:</label>
                        <select id="search-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="searchNotes()">Search Notes</button>
                </div>
            </div>

            <!-- Diagnoses Tool -->
            <div id="diagnoses-tab" class="tab-content">
                <h2>List Diagnoses</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="diagnoses-patient-id">Patient ID (optional):</label>
                        <input type="text" id="diagnoses-patient-id" placeholder="e.g., 10461137">
                    </div>
                    <div class="input-group">
                        <label for="diagnoses-admission-id">Admission ID (optional):</label>
                        <input type="text" id="diagnoses-admission-id" placeholder="e.g., 125957">
                    </div>
                    <div class="input-group">
                        <label for="diagnoses-limit">Limit:</label>
                        <input type="number" id="diagnoses-limit" value="20" min="1" max="100">
                    </div>
                    <div class="input-group">
                        <label for="diagnoses-format">Format:</label>
                        <select id="diagnoses-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="listDiagnoses()">List Diagnoses</button>
                </div>
            </div>

            <!-- Medications Tool -->
            <div id="medications-tab" class="tab-content">
                <h2>List Medications</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="medications-patient-id">Patient ID (optional):</label>
                        <input type="text" id="medications-patient-id" placeholder="e.g., 10461137">
                    </div>
                    <div class="input-group">
                        <label for="medications-admission-id">Admission ID (optional):</label>
                        <input type="text" id="medications-admission-id" placeholder="e.g., 125957">
                    </div>
                    <div class="input-group">
                        <label for="medications-limit">Limit:</label>
                        <input type="number" id="medications-limit" value="20" min="1" max="100">
                    </div>
                    <div class="input-group">
                        <label for="medications-format">Format:</label>
                        <select id="medications-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="listMedications()">List Medications</button>
                </div>
            </div>

            <!-- Procedures Tool -->
            <div id="procedures-tab" class="tab-content">
                <h2>List Procedures</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="procedures-patient-id">Patient ID (optional):</label>
                        <input type="text" id="procedures-patient-id" placeholder="e.g., 10461137">
                    </div>
                    <div class="input-group">
                        <label for="procedures-admission-id">Admission ID (optional):</label>
                        <input type="text" id="procedures-admission-id" placeholder="e.g., 125957">
                    </div>
                    <div class="input-group">
                        <label for="procedures-limit">Limit:</label>
                        <input type="number" id="procedures-limit" value="20" min="1" max="100">
                    </div>
                    <div class="input-group">
                        <label for="procedures-format">Format:</label>
                        <select id="procedures-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="listProcedures()">List Procedures</button>
                </div>
            </div>

            <!-- Lab Events Tool -->
            <div id="lab-events-tab" class="tab-content">
                <h2>List Lab Events</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="lab-patient-id">Patient ID (optional):</label>
                        <input type="text" id="lab-patient-id" placeholder="e.g., 10461137">
                    </div>
                    <div class="input-group">
                        <label for="lab-admission-id">Admission ID (optional):</label>
                        <input type="text" id="lab-admission-id" placeholder="e.g., 125957">
                    </div>
                    <div class="input-group">
                        <label for="lab-limit">Limit:</label>
                        <input type="number" id="lab-limit" value="20" min="1" max="100">
                    </div>
                    <div class="input-group">
                        <label for="lab-format">Format:</label>
                        <select id="lab-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="listLabEvents()">List Lab Events</button>
                </div>
            </div>

            <!-- Natural Query Tool -->
            <div id="natural-query-tab" class="tab-content">
                <h2>Natural Language Query</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="natural-query">Ask a question about the data:</label>
                        <textarea id="natural-query" rows="4" placeholder="e.g., Which patients had both diabetes and hypertension?">Which patients had both diabetes and hypertension?</textarea>
                    </div>
                    <div class="input-group">
                        <label for="natural-limit">Limit:</label>
                        <input type="number" id="natural-limit" value="10" min="1" max="100">
                    </div>
                    <div class="input-group">
                        <label for="natural-format">Format:</label>
                        <select id="natural-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="naturalQuery()">Ask Question</button>
                    <p class="note">Note: This requires an OpenAI API key to be configured on the server.</p>
                </div>
            </div>

            <!-- Schema Tool -->
            <div id="schema-tab" class="tab-content">
                <h2>Database Schema</h2>
                <div class="tool-section">
                    <div class="input-group">
                        <label for="schema-format">Format:</label>
                        <select id="schema-format">
                            <option value="json">JSON</option>
                            <option value="table">Table</option>
                            <option value="markdown">Markdown</option>
                        </select>
                    </div>
                    <button class="primary-btn" onclick="getSchema()">Get Schema</button>
                </div>
            </div>

            <!-- Results Section -->
            <div class="results-section">
                <h3>Results</h3>
                <div class="results-header">
                    <span id="results-info"></span>
                    <button class="secondary-btn" onclick="clearResults()">Clear</button>
                </div>
                <div id="loading" class="loading" style="display: none;">
                    <div class="spinner"></div>
                    <span>Loading...</span>
                </div>
                <div id="results" class="results"></div>
            </div>
        </main>

        <footer>
            <p>Neo4j MCP Server Demo - Test interface for EHR data queries</p>
            <p>Sample Patient IDs: 10461137, 11578849, 12017557, 14037695</p>
        </footer>
    </div>

    <script src="mcp-client.js"></script>
</body>
</html>
</file>

<file path="demo/mcp-client.js">
// MCP Client for Neo4j EHR Server (FastMCP HTTP with SSE)
class MCPClient {
    constructor(serverUrl) {
        this.serverUrl = serverUrl;
        this.requestId = 0;
        this.connected = false;
        this.sessionId = null;
    }

    async connect() {
        try {
            // First, establish a session by making any request to get session ID
            await this.establishSession();
            
            // Then test connection by calling a simple tool
            const result = await this.sendRequest('tools/call', {
                name: 'ehr_get_schema',
                arguments: { format: 'json' }
            });
            
            if (result && !result.error) {
                this.connected = true;
                console.log('Connected! Schema tool test successful');
                return true;
            }
            console.error('Connection test failed:', result?.error);
            return false;
        } catch (error) {
            console.error('Connection error:', error);
            return false;
        }
    }

    async establishSession() {
        try {
            // Make a dummy request to establish session
            const response = await fetch(this.serverUrl, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Accept': 'application/json, text/event-stream',
                },
                body: JSON.stringify({
                    jsonrpc: '2.0',
                    method: 'tools/call',
                    params: { name: 'ehr_get_schema', arguments: { format: 'json' } },
                    id: ++this.requestId
                })
            });

            // Extract session ID from response headers
            this.sessionId = response.headers.get('mcp-session-id');
            console.log('Got session ID:', this.sessionId);
            
            if (!this.sessionId) {
                throw new Error('No session ID received from server');
            }
        } catch (error) {
            console.error('Failed to establish session:', error);
            throw error;
        }
    }

    async callTool(toolName, args) {
        if (!this.connected) {
            throw new Error('Not connected to server');
        }

        try {
            const result = await this.sendRequest('tools/call', {
                name: toolName,
                arguments: args
            });
            
            if (result.error) {
                throw new Error(result.error.message || 'Unknown error');
            }

            return result.result;
        } catch (error) {
            console.error('Tool call error:', error);
            throw error;
        }
    }

    async sendRequest(method, params) {
        const requestId = ++this.requestId;
        
        const headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json, text/event-stream',
        };
        
        // Include session ID if we have it
        if (this.sessionId) {
            headers['mcp-session-id'] = this.sessionId;
        }
        
        const response = await fetch(this.serverUrl, {
            method: 'POST',
            headers: headers,
            body: JSON.stringify({
                jsonrpc: '2.0',
                method: method,
                params: params,
                id: requestId
            })
        });

        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        // Handle Server-Sent Events response or regular JSON
        const text = await response.text();
        
        // Try to parse as SSE first
        const lines = text.split('\n');
        for (const line of lines) {
            if (line.startsWith('data: ')) {
                try {
                    const data = JSON.parse(line.substring(6));
                    if (data.id === requestId) {
                        return data;
                    }
                } catch (e) {
                    // Continue to next line
                }
            }
        }
        
        // If no SSE data found, try parsing as regular JSON
        try {
            const data = JSON.parse(text);
            if (data.id === requestId) {
                return data;
            }
        } catch (e) {
            // Not JSON either
        }
        
        throw new Error('No matching response found');
    }
}

// Global variables
let client = null;
let isConnected = false;

// Connection management
async function toggleConnection() {
    const serverUrl = document.getElementById('server-url').value;
    const connectBtn = document.getElementById('connect-btn');
    const statusIndicator = document.getElementById('status-indicator');
    const statusText = document.getElementById('status-text');

    if (!isConnected) {
        client = new MCPClient(serverUrl);
        const connected = await client.connect();
        
        if (connected) {
            isConnected = true;
            connectBtn.textContent = 'Disconnect';
            statusIndicator.className = 'status-indicator connected';
            statusText.textContent = 'Connected';
            showMessage('Connected to MCP server', 'success');
        } else {
            showMessage('Failed to connect to server', 'error');
        }
    } else {
        client = null;
        isConnected = false;
        connectBtn.textContent = 'Connect';
        statusIndicator.className = 'status-indicator';
        statusText.textContent = 'Disconnected';
        showMessage('Disconnected from server', 'info');
    }
}

// Tab management
function showTab(tabName) {
    // Hide all tabs
    document.querySelectorAll('.tab-content').forEach(tab => {
        tab.classList.remove('active');
    });
    document.querySelectorAll('.tab-button').forEach(btn => {
        btn.classList.remove('active');
    });
    
    // Show selected tab
    document.getElementById(`${tabName}-tab`).classList.add('active');
    event.target.classList.add('active');
}

// Tool functions
async function getPatientInfo() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const patientId = document.getElementById('patient-id').value;
    const format = document.getElementById('patient-format').value;
    
    // Get selected include options
    const includeCheckboxes = document.querySelectorAll('input[name="include"]:checked');
    const include = Array.from(includeCheckboxes).map(cb => cb.value);

    if (!patientId) {
        showMessage('Please enter a patient ID', 'error');
        return;
    }

    showLoading(true);
    try {
        const result = await client.callTool('ehr_patient', {
            subject_id: patientId,
            include: include.length > 0 ? include : ['demographics'],
            format: format
        });
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function searchNotes() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const query = document.getElementById('search-query').value;
    const searchType = document.getElementById('search-type').value;
    const patientId = document.getElementById('search-patient-id').value;
    const admissionId = document.getElementById('search-admission-id').value;
    const limit = parseInt(document.getElementById('search-limit').value);
    const format = document.getElementById('search-format').value;

    if (!query) {
        showMessage('Please enter a search query', 'error');
        return;
    }

    showLoading(true);
    try {
        const args = {
            query: query,
            search_type: searchType,
            limit: limit,
            format: format
        };
        
        if (patientId) args.subject_id = patientId;
        if (admissionId) args.admission_id = admissionId;

        const result = await client.callTool('ehr_search_notes', args);
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function listDiagnoses() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const patientId = document.getElementById('diagnoses-patient-id').value;
    const admissionId = document.getElementById('diagnoses-admission-id').value;
    const limit = parseInt(document.getElementById('diagnoses-limit').value);
    const format = document.getElementById('diagnoses-format').value;

    showLoading(true);
    try {
        const args = {
            limit: limit,
            format: format
        };
        
        if (patientId) args.subject_id = patientId;
        if (admissionId) args.admission_id = admissionId;

        const result = await client.callTool('ehr_list_diagnoses', args);
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function listMedications() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const patientId = document.getElementById('medications-patient-id').value;
    const admissionId = document.getElementById('medications-admission-id').value;
    const limit = parseInt(document.getElementById('medications-limit').value);
    const format = document.getElementById('medications-format').value;

    showLoading(true);
    try {
        const args = {
            limit: limit,
            format: format
        };
        
        if (patientId) args.subject_id = patientId;
        if (admissionId) args.admission_id = admissionId;

        const result = await client.callTool('ehr_list_medications', args);
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function listProcedures() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const patientId = document.getElementById('procedures-patient-id').value;
    const admissionId = document.getElementById('procedures-admission-id').value;
    const limit = parseInt(document.getElementById('procedures-limit').value);
    const format = document.getElementById('procedures-format').value;

    showLoading(true);
    try {
        const args = {
            limit: limit,
            format: format
        };
        
        if (patientId) args.subject_id = patientId;
        if (admissionId) args.admission_id = admissionId;

        const result = await client.callTool('ehr_list_procedures', args);
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function listLabEvents() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const patientId = document.getElementById('lab-patient-id').value;
    const admissionId = document.getElementById('lab-admission-id').value;
    const limit = parseInt(document.getElementById('lab-limit').value);
    const format = document.getElementById('lab-format').value;

    showLoading(true);
    try {
        const args = {
            limit: limit,
            format: format
        };
        
        if (patientId) args.subject_id = patientId;
        if (admissionId) args.admission_id = admissionId;

        const result = await client.callTool('ehr_list_lab_events', args);
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function naturalQuery() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const query = document.getElementById('natural-query').value;
    const limit = parseInt(document.getElementById('natural-limit').value);
    const format = document.getElementById('natural-format').value;

    if (!query) {
        showMessage('Please enter a question', 'error');
        return;
    }

    showLoading(true);
    try {
        const result = await client.callTool('ehr_natural_query', {
            query: query,
            limit: limit,
            format: format
        });
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

async function getSchema() {
    if (!isConnected) {
        showMessage('Please connect to the server first', 'error');
        return;
    }

    const format = document.getElementById('schema-format').value;

    showLoading(true);
    try {
        const result = await client.callTool('ehr_get_schema', {
            format: format
        });
        displayResults(result, format);
    } catch (error) {
        showMessage(`Error: ${error.message}`, 'error');
    } finally {
        showLoading(false);
    }
}

// Display functions
function displayResults(result, format) {
    const resultsDiv = document.getElementById('results');
    const resultsInfo = document.getElementById('results-info');
    
    // Clear previous results
    resultsDiv.innerHTML = '';
    
    if (!result || !result.content || result.content.length === 0) {
        resultsDiv.innerHTML = '<p class="no-results">No results found</p>';
        resultsInfo.textContent = 'No results';
        return;
    }

    // Get the actual content
    const content = result.content[0];
    
    if (format === 'json') {
        // Parse and display JSON
        try {
            const data = typeof content.text === 'string' ? JSON.parse(content.text) : content.text;
            resultsDiv.innerHTML = `<pre class="json-results">${JSON.stringify(data, null, 2)}</pre>`;
            
            // Update results info
            if (Array.isArray(data)) {
                resultsInfo.textContent = `${data.length} results`;
            } else if (data.results && Array.isArray(data.results)) {
                resultsInfo.textContent = `${data.results.length} results`;
            } else {
                resultsInfo.textContent = 'Results loaded';
            }
        } catch (e) {
            resultsDiv.innerHTML = `<pre class="json-results">${content.text}</pre>`;
            resultsInfo.textContent = 'Results loaded';
        }
    } else if (format === 'markdown') {
        // Display markdown as HTML (basic conversion)
        const html = convertMarkdownToHTML(content.text);
        resultsDiv.innerHTML = `<div class="markdown-results">${html}</div>`;
        resultsInfo.textContent = 'Results loaded';
    } else {
        // Display as plain text
        resultsDiv.innerHTML = `<pre class="text-results">${content.text}</pre>`;
        resultsInfo.textContent = 'Results loaded';
    }
}

function convertMarkdownToHTML(markdown) {
    // Basic markdown to HTML conversion
    let html = markdown
        .replace(/^### (.*$)/gim, '<h3>$1</h3>')
        .replace(/^## (.*$)/gim, '<h2>$1</h2>')
        .replace(/^# (.*$)/gim, '<h1>$1</h1>')
        .replace(/^\* (.+)/gim, '<li>$1</li>')
        .replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>')
        .replace(/\*(.+?)\*/g, '<em>$1</em>')
        .replace(/\n\n/g, '</p><p>')
        .replace(/\n/g, '<br>');
    
    // Wrap lists
    html = html.replace(/(<li>.*<\/li>)/s, '<ul>$1</ul>');
    
    // Wrap in paragraphs
    if (!html.startsWith('<')) {
        html = '<p>' + html + '</p>';
    }
    
    return html;
}

function showLoading(show) {
    document.getElementById('loading').style.display = show ? 'flex' : 'none';
}

function clearResults() {
    document.getElementById('results').innerHTML = '';
    document.getElementById('results-info').textContent = '';
}

function showMessage(message, type) {
    // Create a temporary message element
    const messageDiv = document.createElement('div');
    messageDiv.className = `message ${type}`;
    messageDiv.textContent = message;
    
    document.body.appendChild(messageDiv);
    
    // Remove after 3 seconds
    setTimeout(() => {
        messageDiv.remove();
    }, 3000);
}

// Initialize on page load
document.addEventListener('DOMContentLoaded', () => {
    // Set default server URL
    const serverUrl = document.getElementById('server-url');
    if (!serverUrl.value) {
        serverUrl.value = 'http://localhost:8080/mcp/';
    }
});
</file>

<file path="demo/README.md">
# Neo4j MCP Server Demo

An interactive web interface for testing and exploring the Neo4j MCP (Model Context Protocol) server capabilities.

## Overview

This demo provides a user-friendly HTML interface to interact with all the Neo4j MCP server tools without needing to set up a full MCP client. It's perfect for:

- Testing the server functionality
- Exploring the available tools
- Demonstrating capabilities to stakeholders
- Debugging and development

## Prerequisites

1. **Neo4j Database**
   - Neo4j instance running with MIMIC-III or MIMIC-IV data loaded
   - Proper indexes and constraints configured

2. **Python Environment**
   - Python 3.8 or higher
   - Neo4j MCP server installed (`pip install mcp-server-neo4j-ehr` or `pip install -e .` from project root)
   - MCP library installed (`pip install mcp`)

3. **Environment Configuration**
   Create a `.env` file in the project root with:
   ```bash
   NEO4J_URI=bolt://localhost:7687
   NEO4J_USERNAME=neo4j
   NEO4J_PASSWORD=your_password
   NEO4J_DATABASE=neo4j
   
   # Optional - Required for natural language queries
   OPENAI_API_KEY=your_openai_api_key
   
   # Optional - For semantic search
   EMBEDDING_MODEL=text-embedding-3-small
   ```

## Quick Start

### Option 1: Using uv (Recommended)

**Start the MCP Server in stdio mode (default):**
```bash
uv run mcp-server-neo4j-ehr --neo4j-password your_password
```

**Start the MCP Server in HTTP mode:**
```bash
uv run mcp-server-neo4j-ehr \
  --neo4j-password your_password \
  --transport http \
  --host 127.0.0.1 \
  --port 8080
```

**With all options:**
```bash
uv run mcp-server-neo4j-ehr \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-username neo4j \
  --neo4j-password your_password \
  --neo4j-database neo4j \
  --openai-api-key your_openai_key \
  --transport http \
  --host 127.0.0.1 \
  --port 8080
```

### Option 2: Using Python Module

**Start the MCP Server in stdio mode:**
```bash
python -m mcp_server_neo4j_ehr \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-username neo4j \
  --neo4j-password your_password \
  --transport stdio
```

**Start the MCP Server in HTTP mode:**
```bash
python -m mcp_server_neo4j_ehr \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-username neo4j \
  --neo4j-password your_password \
  --transport http \
  --host 127.0.0.1 \
  --port 8080
```

### Option 3: Legacy HTTP Server Script (if available)
```bash
cd demo
python run_http_server.py
```

## Testing with MCP Inspector

Once your server is running, you can test it with the MCP Inspector:

**For stdio transport:**
```bash
npx @modelcontextprotocol/inspector python -m mcp_server_neo4j_ehr \
  --neo4j-uri bolt://localhost:7687 \
  --neo4j-username neo4j \
  --neo4j-password your_password \
  --transport stdio
```

**For HTTP transport:**
```bash
# First start your server with HTTP transport, then:
npx @modelcontextprotocol/inspector http://127.0.0.1:8080/mcp/
```

## Using the Web Demo

1. **Start the Server in HTTP Mode** (see commands above)

2. **Open the Demo Interface**
   - Open `demo/index.html` in your web browser
   - Or serve it with a local web server:
     ```bash
     python -m http.server 8000
     # Then open http://localhost:8000/index.html
     ```

3. **Connect to the Server**
   - Click the "Connect" button in the interface
   - The status indicator should turn green when connected

## Command Line Options

See all available options:
```bash
uv run mcp-server-neo4j-ehr --help
```

Available options include:
- `--neo4j-uri`: Neo4j connection URI (default: bolt://localhost:7687)
- `--neo4j-username`: Neo4j username (default: neo4j)
- `--neo4j-password`: Neo4j password (required)
- `--neo4j-database`: Neo4j database name (default: neo4j)
- `--openai-api-key`: OpenAI API key for natural language queries
- `--transport`: Transport type (stdio, http, sse) (default: stdio)
- `--host`: Host for HTTP/SSE transport (default: 127.0.0.1)
- `--port`: Port for HTTP/SSE transport (default: 8000)
- `--path`: Path for HTTP transport (default: /mcp/)

## Testing the Demo

Run the test suite to verify everything is working:
```bash
cd demo
python test_demo.py
```

Check what data is in your database:
```bash
cd demo
python check_data.py
```

## Using the Demo

### Available Tools

1. **Patient Information**
   - Get comprehensive patient data
   - Select which information to include (demographics, admissions, diagnoses, etc.)
   - Sample patient IDs from your database: 10461137, 11578849, 12017557, 14037695

2. **Search Clinical Notes**
   - Text search: Find notes containing specific terms
   - Semantic search: Find notes semantically similar to your query
   - Filter by patient or admission

3. **List Diagnoses**
   - View all diagnoses or filter by patient/admission
   - See ICD-9 codes and descriptions

4. **List Medications**
   - Browse prescribed medications
   - Filter by patient or admission

5. **List Procedures**
   - View medical procedures performed
   - Filter by patient or admission

6. **List Lab Events**
   - See laboratory test results
   - Filter by patient or admission

7. **Natural Language Query**
   - Ask questions in plain English
   - Requires OpenAI API key
   - Examples:
     - "Which patients had both diabetes and hypertension?"
     - "Show me the most common diagnoses"
     - "Find patients with abnormal lab values"

8. **Database Schema**
   - View the complete Neo4j database schema
   - Understand node types and relationships

### Output Formats

Each tool supports three output formats:
- **JSON**: Raw data format, ideal for developers
- **Table**: Formatted tables (when applicable)
- **Markdown**: Human-readable formatted text

## Testing Scenarios

### Basic Patient Lookup
1. Enter patient ID: `10461137`
2. Check "Demographics" only
3. Click "Get Patient Info"

### Comprehensive Patient Record
1. Enter patient ID: `10461137`
2. Check all include options
3. Set format to "Markdown"
4. Click "Get Patient Info"

### Text Search Example
1. Go to "Search Notes" tab
2. Enter query: "chest pain"
3. Set search type to "Text Search"
4. Click "Search Notes"

### Natural Language Query Example
1. Go to "Natural Query" tab
2. Enter: "Which patients had pneumonia?"
3. Click "Ask Question"

## Troubleshooting

### Connection Issues
- Ensure the MCP server is running (`python run_http_server.py`)
- Check the server URL (default: `http://localhost:8080`)
- Look for error messages in the server console

### No Results
- Verify Neo4j is running and accessible
- Check that MIMIC data is loaded
- Confirm patient IDs exist in the database
- Review server logs for query errors

### Natural Query Not Working
- Ensure `OPENAI_API_KEY` is set in environment
- Check for API key validity
- Monitor usage limits

### CORS Errors
- Make sure you're using the HTTP server script provided
- Don't open the HTML file directly with `file://` protocol
- Use a local web server if needed

## Development

### Project Structure
```
demo/
├── index.html          # Main interface
├── mcp-client.js      # JavaScript MCP client
├── styles.css         # Styling
├── run_http_server.py # HTTP server script
└── README.md          # This file
```

### Extending the Demo

To add new features:
1. Add UI elements in `index.html`
2. Implement client functions in `mcp-client.js`
3. Style with `styles.css`

### Debugging

Enable browser developer console to see:
- Network requests to the MCP server
- Response data and errors
- JavaScript console logs

## Security Notes

- This demo is for development/testing only
- CORS is enabled for all origins (*)
- Don't expose to public internet without proper security
- Sanitize inputs in production environments

## Resources

- [MCP Documentation](https://modelcontextprotocol.io/docs)
- [Neo4j Python Driver](https://neo4j.com/docs/python-manual/current/)
- [MIMIC Database](https://mimic.mit.edu/)
- [Project Repository](https://github.com/your-repo/neo4j-mcp)
</file>

<file path="demo/run_http_server.py">
#!/usr/bin/env python3
"""
HTTP Server for Neo4j MCP Server Demo

This script runs the Neo4j MCP server in HTTP mode with CORS enabled,
allowing the HTML demo interface to connect and interact with it.
"""

import logging
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Add the parent directory to the Python path so we can import the MCP server
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

# Load environment variables from .env file
env_path = parent_dir / '.env'
if env_path.exists():
    load_dotenv(env_path)
    print(f"✅ Loaded environment from {env_path}")
else:
    print(f"⚠️  No .env file found at {env_path}")

try:
    from src.mcp_server_neo4j_ehr.server import main as server_main
except ImportError:
    print("Error: Neo4j MCP server not found. Please ensure the server is properly installed.")
    print("Try running: pip install -e . from the project root directory")
    sys.exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def run_http_server():
    """Run the MCP server in HTTP mode with CORS enabled."""
    
    # Check for required environment variables
    required_vars = ['NEO4J_URI', 'NEO4J_USERNAME', 'NEO4J_PASSWORD']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
        logger.info("Please set these variables in your .env file or environment")
        sys.exit(1)
    
    # Optional environment variables
    if not os.getenv('OPENAI_API_KEY'):
        logger.warning("OPENAI_API_KEY not set. Natural language queries will not work.")
    
    try:
        # Get environment variables
        neo4j_uri = os.getenv('NEO4J_URI', 'bolt://localhost:7687')
        neo4j_username = os.getenv('NEO4J_USERNAME', 'neo4j')
        neo4j_password = os.getenv('NEO4J_PASSWORD')
        neo4j_database = os.getenv('NEO4J_DATABASE', 'neo4j')
        openai_api_key = os.getenv('OPENAI_API_KEY')
        
        host = "localhost"
        port = 8080
        
        logger.info(f"Starting HTTP server on http://{host}:{port}")
        logger.info("CORS is enabled for all origins (*)") 
        logger.info("Press Ctrl+C to stop the server")
        
        # Use the updated server main function
        server_main(
            neo4j_uri=neo4j_uri,
            neo4j_username=neo4j_username,
            neo4j_password=neo4j_password,
            neo4j_database=neo4j_database,
            openai_api_key_param=openai_api_key,
            transport="http",
            host=host,
            port=port,
            path="/mcp/"
        )
            
    except Exception as e:
        logger.error(f"Failed to start server: {e}")
        sys.exit(1)

def main():
    """Main entry point."""
    print("\n🚀 Neo4j MCP Server - HTTP Mode\n")
    print("This server allows the HTML demo interface to connect to the Neo4j MCP server.")
    print("\nMake sure you have:")
    print("1. Neo4j running with MIMIC data loaded")
    print("2. Environment variables configured (.env file)")
    print("3. Required Python packages installed\n")
    
    try:
        run_http_server()
    except KeyboardInterrupt:
        print("\n\nServer stopped by user")
    except Exception as e:
        logger.error(f"Server error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
</file>

<file path="src/mcp_server_neo4j_ehr/modules/constants.py">
"""Constants for the Neo4j EHR MCP Server."""

# Default values
DEFAULT_LIMIT = 20
DEFAULT_NOTE_SEARCH_LIMIT = 5
DEFAULT_NATURAL_QUERY_LIMIT = 10

# Output formats
OUTPUT_FORMAT_JSON = "json"
OUTPUT_FORMAT_TABLE = "table"
OUTPUT_FORMAT_TEXT = "text"
OUTPUT_FORMAT_MARKDOWN = "markdown"

# Note types
NOTE_TYPE_DISCHARGE = "discharge"
NOTE_TYPE_RADIOLOGY = "radiology"
NOTE_TYPE_ALL = "all"

# Embedding model
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMENSION = 1536

# Neo4j indexes
NOTE_EMBEDDINGS_INDEX = "note_embeddings"

# System prompts for natural language queries
NATURAL_QUERY_SYSTEM_PROMPT = """You are a Neo4j Cypher query expert specialized in medical/EHR data.
You will be given a complete database schema with all node properties and a natural language question.
Generate a valid Cypher query that answers the question. Only return the Cypher query, no explanations.

Important guidelines:
- Use appropriate WHERE clauses for filtering
- ALWAYS include LIMIT clauses to prevent large result sets
- Use indexed properties in WHERE clauses when possible for better performance
- Use proper node labels and relationship types from the schema
- Return meaningful data that directly answers the question
- For text searches in notes, use: WHERE toLower(n.text) CONTAINS toLower('search term')
- For date comparisons, use proper datetime() functions
- For finding abnormal lab results: WHERE l.flag IS NOT NULL AND l.flag <> 'normal'
- Prefer using unique identifiers (subject_id, hadm_id, note_id) when available
- Include relevant properties in RETURN statements to provide context

Example patterns:
- Patient data: MATCH (p:Patient {subject_id: '10000032'})
- Patient admissions: MATCH (p:Patient {subject_id: '10000032'})-[:HAS_ADMISSION]->(a:Admission)
- Admission diagnoses: MATCH (a:Admission {hadm_id: '12345'})-[:HAS_DIAGNOSIS]->(d:Diagnosis)
- Lab results: MATCH (l:LabEvent) WHERE l.subject_id = '10000032' AND l.flag = 'abnormal'
"""
</file>

<file path="src/mcp_server_neo4j_ehr/modules/db_connection.py">
"""Database connection management for Neo4j."""

import logging
from typing import Optional, Dict, Any, List
from neo4j import AsyncDriver, AsyncGraphDatabase, AsyncResult
from neo4j.exceptions import Neo4jError

logger = logging.getLogger(__name__)


class Neo4jConnection:
    """Manages Neo4j database connections and queries."""
    
    def __init__(self, driver: AsyncDriver, database: str = "neo4j"):
        self.driver = driver
        self.database = database
    
    async def execute_read(self, query: str, parameters: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Execute a read query and return results as a list of dictionaries."""
        try:
            async with self.driver.session(database=self.database) as session:
                result = await session.execute_read(
                    self._run_query, query, parameters or {}
                )
                return result
        except Neo4jError as e:
            logger.error(f"Neo4j read error: {e}")
            raise
    
    async def execute_write(self, query: str, parameters: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Execute a write query and return results as a list of dictionaries."""
        try:
            async with self.driver.session(database=self.database) as session:
                result = await session.execute_write(
                    self._run_query, query, parameters or {}
                )
                return result
        except Neo4jError as e:
            logger.error(f"Neo4j write error: {e}")
            raise
    
    @staticmethod
    async def _run_query(tx, query: str, parameters: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Run a query within a transaction."""
        result = await tx.run(query, parameters)
        records = await result.data()
        return records
    
    async def test_connection(self) -> bool:
        """Test the database connection."""
        try:
            await self.execute_read("RETURN 1 as test")
            return True
        except Exception as e:
            logger.error(f"Connection test failed: {e}")
            return False
    
    async def get_schema(self) -> Dict[str, Any]:
        """Get the database schema information - hardcoded for EHR data."""
        schema = {
            "nodes": [
                {
                    "label": "Patient",
                    "properties": [
                        "subject_id",  # unique, indexed
                        "gender",      # indexed
                        "anchor_age",
                        "anchor_year",
                        "anchor_year_group",
                        "dod"         # date of death
                    ],
                    "property_types": {
                        "subject_id": "string (unique, indexed)",
                        "gender": "string (indexed)",
                        "anchor_age": "integer",
                        "anchor_year": "integer", 
                        "anchor_year_group": "string",
                        "dod": "datetime"
                    }
                },
                {
                    "label": "Admission",
                    "properties": [
                        "hadm_id",            # unique, indexed
                        "admission_type",     # indexed
                        "admittime",
                        "dischtime",
                        "deathtime",
                        "admission_location",
                        "discharge_location",
                        "insurance",
                        "language",
                        "marital_status",
                        "race",
                        "edregtime",
                        "edouttime",
                        "hospital_expire_flag",
                        "admit_provider_id"
                    ],
                    "property_types": {
                        "hadm_id": "string (unique, indexed)",
                        "admission_type": "string (indexed)",
                        "admittime": "datetime",
                        "dischtime": "datetime",
                        "deathtime": "datetime",
                        "admission_location": "string",
                        "discharge_location": "string",
                        "insurance": "string",
                        "language": "string",
                        "marital_status": "string",
                        "race": "string",
                        "edregtime": "datetime",
                        "edouttime": "datetime",
                        "hospital_expire_flag": "integer",
                        "admit_provider_id": "string"
                    }
                },
                {
                    "label": "DischargeNote",
                    "properties": [
                        "note_id",       # unique, indexed
                        "hadm_id",       # indexed
                        "subject_id",    # indexed
                        "note_type",     # indexed
                        "text",          # indexed
                        "note_seq",
                        "charttime",
                        "storetime",
                        "embedding",
                        "embedding_model",
                        "embedding_created"
                    ],
                    "property_types": {
                        "note_id": "string (unique, indexed)",
                        "hadm_id": "string (indexed)",
                        "subject_id": "string (indexed)",
                        "note_type": "string (indexed)",
                        "text": "string (indexed)",
                        "note_seq": "integer",
                        "charttime": "datetime",
                        "storetime": "datetime",
                        "embedding": "float[]",
                        "embedding_model": "string",
                        "embedding_created": "datetime"
                    }
                },
                {
                    "label": "RadiologyReport",
                    "properties": [
                        "note_id",       # unique, indexed
                        "hadm_id",       # indexed
                        "subject_id",    # indexed
                        "note_type",     # indexed
                        "text",          # indexed
                        "note_seq",
                        "charttime",
                        "storetime",
                        "embedding",
                        "embedding_model",
                        "embedding_created"
                    ],
                    "property_types": {
                        "note_id": "string (unique, indexed)",
                        "hadm_id": "string (indexed)",
                        "subject_id": "string (indexed)",
                        "note_type": "string (indexed)",
                        "text": "string (indexed)",
                        "note_seq": "integer",
                        "charttime": "datetime",
                        "storetime": "datetime",
                        "embedding": "float[]",
                        "embedding_model": "string",
                        "embedding_created": "datetime"
                    }
                },
                {
                    "label": "LabEvent",
                    "properties": [
                        "lab_event_id",    # unique, indexed
                        "subject_id",      # indexed
                        "hadm_id",         # indexed
                        "charttime",       # indexed
                        "label",           # indexed
                        "itemid",          # indexed
                        "category",        # indexed
                        "flag",            # indexed
                        "value",           # indexed
                        "comments",        # indexed
                        "ref_range_upper",
                        "ref_range_lower",
                        "fluid",
                        "priority",
                        "storetime"
                    ],
                    "property_types": {
                        "lab_event_id": "string (unique, indexed)",
                        "subject_id": "string (indexed)",
                        "hadm_id": "string (indexed)",
                        "charttime": "datetime (indexed)",
                        "label": "string (indexed)",
                        "itemid": "string (indexed)",
                        "category": "string (indexed)",
                        "flag": "string (indexed)",
                        "value": "string (indexed)",
                        "comments": "string (indexed)",
                        "ref_range_upper": "float",
                        "ref_range_lower": "float",
                        "fluid": "string",
                        "priority": "string",
                        "storetime": "datetime"
                    }
                },
                {
                    "label": "Medication",
                    "properties": [
                        "medication",    # indexed
                        "route",         # indexed
                        "hadm_id",
                        "subject_id",
                        "frequency",
                        "verifiedtime"
                    ],
                    "property_types": {
                        "medication": "string (indexed)",
                        "route": "string (indexed)",
                        "hadm_id": "string",
                        "subject_id": "string",
                        "frequency": "string",
                        "verifiedtime": "datetime"
                    }
                },
                {
                    "label": "Diagnosis",
                    "properties": [
                        "icd_code",      # indexed
                        "long_title",    # indexed
                        "synonyms",      # indexed
                        "hadm_id",
                        "subject_id",
                        "seq_num",
                        "icd_version"
                    ],
                    "property_types": {
                        "icd_code": "string (indexed)",
                        "long_title": "string (indexed)",
                        "synonyms": "string[] (indexed)",
                        "hadm_id": "string",
                        "subject_id": "string",
                        "seq_num": "integer",
                        "icd_version": "integer"
                    }
                },
                {
                    "label": "Procedure",
                    "properties": [
                        "icd_code",      # indexed
                        "long_title",    # indexed
                        "hadm_id",
                        "seq_num",
                        "chartdate",
                        "icd_version"
                    ],
                    "property_types": {
                        "icd_code": "string (indexed)",
                        "long_title": "string (indexed)",
                        "hadm_id": "string",
                        "seq_num": "integer",
                        "chartdate": "datetime",
                        "icd_version": "integer"
                    }
                }
            ],
            "relationships": [
                {"relationshipType": "HAS_ADMISSION"},
                {"relationshipType": "INCLUDES_DISCHARGE_NOTE"},
                {"relationshipType": "INCLUDES_RADIOLOGY_REPORT"},
                {"relationshipType": "INCLUDES_LAB_EVENT"},
                {"relationshipType": "HAS_DIAGNOSIS"},
                {"relationshipType": "HAS_PROCEDURE"},
                {"relationshipType": "HAS_MEDICATION"}
            ],
            "constraints": [],  # Will be populated if needed
            "indexes": []       # Will be populated if needed
        }
        
        return schema
    
    async def close(self):
        """Close the database connection."""
        if self.driver:
            await self.driver.close()


def create_neo4j_driver(uri: str, username: str, password: str) -> AsyncDriver:
    """Create a Neo4j async driver instance."""
    return AsyncGraphDatabase.driver(uri, auth=(username, password))
</file>

<file path="src/mcp_server_neo4j_ehr/__main__.py">
"""Entry point for the Neo4j EHR MCP Server."""

import os
import argparse
from dotenv import load_dotenv
from .server import main as server_main

# Load environment variables
load_dotenv()


def main():
    """Main entry point for the package."""
    parser = argparse.ArgumentParser(description="Neo4j EHR MCP Server")
    parser.add_argument("--neo4j-uri", help="Neo4j connection URI", 
                        default=os.getenv("NEO4J_URI", "bolt://localhost:7687"))
    parser.add_argument("--neo4j-username", help="Neo4j username", 
                        default=os.getenv("NEO4J_USERNAME", "neo4j"))
    parser.add_argument("--neo4j-password", help="Neo4j password", 
                        default=os.getenv("NEO4J_PASSWORD", "password"))
    parser.add_argument("--neo4j-database", help="Neo4j database name", 
                        default=os.getenv("NEO4J_DATABASE", "neo4j"))
    parser.add_argument("--openai-api-key", help="OpenAI API key for semantic search", 
                        default=os.getenv("OPENAI_API_KEY"))
    parser.add_argument("--transport", default="stdio", 
                        choices=["stdio", "sse", "http"],
                        help="Transport type (stdio, sse, http)")
    parser.add_argument("--host", default="127.0.0.1", help="Host for HTTP transport")
    parser.add_argument("--port", type=int, default=8000, help="Port for HTTP transport")
    parser.add_argument("--path", default="/mcp/", help="Path for HTTP transport")
    
    args = parser.parse_args()
    
    # Validate required parameters
    if not args.neo4j_password:
        parser.error("Neo4j password is required (via --neo4j-password or NEO4J_PASSWORD env var)")
    
    # Run the server
    server_main(
        args.neo4j_uri,
        args.neo4j_username,
        args.neo4j_password,
        args.neo4j_database,
        args.openai_api_key,
        args.transport,
        args.host,
        args.port,
        args.path
    )


if __name__ == "__main__":
    main()
</file>

<file path="CHANGELOG.md">
# Changelog

All notable changes to the Neo4j EHR MCP Server project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Changed
- **BREAKING**: Refactored `ehr_search_notes` tool → `ehr_get_clinical_notes`
  - Removed `query` parameter (no more text-based searching)
  - Removed `semantic` parameter (no more AI-powered semantic search)
  - Simplified to retrieve notes by type, patient ID, or admission ID only
  - Results ordered by `charttime DESC` (most recent first)
  - Improved Claude Desktop integration with clearer parameter usage
- Tool separation: Use `ehr_get_clinical_notes` for simple retrieval, `ehr_natural_query` for content searches

### Added
- Comprehensive test suite with 71 tests covering all functionality
- Unit tests for all 8 MCP tools with mocked dependencies
- Integration tests that verify real Neo4j database interactions
- Test documentation in `tests/README.md` and `src/mcp_server_neo4j_ehr/tests/README.md`
- Debug script (`debug_natural_query.py`) for testing natural language queries interactively
- Enhanced logging in natural language query module to show:
  - Input queries
  - Generated Cypher queries from OpenAI
  - Query execution results
- DateTime conversion handling for Neo4j DateTime objects to Python datetime
- Test fixtures for common data types (patients, admissions, diagnoses, etc.)

### Changed
- Updated all Pydantic models to use `field_serializer` instead of deprecated `json_encoders`
- Fixed FastMCP tool registration tests to use `get_tools()` async method
- Updated integration tests to use actual patient IDs from test database
- Enhanced natural language query tests to display full outputs

### Fixed
- DateTime serialization issues when Neo4j returns DateTime objects
- OpenAI mock patches in tests to use correct import paths
- Test assertions for procedures when no data is found
- Pydantic v2 deprecation warnings

## [0.1.0] - 2024-01-24

### Added
- Initial implementation of Neo4j EHR MCP Server
- FastMCP-based server with 8 EHR query tools:
  - `ehr_patient` - Retrieve patient information
  - `ehr_search_notes` - Search clinical notes
  - `ehr_list_diagnoses` - List patient diagnoses
  - `ehr_list_lab_events` - List laboratory events
  - `ehr_list_medications` - List medications
  - `ehr_list_procedures` - List procedures
  - `ehr_natural_query` - Natural language to Cypher queries
  - `ehr_get_schema` - Get database schema
- Support for multiple output formats (JSON, table, markdown)
- Semantic search capabilities using OpenAI embeddings
- Natural language query processing with GPT-4
- Comprehensive data models for MIMIC-IV style EHR data
- Neo4j async driver integration
- Environment-based configuration
- Project documentation and specifications
</file>

<file path="pyproject.toml">
[project]
name = "mcp-server-neo4j-ehr"
version = "0.1.0"
description = "MCP server for querying a Neo4j EHR database."
readme = "README.md"
authors = [
    { name = "Your Name", email = "your@email.com" }
]
requires-python = ">=3.10"
dependencies = [
    "click>=8.1.7",
    "fastmcp>=2.0.0",
    "pydantic>=2.0.0",
    "neo4j>=5.0.0",
    "python-dotenv>=1.0.0",
    "openai>=1.0.0",
    "tabulate>=0.9.0",
]

[project.scripts]
mcp-server-neo4j-ehr = "mcp_server_neo4j_ehr.__main__:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.21.0",
    "pytest-mock>=3.11.0",
]
</file>

<file path="src/mcp_server_neo4j_ehr/modules/functionality/natural_query.py">
"""Natural language query functionality using LLM."""

import json
import logging
from typing import Any, Dict, List
from openai import OpenAI
from tabulate import tabulate

from ..db_connection import Neo4jConnection
from ..data_types import OutputFormat
from ..constants import (
    OUTPUT_FORMAT_JSON, OUTPUT_FORMAT_TABLE, OUTPUT_FORMAT_MARKDOWN,
    NATURAL_QUERY_SYSTEM_PROMPT
)

logger = logging.getLogger(__name__)


async def natural_query(
    db: Neo4jConnection,
    query: str,
    limit: int = 10,
    format: OutputFormat = OUTPUT_FORMAT_MARKDOWN,
    openai_api_key: str = None
) -> str:
    """Convert natural language query to Cypher and execute."""
    
    try:
        # Log the incoming natural language query
        logger.info(f"Natural language query: {query}")
        
        # First, get the database schema
        schema = await db.get_schema()
        schema_text = format_schema_for_llm(schema)
        logger.debug(f"Schema text sent to LLM: {schema_text[:500]}...")  # First 500 chars
        
        # Generate Cypher query using LLM
        client = OpenAI(api_key=openai_api_key)
        
        messages = [
            {"role": "system", "content": NATURAL_QUERY_SYSTEM_PROMPT},
            {"role": "user", "content": f"Database Schema:\n{schema_text}\n\nQuestion: {query}\n\nGenerate a Cypher query with LIMIT {limit}:"}
        ]
        
        logger.info("Sending query to OpenAI GPT-4...")
        response = client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=messages,
            temperature=0.1,
            max_tokens=500
        )
        
        cypher_query = response.choices[0].message.content.strip()
        logger.info(f"Raw LLM response: {cypher_query}")
        
        # Clean up the query (remove markdown code blocks if present)
        if cypher_query.startswith("```"):
            cypher_query = cypher_query.split("```")[1]
            if cypher_query.startswith("cypher"):
                cypher_query = cypher_query[6:]
        cypher_query = cypher_query.strip()
        
        logger.info(f"Cleaned Cypher query: {cypher_query}")
        
        # Execute the query
        try:
            results = await db.execute_read(cypher_query)
            logger.info(f"Query executed successfully. Result count: {len(results)}")
            if results and len(results) > 0:
                logger.debug(f"First result: {results[0]}")
        except Exception as e:
            logger.error(f"Error executing Cypher query: {e}")
            return json.dumps({
                "error": "Failed to execute generated query",
                "query": cypher_query,
                "details": str(e)
            })
        
        # Format results
        response_data = {
            "question": query,
            "cypher_query": cypher_query,
            "results": results,
            "count": len(results)
        }
        logger.info(f"Returning {len(results)} results for query: {query}")
        
        if format == OUTPUT_FORMAT_MARKDOWN:
            return format_natural_query_as_markdown(response_data)
        elif format == OUTPUT_FORMAT_TABLE:
            return format_natural_query_as_table(response_data)
        else:
            return json.dumps(response_data)
            
    except Exception as e:
        logger.error(f"Error in natural language query: {e}")
        return json.dumps({
            "error": "Failed to process natural language query",
            "details": str(e)
        })


def format_schema_for_llm(schema: Dict[str, Any]) -> str:
    """Format schema information for LLM context."""
    lines = []
    
    # Node labels with detailed property information
    lines.append("NODE TYPES AND PROPERTIES:")
    lines.append("(Note: Properties marked as 'indexed' should be preferred in WHERE clauses for better performance)")
    lines.append("")
    
    for node in schema.get("nodes", []):
        label = node.get("label", "Unknown")
        properties = node.get("properties", [])
        property_types = node.get("property_types", {})
        
        lines.append(f"Node: {label}")
        lines.append("Properties:")
        
        # Group properties by type for better understanding
        identifiers = []
        timestamps = []
        clinical_data = []
        other = []
        
        for prop in properties:
            prop_info = f"  - {prop}: {property_types.get(prop, 'string')}"
            
            # Categorize properties
            if prop in ["subject_id", "hadm_id", "note_id", "lab_event_id"]:
                identifiers.append(prop_info)
            elif "time" in prop or "date" in prop or prop == "dod":
                timestamps.append(prop_info)
            elif prop in ["diagnosis", "medication", "icd_code", "long_title", "label", "value", "flag", "text"]:
                clinical_data.append(prop_info)
            else:
                other.append(prop_info)
        
        if identifiers:
            lines.append("  Identifiers:")
            lines.extend(identifiers)
        if timestamps:
            lines.append("  Timestamps:")
            lines.extend(timestamps)
        if clinical_data:
            lines.append("  Clinical Data:")
            lines.extend(clinical_data)
        if other:
            lines.append("  Other:")
            lines.extend(other)
        
        lines.append("")
    
    # Relationships with cardinality
    lines.append("RELATIONSHIPS:")
    lines.append("- (Patient)-[:HAS_ADMISSION]->(Admission)  [1 patient : many admissions]")
    lines.append("- (Admission)-[:INCLUDES_DISCHARGE_NOTE]->(DischargeNote)  [1 admission : many notes]")
    lines.append("- (Admission)-[:INCLUDES_RADIOLOGY_REPORT]->(RadiologyReport)  [1 admission : many reports]")
    lines.append("- (Admission)-[:HAS_DIAGNOSIS]->(Diagnosis)  [1 admission : many diagnoses]")
    lines.append("- (Admission)-[:HAS_PROCEDURE]->(Procedure)  [1 admission : many procedures]")
    lines.append("- (Admission)-[:HAS_MEDICATION]->(Medication)  [1 admission : many medications]")
    lines.append("- (Admission)-[:INCLUDES_LAB_EVENT]->(LabEvent)  [1 admission : many lab events]")
    lines.append("")
    
    # Query guidelines
    lines.append("QUERY GUIDELINES:")
    lines.append("1. Use indexed properties in WHERE clauses when possible")
    lines.append("2. For text searches in notes, use: WHERE toLower(n.text) CONTAINS toLower('search term')")
    lines.append("3. For date comparisons, use: WHERE n.admittime >= datetime('2024-01-01')")
    lines.append("4. For finding abnormal lab results, check: WHERE l.flag IS NOT NULL AND l.flag <> 'normal'")
    lines.append("5. Always include LIMIT to prevent large result sets")
    lines.append("")
    
    # Common patterns
    lines.append("COMMON QUERY PATTERNS:")
    lines.append("- Patient with admissions: MATCH (p:Patient {subject_id: 'X'})-[:HAS_ADMISSION]->(a:Admission)")
    lines.append("- Admission with all clinical data: MATCH (a:Admission {hadm_id: 'X'})-[r]->(n)")
    lines.append("- Lab results for patient: MATCH (l:LabEvent) WHERE l.subject_id = 'X'")
    lines.append("- Diagnoses by ICD code: MATCH (d:Diagnosis) WHERE d.icd_code STARTS WITH 'I21'")
    
    return "\n".join(lines)


def format_natural_query_as_markdown(data: Dict[str, Any]) -> str:
    """Format natural query results as markdown."""
    lines = []
    
    lines.append(f"## Question\n{data['question']}\n")
    lines.append(f"## Generated Cypher Query\n```cypher\n{data['cypher_query']}\n```\n")
    lines.append(f"## Results ({data['count']} rows)\n")
    
    if data['results']:
        # Create table from results
        first_row = data['results'][0]
        headers = list(first_row.keys())
        
        lines.append("| " + " | ".join(headers) + " |")
        lines.append("| " + " | ".join(["-" * len(h) for h in headers]) + " |")
        
        for row in data['results']:
            values = [str(row.get(h, "")) for h in headers]
            lines.append("| " + " | ".join(values) + " |")
    else:
        lines.append("No results found.")
    
    return "\n".join(lines)


def format_natural_query_as_table(data: Dict[str, Any]) -> str:
    """Format natural query results as table."""
    output = []
    
    output.append(f"QUESTION: {data['question']}")
    output.append(f"\nCYPHER QUERY:\n{data['cypher_query']}")
    output.append(f"\nRESULTS ({data['count']} rows):")
    
    if data['results']:
        # Convert results to table
        headers = list(data['results'][0].keys())
        table_data = []
        
        for row in data['results']:
            table_data.append([str(row.get(h, "")) for h in headers])
        
        output.append(tabulate(table_data, headers=headers, tablefmt="grid"))
    else:
        output.append("No results found.")
    
    return "\n".join(output)
</file>

<file path="src/mcp_server_neo4j_ehr/server.py">
"""Main server implementation for Neo4j EHR MCP Server."""

import logging
from typing import Literal, Optional
from fastmcp import FastMCP
from neo4j import AsyncDriver

from .modules.db_connection import Neo4jConnection
from .modules.constants import *
from .modules.data_types import OutputFormat, NoteType
from .modules.functionality.patient import get_patient
from .modules.functionality.get_clinical_notes import get_clinical_notes
from .modules.functionality.list_diagnoses import list_diagnoses
from .modules.functionality.list_lab_events import list_lab_events
from .modules.functionality.list_medications import list_medications
from .modules.functionality.list_procedures import list_procedures
from .modules.functionality.natural_query import natural_query
from .modules.functionality.get_schema import get_schema

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create MCP server instance
mcp = FastMCP("mcp-server-neo4j-ehr")

# Global variables for database connection and OpenAI key
db_connection: Optional[Neo4jConnection] = None
openai_api_key: Optional[str] = None


@mcp.tool
async def ehr_patient(
    subject_id: str,
    include_admissions: bool = True,
    include_diagnoses: bool = False,
    include_procedures: bool = False,
    include_medications: bool = False,
    include_lab_events: bool = False,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """Get a comprehensive summary of a patient's record."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await get_patient(
        db_connection, subject_id, include_admissions, include_diagnoses,
        include_procedures, include_medications, include_lab_events, format
    )


@mcp.tool
async def ehr_get_clinical_notes(
    note_type: NoteType = NOTE_TYPE_ALL,
    limit: int = DEFAULT_NOTE_SEARCH_LIMIT,
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """Retrieve clinical notes by type (discharge or radiology).
    
    For discharge summaries: Use admission_id to get notes for a specific admission.
    For radiology reports: Use patient_id to get all imaging reports for a patient.
    To get all notes: Specify note_type and patient_id or admission_id.
    
    This tool returns ALL matching notes without filtering by content."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await get_clinical_notes(
        db_connection, note_type, limit,
        patient_id, admission_id, format
    )


@mcp.tool
async def ehr_list_diagnoses(
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    limit: int = DEFAULT_LIMIT,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List diagnoses for a patient or admission."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await list_diagnoses(db_connection, patient_id, admission_id, limit, format)


@mcp.tool
async def ehr_list_lab_events(
    patient_id: str,
    admission_id: Optional[str] = None,
    abnormal_only: bool = False,
    category: Optional[str] = None,
    limit: int = DEFAULT_LIMIT,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List lab events for a patient."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await list_lab_events(
        db_connection, patient_id, admission_id, abnormal_only,
        category, limit, format
    )


@mcp.tool
async def ehr_list_medications(
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    medication: Optional[str] = None,
    route: Optional[str] = None,
    limit: int = DEFAULT_LIMIT,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List medications for a patient or admission."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await list_medications(
        db_connection, patient_id, admission_id, medication,
        route, limit, format
    )


@mcp.tool
async def ehr_list_procedures(
    patient_id: Optional[str] = None,
    admission_id: Optional[str] = None,
    limit: int = DEFAULT_LIMIT,
    format: OutputFormat = OUTPUT_FORMAT_JSON
) -> str:
    """List procedures for a patient or admission."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await list_procedures(db_connection, patient_id, admission_id, limit, format)


@mcp.tool
async def ehr_natural_query(
    query: str,
    limit: int = DEFAULT_NATURAL_QUERY_LIMIT,
    format: OutputFormat = OUTPUT_FORMAT_MARKDOWN
) -> str:
    """Ask a question in natural language."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    if not openai_api_key:
        return '{"error": "OpenAI API key is required for natural language queries"}'
    return await natural_query(db_connection, query, limit, format, openai_api_key)


@mcp.tool
async def ehr_get_schema(
    format: OutputFormat = OUTPUT_FORMAT_MARKDOWN
) -> str:
    """Get the database schema."""
    if not db_connection:
        return '{"error": "Database connection not initialized"}'
    return await get_schema(db_connection, format)


def main(
    neo4j_uri: str,
    neo4j_username: str,
    neo4j_password: str,
    neo4j_database: str,
    openai_api_key_param: Optional[str] = None,
    transport: Literal["stdio", "sse", "http"] = "stdio",
    host: str = "127.0.0.1",
    port: int = 8000,
    path: str = "/mcp/",
) -> None:
    """Main entry point for the server."""
    global db_connection, openai_api_key
    
    # Import the driver creation function
    from .modules.db_connection import create_neo4j_driver
    
    # Create Neo4j driver
    driver = create_neo4j_driver(neo4j_uri, neo4j_username, neo4j_password)
    
    # Initialize global variables
    db_connection = Neo4jConnection(driver, neo4j_database)
    openai_api_key = openai_api_key_param
    
    # Run the server with correct parameters
    if transport == "stdio":
        mcp.run()
    elif transport == "http":
        mcp.run(transport="http", host=host, port=port, path=path)
    elif transport == "sse":
        mcp.run(transport="sse", host=host, port=port)
    else:
        raise ValueError(f"Unsupported transport: {transport}")
</file>

<file path="README.md">
# Neo4j MCP Server for EHR GraphRAG

This project provides a Model Context Protocol (MCP) server to interact with a Neo4j graph database containing Electronic Health Record (EHR) data, specifically modeled after the MIMIC-IV dataset. It allows users to query complex medical data using both structured commands and natural language.

## Overview

Querying large, interconnected EHR datasets can be challenging. This MCP server simplifies the process by providing a set of intuitive tools to:
- Retrieve detailed patient records.
- Perform semantic searches on clinical notes like discharge summaries and radiology reports.
- List specific clinical events like diagnoses, lab results, and medications.
- Translate natural language questions into executable Cypher queries against the graph.

This enables powerful GraphRAG (Retrieval-Augmented Generation) workflows where a Large Language Model (LLM) can be grounded with real-time, specific data from the EHR graph.

## Features

- **Natural Language Querying**: Ask complex questions in plain English. The server leverages an LLM that can inspect the graph schema to generate accurate Cypher queries.
- **Simple Note Retrieval**: Get discharge summaries or radiology reports by patient/admission ID without complex searching.
- **Structured API**: A robust set of commands for precise data retrieval (e.g., get a specific patient, list diagnoses for an admission).
- **Content-Based Search**: Use natural language queries to search within clinical notes and find specific medical information.
- **Schema Awareness**: Includes a tool to fetch the database schema, which is crucial for enabling an LLM to write accurate queries.
- **Flexible Output**: Get results in JSON for programmatic use or in human-readable tables and markdown.

## Prerequisites

- Python 3.9+
- `uv` (or `pip` and `venv`)
- A Neo4j AuraDB or local instance populated with data conforming to the [spec schema](specs/neo4j-mcp-v1.md).
- An OpenAI API key for semantic search and natural language processing.

## Quick Start

1. **Clone and install:**
   ```bash
   git clone https://github.com/your-username/neo4j-mcp.git
   cd neo4j-mcp
   uv pip install -e .
   ```

2. **Set up environment variables:**
   ```bash
   cp .env.example .env
   # Edit .env with your Neo4j and OpenAI credentials
   ```

3. **Test the connection:**
   ```bash
   uv run python examples/test_connection.py
   ```

4. **Run tests to verify everything works:**
   ```bash
   uv run pytest -k "not integration"  # Unit tests only
   uv run pytest  # All tests (requires database)
   ```

5. **Try natural language queries:**
   ```bash
   uv run python debug_natural_query.py "How many patients are in the database?"
   ```

## Installation

### Using pip

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/neo4j-mcp.git
    cd neo4j-mcp
    ```

2.  **Install the package:**
    ```bash
    pip install -e .
    ```

### Using uv (recommended)

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/neo4j-mcp.git
    cd neo4j-mcp
    ```

2.  **Install with uv:**
    ```bash
    uv pip install -e .
    ```

### Configuration

Set up environment variables by creating a `.env` file in the project root:

```env
# Neo4j connection settings
NEO4J_URI="neo4j+s://your-instance.databases.neo4j.io"
NEO4J_USERNAME="neo4j"
NEO4J_PASSWORD="your-password"
NEO4J_DATABASE="neo4j"

# OpenAI API key for semantic search and natural language queries
OPENAI_API_KEY="sk-..."
```

## Usage

### Running the Server

**Using stdio transport (default):**
```bash
uv run mcp-server-neo4j-ehr
```

**Using HTTP transport:**
```bash
uv run mcp-server-neo4j-ehr --transport http --port 8000
```

**With custom Neo4j connection:**
```bash
uv run mcp-server-neo4j-ehr --neo4j-uri bolt://localhost:7687 --neo4j-password mypassword
```

### MCP Client Configuration

To use this server with Claude Desktop, add it to your MCP settings:

```json
{
  "mcpServers": {
    "neo4j-ehr": {
      "command": "mcp-server-neo4j-ehr",
      "env": {
        "NEO4J_URI": "neo4j+s://your-instance.databases.neo4j.io",
        "NEO4J_USERNAME": "neo4j",
        "NEO4J_PASSWORD": "your-password",
        "NEO4J_DATABASE": "neo4j",
        "OPENAI_API_KEY": "sk-..."
      }
    }
  }
}
```

### Example Use Cases

- **Get a patient's full record:**
  ```
  ehr patient "10000032" --include-diagnoses=True --include-medications=True
  ```

- **Get the most recent discharge summary:**
  ```
  ehr get-clinical-notes --patient-id="10000032" --note-type=discharge --limit=1 --format=text
  ```

- **Ask a question in natural language:**
  ```
  ehr natural-query "What was the final diagnosis for patient 10000032's admission on 2124-08-07?"
  ```
  
- **Provide the database schema to an LLM to help it construct queries:**
  ```
  ehr get-schema
  ```

## API Reference

The following commands are available through the MCP server:

```
# Get a comprehensive summary of a patient's record
ehr patient <subject_id> \
    --include-admissions: bool = True \
    --include-diagnoses: bool = False \
    --include-procedures: bool = False \
    --include-medications: bool = False \
    --include-lab-events: bool = False \
    --format: json | table = json

# Retrieve clinical notes by type (discharge or radiology)
ehr get-clinical-notes \
    --note-type: discharge | radiology | all = all \
    --limit: int = 10 \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --format: json | text | table = json

# List diagnoses for a patient or admission
ehr list-diagnoses \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

# List lab events for a patient
ehr list-lab-events \
    --patient-id: str (required) \
    --admission-id: str (optional) \
    --abnormal-only: bool = False \
    --category: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

# List medications for a patient or admission
ehr list-medications \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --medication: str (optional) \
    --route: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

# List procedures for a patient or admission
ehr list-procedures \
    --patient-id: str (optional) \
    --admission-id: str (optional) \
    --limit: int = 20 \
    --format: json | table = json

# Ask a question in natural language
ehr natural-query <query> \
    --limit: int = 10 \
    --format: json | markdown | table = markdown

# Get the database schema
ehr get-schema \
    --format: json | markdown = markdown
```

### Clinical Notes: Two Approaches

**For simple note retrieval by ID:**
```bash
# Get all radiology reports for a patient
ehr get-clinical-notes --note-type=radiology --patient-id="10461137"

# Get discharge summary for specific admission
ehr get-clinical-notes --note-type=discharge --admission-id="25236814" --limit=1

# Get most recent discharge summary (sorted by charttime)
ehr get-clinical-notes --note-type=discharge --patient-id="10461137" --limit=1
```

**For content-based searches:**
```bash
# Search within note content using natural language
ehr natural-query "Find all notes mentioning pulmonary fibrosis for patient 10461137"
ehr natural-query "What imaging studies were done for this patient's respiratory issues?"
ehr natural-query "Show me abnormal lab results from the most recent admission"
```

## Development

### Running Tests

```bash
# Run all tests
uv run pytest

# Run only unit tests (skip integration tests)
uv run pytest -k "not integration"

# Run only integration tests
uv run pytest -k "integration"

# Run tests with output visible
uv run pytest -v -s

# Run tests with coverage
uv pip install pytest-cov
uv run pytest --cov=src/mcp_server_neo4j_ehr --cov-report=html

# Run specific test file
uv run pytest src/mcp_server_neo4j_ehr/tests/functionality/test_patient.py

# Run natural language query test with debug output
uv run pytest "src/mcp_server_neo4j_ehr/tests/functionality/test_natural_query.py::TestNaturalQueryIntegration" -v -s --log-cli-level=INFO
```

For more details on testing, see the [test documentation](src/mcp_server_neo4j_ehr/tests/README.md).

### Debugging Natural Language Queries

To see what Cypher queries are generated from natural language questions:

```bash
# Interactive mode - enter queries and see results
uv run python debug_natural_query.py

# Command line mode - test a specific query
uv run python debug_natural_query.py "How many patients have heart failure?"
```

This debug script shows:
- The natural language query being processed
- The generated Cypher query from OpenAI
- The query execution results
- Any errors or issues

### Project Structure

```
src/mcp_server_neo4j_ehr/
├── __init__.py
├── __main__.py           # CLI entry point
├── server.py             # Main server implementation
├── modules/
│   ├── constants.py      # Configuration constants
│   ├── data_types.py     # Pydantic models
│   ├── db_connection.py  # Neo4j connection management
│   └── functionality/    # Tool implementations
│       ├── patient.py
│       ├── search_notes.py
│       ├── list_diagnoses.py
│       ├── list_lab_events.py
│       ├── list_medications.py
│       ├── list_procedures.py
│       ├── natural_query.py
│       └── get_schema.py
└── tests/                # Test suite
    ├── README.md         # Test documentation
    ├── conftest.py       # Test fixtures
    └── functionality/    # Module tests
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License.
</file>

</files>
